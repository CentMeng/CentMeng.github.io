[{"title":"描述统计学","date":"2019-06-17T13:45:41.000Z","path":"2019/06/17/描述统计学/","text":"这里只针对一些知识做简要的记录，着重了解下箱线图和标准差部分 研究方法一句话概括统计学研究方法：学习构建、总体与样本、相关与因果、假设与试验 构建：抽象的概念如何描述，即如何根据参数来描述问题 可以度量构建（抽象）的可操作定义（参数），构建被测量后，我们便可以分析它们了 当更多的因素为常量时，测试结果就更可信 统计量：描述样本的数字 变量：描述各个数据点的特征，例如性别等 常量：不会改变的数 调查方法安慰剂方法：为了让调查有对比，需要让正常的人也参与进来，比如服药，不能给真实的药，只能用安慰剂，但也不能让他们知道是安慰剂 在这样的基础上我们又可以划分为单盲和双盲： 单盲：只让被调查方不知道自己服用的是否有效的药 双盲：被调查者和统计者都不让知道，一面影响统计者判断 数据可视化 频次：出现的次数 相对频率：每一种类与总体的比 组距：指每组的最高数值与最低数值之间的距离 直方图软件：Interactivate 正态分布：会有峰值叫做众数，图对称，众数=中位数=平均值 偏斜分布：当多数数据集中在曲线的一端，而少数数据在曲线的另一端，数据分布的形态就产生了偏斜。当偏斜的一边的趋向正数的方向，叫正偏态。当偏斜的一边的趋向负数的方向叫负偏态。 集中趋势 集中趋势，我们要学会用一个数字描述的三种量度，即均值、中位数和众数 中位数：分布在中间的值,中位数是位于“中间”的数据，意味着有一半数据值小于它，而另一半大于它。由于存在偏斜分布，所以用中位数来代表平均水平（为了避免有异常值影响平均值）。中位数如果不是正好有一个值在中间，则取中间两个值的平均值。比如1，3，5，7，8，10队列的中位数是（5+7）/2 众数：出现次数最多的众数，众数分类可能有多个众数会有多个众数，比如鞋，男鞋中有一个众数，女鞋中有一个众数。所以众数可用于描述任何数据类型，数值型和类别型都可以 均值：平均数 均值、中位数和众数特性 有一个简单的公式 如果数据集中有数据的值变化，它也一定会变化 不受组距变化的影响 不易受到异常值的影响 容易在直方图上找到 箱线图 一般来说，在去除数据点前，我们建议首先将数据点通过图像表述出来（直方图、散点图、箱线图等），这样可以帮助你获得对数据整理分析的了解。然后，基于项目的背景，判断你更关心数据的哪一部分（大多数正常数据，还是小部分异常数据），因为在一些项目背景下，你可能更关心那些异常值，比如在 数据分析（进阶）课程的安然数据分析中，那些工资异常高的人更有可能腐败。最后，是基于现有的数据量作出决定，究竟是直接丢弃部分数据还是对部分作出调整，亦或是有保留地接受所有数据。特别记住一点，没有一种分析方法100%正确，但我们总可以尝试根据不同的需求找到一种最合理的方法。 所以我们可以通过箱线图直观的表示四分位数和异常值 在了解箱线图，我们需要先知道几个概念 四分位：第1个四分位就是第一个数与中位数中间的数，即分成四份，第一份的最后一个。以此类推 IQR：第3个四分位减去第1个四分位 即Q3-Q1 定义异常值：如果一个值小于第1个四分位数减去1.5倍的IQR 或者大于第3个四分位数加上1.5倍的IQR 了解了上面的概念，下面我们来看下箱线图： 直方图与箱线图对应关系，请注意图C的包含zuckerberg的异常值 如上图，可以看到直方图组距和箱线图的组距关系，以及异常值的标记位置 数学符号 用符号讲故事，语言如此，数学也如此 μ（总体参数）：用来描述整个总体的值,即抽样总体的数 x-bar(样本参数)：用来描述样本（总体中的某一部分）的值；我们使用统计量来估计总体参数。估计值是我们对总体参数的最佳猜测。所以，我们可以使用 X-bar 来估计μ。参数（μ）是用来描述整个总体的值。 μ和x-bar的两者之间的差别叫做抽样误差 均值数字表达如下图 均值数字符号进一步描述 我们用上面的样本参数和总体参数针对均值来说明，左边的是样本的平均值，右边的是总体的平均值的符号写法 中位数公式，数据集个数为偶数 数据为奇数 偏差：每个值与数据集均值之间差 平均偏差：衡量差异性最好的选项。算法是找出每个值与数据集均值之间差的平均值（平均偏差），有些值不需要负数则使用平均绝对偏差。 方差：各个数据分别与其平均数之差的平方的和的平均数，用字母D表示。在概率论和数理统计中，方差（Variance）用来度量随机变量和其数学期望（即均值）之间的偏离程度。在许多实际问题中，研究随机变量和均值之间的偏离程度有着重要意义。 标准差（Standard Deviation）：标准差是方差的算术平方根，用小写的西格玛表示。中文环境中又常称均方差，但不同于均方误差（mean squared error，均方误差是各数据偏离真实值的距离平方的平均数，也即误差平方和的平均数，计算公式形式上接近方差，它的开方叫均方根误差，均方根误差才和标准差形式上接近），标准差是离均差平方和平均后的方根，用σ表示。标准差是方差开平方。 大写的西格玛是求和 标准差图形化解释： 每个值与平均值的偏差，这就是偏差，然后我们对每个偏差取平方，等同于这些方形的面积，然后我们得出这些方形面积的平均值，将平均值开平方，从而得到方形的边长，即标准差。 如下图所示 标准差特性 在正态分布中，68.2%的数据在平均值一个标准差的范围之内，即（平均值+标准差）和（平均值-标准差），95%的数据在两个标准差之内，即（平均值+2标准差）和（平均值-2标准差）。如下图所示 标准差归一化 我们用一个示例来说明，标准差归一化的问题，A是facebook好友数，其中用户距离μ是3.5个标准差，B是twitter关注数，用户距离μ是2.5个标准差，能说明A比B更不受关注吗？答案是不能的。 根据上面的问题，可得出下图： 上图合二为一得到未进行归一化的下图 下面使用0作为参考点，进行归一化，得到标准化分布图，如下图所示 对两个图做标准分布后，发现B比A离得更远，这是因为在facebook归一化就是将所有值按 进行计算新值，得出新的均值和方差，即平均值为0，标准偏差为1。具体步骤就是减去平均值，将其平移到0处，然后除以标准差，使标准差等于1。通过z值，我们可以将任何正态分布进行转换，并做比较，正如上面facebook和twitter的例子 上面的示例，最终结果小于值210的比例与这里的小于值0.56的比例完全相同，同时也等于最右边图小于55.6的比例。 所以判定不同组数据，来分析同一个目的，需要对两组数据做归一化之后再做比较结果。","categories":[{"name":"统计学","slug":"统计学","permalink":"https://centmeng.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://centmeng.github.io/tags/统计学/"}]},{"title":"贝塞尔校正","date":"2019-06-17T13:40:18.000Z","path":"2019/06/17/贝塞尔校正/","text":"“贝塞尔校正(Bessel’s Correction)”这个名词，是德国天文学家，数学家 Friedrich Bessel在进行天体测量学研究时提出的一个方法。其主要目的是一个与统计学的方差和标准差相关的一个修正方法而已。 大家都知道方差和标准差的公式，除数都是数据的个数即n，但是对于样本方差和样本标准差我们如何去估算总体方差和标准差呢？如下图所示 上图表示的含义是样本标准差去估计总体标准差（就是利用样本标准差去估算总体标准差），小写s表示更正后的标准差。用样本的标准差去估计的总体的标准差的时候需要通过贝塞尔校正 。分母减一，使值变大一点。那么为什么需要 减去1呢？ 原因在于：比如在高斯分布（正态分布）中，我们抽取一部分的样本，用样本的方差来估计总体的方差。由于样本绝大部分会落在中间位置附近，那么样本方差一定小于总体的方差（因为高斯分布的边沿抽取的数据很少）。为了能弥补这方面的缺陷，那么我们把公式的n改为n-1,以此来提高方差的数值。这种方法叫做贝塞尔校正系数。 PS：当我们用小样本数据的标准差去估计总体的标准差的时候采用 n-1,但是这个小样本数据的实际标准差还是用 n 的那个公式的，不要混淆了数据的实际标准差。","categories":[{"name":"统计学","slug":"统计学","permalink":"https://centmeng.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://centmeng.github.io/tags/统计学/"}]},{"title":"nginx重试机制的深坑","date":"2019-04-18T09:45:43.000Z","path":"2019/04/18/nginx重试机制的深坑/","text":"写了一个批量发短信的方法，为了方便，通过接口请求的方式进行调用，在调用过程中由于发送数量多，造成请求处理超时，导致了nginx重试机制，最终导致短信多次重发。血淋淋的教训啊~ nginx公司的服务和大多数公司服务一样，都采用多节点的方式部署，并使用nginx进行负载均衡。nginx是常用的一种HTTP和反向代理服务器，支持容错和负载均衡，其中nginx的重试机制就是容错的一种。 在nginx的配置中，proxy_next_upstream 和proxy_next_upstream_tries是重试配置，其中proxy_next_upstream给出了在什么情况下进行重试，官方文档给出的说明是： 123Syntax: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...; Default: proxy_next_upstream error timeout; Context: http, server, location 根据文档所知，当请求服务器发生错误或超时时，会尝试到下一台服务器。proxy_next_upstream_tries官方给出的文档是： 1234Syntax: proxy_next_upstream_tries number; Default: proxy_next_upstream_tries 0; Context: http, server, location This directive appeared in version 1.7.5. proxy_next_upstream_tries配置决定最多重试多少次，0表示不限制。我们的nginx没有找到该配置项，默认尝试了3次。 好了，下面看下破案现场吧 可以看到超时时间是60秒，超时之后，都会向之前没有重试过的服务器再次请求。 总结场景：请求一个接口，处理时间较长（如1分钟），且为同步操作（即处理完成后才返回结果）。若nginx配置的响应等待时间（proxy_read_timeout）为60秒，就会触发超时重试，将请求又打到另一台。如果处理中没有考虑到重复数据的场景，就会发生数据多次重复调用！所以下次如有这种情况可以使用IP:Port的方式进行操作，请注意你的姿势。","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"深坑解决","slug":"深坑解决","permalink":"https://centmeng.github.io/tags/深坑解决/"}]},{"title":"Docker","date":"2018-08-05T03:45:17.000Z","path":"2018/08/05/Docker/","text":"新接触python的flask和react，由于装环境太麻烦，所以决定用Docker搞一把。首先先打一个python3.6和centos的镜像 1. python3.6和centos71.1 下载基础镜像123456789101112131415#搜索centos7docker search centos7ååå#下载centos7镜像docker pull centos#如果没有登录需要使用docker login命令登录#查看镜像docker image ls#启动镜像docker run -ti image_id #查看镜像，可以查看容器iddocker ps -a 1.2 在基础镜像安装python 进入/usr/local目录 下载python 1wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tar.xz 如果没有wget使用yum安装 yum install wget 由于xz结尾的文件，故可以使用如下命令来解压： 123 xz -d Python-3.6.5.tar.xz #再执行tar tar xvf Python-3.6.5.tar 继续执行如下命令： 1234567891011121314151617181920212223#更改目录mv python-3.6.5 python3#进入python解压后目录cd python3 ./configure --prefix=/usr/local/python3 --enable-optimizationsmake#替换python# 进入/usr/bin目录cd /usr/bin# 之前2.7版本备份mv python python.bak其中有python, python2.7, python2三个文件，其实都是指向python2.7的，这里将python备份#做超链接ln -s /usr/local/python3/bin/python /usr/bin/python#检验python -V 中途如果出现失败情况，则通过yum安装相应包 123456789#如果出现 错误尝试安装yum install gccyum install gcc-c++#如果sudo命令缺失yum install sudomake#如果make命令缺失yum install make 1.3 将容器打包成镜像 commit时候不要退出docker镜像,commit后可以exit退出 1234567891011121314docker commit -a &quot;mengshaojie.com&quot; -m &quot;python3.6 in centOS&quot; 容器名称或id 打包的镜像名称:标签 OPTIONS说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。#查看容器iddocker ps -a docker commit -a &quot;mengshaojie.com&quot; -m &quot;python3.6.5 in CentOS&quot; 容器id python36-centos7#标记镜像docker tag python36-centos7（原镜像） mengshaojie（用户名）/python36-centos7（名称）:1.0（标记即版本号） 1.4 推送到远程仓库1docker push mengshaojie/python36-centos7:1.0 2. 上一步骤镜像基础上加入mongodb和redis2.1 进入mengshaojie/python36-centos7:1.0镜像1docker run -ti mengshaojie/python36-centos7:1.0 2.2 安装mongodb2.2.1 下载安装下载地址：https://www.mongodb.com/download-center#production 1wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.6.3.tgz 安装路径：/usr/local/mongodb 2.2.2 配置环境变量1vi /etc/profile 最后面增加如下代码：export PATH=$PATH:/usr/local/mongodb/bin 12source /etc/profilesource /root/.bashrc 2.2.3 设置mongodb的数据库路径1mongod --dbpath=/opt/mongodb/data 2.3 安装redis2.3.1 下载安装下载地址：https://redis.io/ 1wget http://download.redis.io/releases/redis-4.0.9.tar.gz 安装路径：/usr/local/redis 2.3.2 安装12#redis目录make 2.4 重复1.3和1.4（记住修改名称）12345678docker ps -adocker commit -a &quot;mengshaojie.com&quot; -m &quot;python3.6.5 in CentOS&quot; e14e59c9e5fe python36-mongodb363-redis409-centos7docker tag python36-mongodb363-redis409-centos7 mengshaojie/python36-mongodb363-redis409-centos7:1.0docker push mengshaojie/python36-mongodb363-redis409-centos7:1.0 3 Docker其他命令123456789101112131415161718192021222324252627#删除所有容器sudo docker rm $(docker ps -a -q)#删除tag和镜像docker rmi -f mengshaojie/common:1.0#本地目录拷贝到容器中docker cp 本地目录 容器id:容器目录#容器和镜像区别，镜像是相当于安装盘，容器相当于安装盘安装的多少个系统exit 退出docker后重新进入容器需要执行以下不走## 查询容器docker ps -a## 启动容器docker start 容器id## 进入容器，这样和docker run -ti 镜像id不同的是会进入同一个容器，不会新创建个容器docker attach 容器id# 导出容器docker export 容器id &gt; /localpath/***.tar# 导入容器docker import 容器id# 把正在运行的容器保存成镜像docker commit # 保存镜像和加载镜像docker save 镜像id &gt; /home/myimage-save-0411.tar docker load &lt; /home/myimage-save-0411.tar# 查询所有镜像的ipdocker inspect -f &apos;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; $(docker ps -aq) #导出 export 与 保存 save 的区别 (1).export导出的镜像文件大小 小于 save保存的镜像 (2).export 导出（import导入）是根据容器拿到的镜像，再导入时会丢失镜像所有的历史，所以无法进行回滚操作（docker tag ）；而save保存（load加载）的镜像，没有丢失镜像的历史，可以回滚到之前的层（layer）。（查看方式：docker images –tree） https://blog.csdn.net/clj198606061111/article/details/50450793","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"运维相关","slug":"运维相关","permalink":"https://centmeng.github.io/tags/运维相关/"}]},{"title":"AOP总结（自定义注解和AOP及反射结合）","date":"2018-08-05T03:32:22.000Z","path":"2018/08/05/AOP总结（自定义注解和AOP及反射结合）/","text":"面向切面编程即AOP（Aspect Oriented Program），是在运行时，动态地将代码切入到类的指定方法，指定位置上的编程思想就是面向切面的编程。 在工作中，遇到了想实时监听订单状态变更的需求，于是决定用kafka消息队列来传递订单变更的消息，但是再每个调用订单变更的地方太麻烦了，所以决定写个公共方法，然后通过切面编程来解决此需求。废话不多说了，上代码 demo代码自定义注解1234567891011121314151617/** * @author Vincent.M * @mail mengshaojie@188.com * @date 2018/5/18 * @copyright ©2018 孟少杰 All Rights Reserved * @desc 订单状态改变，kafka集群生产消息注解 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documentedpublic @interface KafKaProductor &#123; KafkaTopics topic(); String routeKey() default \"\"; String message() default \"\"; //type =1 增删改查状态改变 int type() default 0;&#125; 方法1234@KafKaProductor(topic=KafkaTopics.ORDER,type = 1) public int insertSelective(Userorder userorder)&#123; return orderMapper.insertSelective(userorder); &#125; AOP切面代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import com.alibaba.fastjson.JSONObject;import com.zongjie.mq.kafka.enums.KafkaTopics;import com.zongjie.mq.kafka.KafkaProducer;import com.demo.order.server.annotations.KafKaProductor;import com.zongjie.order.server.model.UserOrderMQ;import com.zongjie.order.server.model.Userorder;import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.lang.reflect.Method;/**Java * @author Vincent.M * @mail mengshaojie@188.com * @date 2018/5/18 * @copyright ©2018 孟少杰 All Rights Reserved * @desc KafKa发送消息切面 */@Aspect@Component@Slf4jpublic class KafKaProductAspect &#123; @Autowired KafkaProducer kafkaProducer; @Around(\"execution(* com.demo.order.server.service.impl..*.insertSelective(..)) || execution(* com.demo.order.server.service.impl..*.updateByPrimaryKeySelective(..)) \") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; MethodSignature signature = (MethodSignature) pjp.getSignature(); log.info(\"[KafKa生产],订单，执行类&#123;&#125;,执行方法&#123;&#125;\", signature.getDeclaringTypeName(), signature.getName()); Method targetMethod = signature.getMethod(); Object obj = null; if (targetMethod.isAnnotationPresent(KafKaProductor.class)) &#123; KafKaProductor orderStatusUpdate = (KafKaProductor) targetMethod.getAnnotation(KafKaProductor.class); KafkaTopics topic = orderStatusUpdate.topic(); String routeKey = orderStatusUpdate.routeKey(); String message = orderStatusUpdate.message(); int type = orderStatusUpdate.type(); log.info(\"[KafKa生产],订单，执行类&#123;&#125;,执行方法&#123;&#125;,topic:&#123;&#125;,routeKey:&#123;&#125;,message:&#123;&#125;\", signature.getDeclaringTypeName(), signature.getName(), topic, routeKey, message); obj = pjp.proceed(); switch (type) &#123; case 1: if ((Integer) obj &gt; 0) &#123; Userorder userorder = (Userorder) pjp.getArgs()[0]; log.info(\"[KafKa生产],订单type=1，执行类&#123;&#125;,执行方法&#123;&#125;,topic:&#123;&#125;,原message:&#123;&#125;\", signature.getDeclaringTypeName(), signature.getName(), topic, JSONObject.toJSONString(userorder)); UserOrderMQ userOrderMQ = new UserOrderMQ(); BeanUtils.copyProperties(userorder,userOrderMQ); log.info(\"[KafKa生产],订单type=1，执行类&#123;&#125;,执行方法&#123;&#125;,topic:&#123;&#125;,转换后message:&#123;&#125;\", signature.getDeclaringTypeName(), signature.getName(), topic, JSONObject.toJSONString(userOrderMQ)); kafkaProducer.send(com.zongjie.mq.kafka.enums.KafkaTopics.ORDER, routeKey, JSONObject.toJSONString(userOrderMQ)); &#125; break; &#125; &#125;else&#123; obj = pjp.proceed(); &#125; return obj; &#125;&#125; 上面的例子，是针对订单变更，发送kafka生产者消息的例子。使用了自定义注解,来传递消息类型，消息内容等信息，用AOP的配置execution的表达式设置方法切面，然后通过反射获取注解内容，和方法内容。 下面来总结下，首先说下execution表达式吧 execution表达式 在多个表达式之间使用 || , or 表示 或 ，使用 &amp;&amp; , and 表示 与 ， ！ 表示非，例如上面demo execution( com.demo.service.impl...*(..)) 符号 含义 execution（） 表达式的主体 第一个”“符号 表示返回值的类型任意 com.demo.service.impl AOP所切的服务的包名 包名后面的”..“ 表示当前包及子包 第二个”“ 表示类名，即所有类。此处可以自定义 .(..) 表示任何方法名，括号表示参数，两个点表示任何参数类型,set标识set开头的方法Dao标识Dao结尾的方法 举例说明: 123com.demo.order.server.service.impl..*.insert*(..)) com.demo.order.server.service.impl包下所有insert开头的方法 advice 大家都知道spring中有@Before、@Around和@After等advice，这里我们介绍下advice的执行场景和注意点。 @Before是在所拦截方法执行之前执行一段逻辑。@After 是在所拦截方法执行之后执行一段逻辑。@Around是可以同时在所拦截方法的前后执行一段逻辑。 如果在同一个 aspect 类中，针对同一个 pointcut，定义了两个相同的 advice(比如，定义了两个 @Before)，那么这两个 advice 的执行顺序是无法确定的，哪怕你给这两个 advice 添加了 @Order 这个注解，也不行。 对于@Around这个advice，不管它有没有返回值，但是必须要方法内部，调用一下 pjp.proceed();否则，Controller 中的接口将没有机会被执行，从而也导致了 @Before这个advice不会被触发。 进过的坑 不能在方法methodA中调用某个方法methodB，然后对这个调用的某个方法methodB做切面，要对某个类要调用的方法做切面才有效,例如methodAååå","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://centmeng.github.io/tags/Spring/"}]},{"title":"SpringBoot starter制作","date":"2018-08-05T03:10:46.000Z","path":"2018/08/05/starter制作/","text":"大家都知道，在spring-boot有众多starter。在传统Maven项目中通常将一些层、组件拆分为模块来管理，以便相互依赖复用，在spring-boot项目中我们则可以创建自定义spring-boot starter来达成该目的。å 这里我们做一个KafKa的starter来进行讲解，首先，我们先引入依赖，pom.xml如下 pom.xml引入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.zongjie&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-kafka-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.10&lt;/artifactId&gt; &lt;version&gt;0.8.2.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; Spring官方 Starter通常命名为spring-boot-starter-{name}如 spring-boot-starter-web， Spring官方建议非官方Starter命名应遵循{name}-spring-boot-starter的格式。 写配置和service 这里我们写kafka需要从application.properties读取的配置，在引用的项目中，配置即可 以生产者为例的配置文件 12345678910111213141516171819202122232425262728293031323334353637383940/** * @author Vincent.M * @mail mengshaojie@188.com * @date 2018/5/21 * @copyright ©2018 孟少杰 All Rights Reserved * @desc */@Data@ConfigurationProperties(ProducerProperties.PREFIX)public class ProducerProperties &#123; public static final String PREFIX = \"com.mq.kafka.producer\"; private String serializerClass; private String producerType; private int maxQueueBuffer; private String brokerList; private int requiredAck; public Properties getProperties() &#123; Properties properties = new Properties(); if (serializerClass != null) &#123; properties.setProperty(\"serializer.class\", serializerClass); &#125; if (producerType != null) &#123; properties.setProperty(\"producer.type\", producerType); &#125; if (maxQueueBuffer &gt; 0) &#123; properties.setProperty(\"queue.buffering.max.ms\", String.valueOf(maxQueueBuffer)); &#125; if (brokerList != null) &#123; properties.setProperty(\"metadata.broker.list\", brokerList); &#125; if (requiredAck &gt; 0) &#123; properties.setProperty(\"request.required.acks\", String.valueOf(requiredAck)); &#125; return properties; &#125;&#125; service需要被引用的类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class KafkaProducer implements InitializingBean &#123; private static ConcurrentHashMap&lt;String, ProducerWrapper&gt; producerWrapperMap = new ConcurrentHashMap&lt;String, ProducerWrapper&gt;(); ProducerProperties producerProperties; public KafkaProducer(ProducerProperties producerProperties)&#123; this.producerProperties = producerProperties; &#125; /** * 同步发送生产者数据 * * @param topic 主题 * @param routeKey 消息分组的字段,为null会选择随机分组 * @param msg 消息体 */ public void send(KafkaTopics topic, String routeKey, String msg) &#123; getProducer(topic.getTopic()).send(topic, routeKey, msg); &#125; /** * 异步发送生产者数据，会先放到内存队列中再发送 * * @param topic * @param routeKey * @param msg */ public void sendAsync(KafkaTopics topic, String routeKey, String msg) &#123; getProducer(topic.getTopic()).sendAsync(topic, routeKey, msg); &#125; /** * 获取信息发送器 * * @param topic * @return */ private ProducerWrapper getProducer(String topic) &#123; if (!producerWrapperMap.containsKey(topic)) &#123; synchronized (producerWrapperMap) &#123; if (!producerWrapperMap.containsKey(topic)) &#123; if (producerProperties != null) &#123; producerWrapperMap.put(topic, new ProducerWrapper(topic, producerProperties.getProperties())); &#125; &#125; &#125; &#125; return producerWrapperMap.get(topic); &#125; public void afterPropertiesSet() throws Exception &#123; Assert.notNull(producerProperties, &quot;producerProperties &apos;producer&apos; is required&quot;); &#125;&#125;","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://centmeng.github.io/tags/spring-boot/"}]},{"title":"2018-我想和世界谈谈（不昧己心，不尽人情，不竭物力）","date":"2018-01-01T03:17:48.000Z","path":"2018/01/01/2018-我想和世界谈谈（不昧己心，不尽人情，不竭物力）/","text":"不昧己心-古人云：“仰不愧于天，俯不怍于人。”做人做事，一定要不昧己心，做事光明磊落，不要背地里损害他人利益。 不尽人情-是教我们凡事都要留有余地，事不能做尽、势不能用尽、福不能享尽、话不能说尽。所以《周易》中说，“上九，亢龙有悔”。 不竭物力-这句话出自《淮南子•主术训》。意思是不要排尽湖中或池中的水来捕鱼，不要焚烧山林来猎取猎物。一方面上天有好生之德，人类向自然索取所需，但一定要遵循生态规律，这样才能和谐相处。如果一位索取，竭尽物力，等待我们的必然是大自然眼里的惩罚。国家可持续发展战略也因此。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;年底了，到了评定和发年终奖的时候，总会想起2015年，当时决定来北京发展，在发年终奖前和公司提出离职，只为了能够让公司提前安排接手人员，避免影响“摇点”业务开发。可想而知，年终奖受到了影响，其实这个自己一开始就做好了准备。但当时觉得自己是个loser是在开年会时候，我一个奖都没得。当时想法自己离开这样的公司是值得的，所以也没有怨言。但过完年回到公司，统计每个人奖项的时候，部门负责人刘守建看到统计结果，发现没有我，于是找行政和副总理论，最终给我评定了奖项。虽然知道这个奖项有多么虚，但起码觉得对工作的付出得到了肯定。后来在北京创业失败，说走就走的旅行的时候，回到大连，又和“摇点”团队相聚，部门负责人改签了出差的火车票来聚会，其他小伙伴也是一呼即来。也是那次聚会才知道，我离职前，刘守建和公司副总吵架是因为我的年终奖太少而吵。不昧己心，终会有回报的。失去了部分年终奖，但得到众人的认可，同时“摇点”这个团队的每个人，都是最好的朋友、兄弟。尤其从项目经理李相禄那学到不少管理和处事经验，这也比钱重要的多。那一年为来北京打下了很好的基础。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2016年，这一年创过业也失败过，这一年体会最深的就是“不尽人情”，也让自己吃了亏。这一年，是成长最快的一年，也因为成长，所以变的更加傲娇。等真正跌下来的时候，才发现自己陷入了迷茫和忧郁中，间接的影响了自己的生活，天天为自己的未来而迷茫，生怕自己被淘汰，无力去照顾自己想要照顾的人。这一段迷茫和忧郁期，从16年年底一直持续到17年年底。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2017年，正如刚刚所说处在迷茫和忧郁中，这一年缺少一位真正能指引我发展道路的人，来告诉我该怎么走，才能有能力越来越好，能够让我有能力照顾我想照顾的人。这一年处处尝试，尝试大数据发展规划、尝试架构师发展规划、尝试咨询师发展规划，一直没有明确下来。到了年底，才想开，其实这一切都不冲突，就看路怎么走。当然，虽然在迷茫中，但工作技能还是得到了提升。总结起来2017年不是“不竭物力”，而是感恩。这一年的工作，由于自己原因，同时也因一些同事对自己的不理解，所以压力还是有的。也想过换工作，也有乙方和兄弟公司开条件让去他们那边。但最终都没有离开，虽然这里有一些自己看不惯的，但这里有一个能懂你的领导，并给你创造条件让你实现自己的价值。正如之前在“摇点”，虽然工资不高，但有李相禄在，每个成员也都过的很开心。有一些事，是钱不能相比的。当然，滴水之恩，当涌泉相报，在愿景还没实现就逃离，是不懂得感恩同时也是不负责任的。对于工作中，发生冲突的同事，虽然因为各种原因，你们选择接受我的想法和接受我的脾气，但我想说，我就是“知错改错不认错”，我的错，我知道，只是不承认。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2018年，是时候该对自己说说了，2018年，要把17年失去的追回来；2018年，要收收自己的脾气；2018年照着自己的规划，去完成自己的目标；2018年，做更好的自己。“不昧己心，不尽人情，不竭物力”。","categories":[{"name":"随笔集","slug":"随笔集","permalink":"https://centmeng.github.io/categories/随笔集/"}],"tags":[{"name":"随笔集","slug":"随笔集","permalink":"https://centmeng.github.io/tags/随笔集/"}]},{"title":"Maven私服上传多个jdk版本包即多profile配置","date":"2017-11-10T15:01:13.000Z","path":"2017/11/10/Maven私服上传多个jdk版本包即多profile配置/","text":"在项目中，我们打的jar包，由于使用者jdk版本不同，有可能导致Unsupported major.minor version 52.0 类似这样的错误，解决方法就是上传私服多个jdk版本。 项目整体框架图 netpay-parent netpay项目的parent项目，只有pom文件 netpay-api 存放netpay项目所有服务都会用到的公共Entity netpay-common 存放netpay项目所有服务都会用到的公共工具类和组件 netpay-merchant-facade 存放netpay-merchant对外暴露的服务和entity netpay-merchant-service netpay-merchant服务实现 配置 1.netpay-parent中pom.xml 所有项目都继承parent，所以给parent设置了属性，则其他项目也适用。在netpay-parent中pom.xml中添加如下代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;build&gt; &lt;finalName&gt;netpay-parent&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 解解决maven update project 后版本降低为1.5的bug --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jar.source&gt;$&#123;java.version&#125;&lt;/jar.source&gt; &lt;jar.target&gt;$&#123;java.version&#125;&lt;/jar.target&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;jdk16&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;classifier&gt;jdk16&lt;/classifier&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;properties&gt; &lt;jar.source&gt;1.6&lt;/jar.source&gt; &lt;jar.target&gt;1.6&lt;/jar.target&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 打包不同版本的jdk，只需要修改build中plugin的jar.source，jar.target改成响应jdk版本例如1.8或者1.6。 profiles是重点,也是多profile配置的核心，在这里定义了两个profile，一个是default默认的，一个是jdk16（如需改成其他的jdk则对应修改jdk16和1.6） 2.修改运行环境 此处用idea作为开发工具，eclipse和myeclipse同理，在idea中每打包一个jdk版本修改如下几个地方 settings（Preferences） Module Settings 各个子项目都需要修改 3.Rebuild 项目 4.上传到私服 执行命令（在netpay-parent项目下）： 默认方式： 1mvn deploy 使用jdk16配置方式： 1mvn deploy -P jdk16 使用 默认方式 123456&lt;dependency&gt; &lt;groupId&gt;net.netpay&lt;/groupId&gt; &lt;artifactId&gt;netpay-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;classifier&gt;jdk16&lt;/classifier&gt;&lt;/dependency&gt; 使用jdk16版本方式 123456&lt;dependency&gt; &lt;groupId&gt;net.netpay&lt;/groupId&gt; &lt;artifactId&gt;netpay-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;classifier&gt;jdk16&lt;/classifier&gt; &lt;/dependency&gt; Ok,以上就是maven配置多个profile的方式，望大家多多指教。","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"},{"name":"maven","slug":"maven","permalink":"https://centmeng.github.io/tags/maven/"}]},{"title":"SpringBoot使用自己项目的parent","date":"2017-10-29T04:49:57.000Z","path":"2017/10/29/SpringBoot使用自己项目的parent/","text":"我们在使用spring-boot的时候，parent需要继承一个spring的 spring-boot-starter-parent，但是有时候在我们自己的项目中，会定义一个自己的 parent 项目，这种情况下，我们该如何达到即使用了我们的parent，又将spring-boot集成进来呢？ 其实，spring-boot也想到了这种情况，所以只需几步就可以完成： 自己parent dependencyManagement是与dependencies同级。请注意，它的 type 是 pom，scope 是 import，这种类型的 dependency 只能在 dependencyManagement 标签中声明。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 自己子项目 集成自己的parent 123456&lt;parent&gt; &lt;groupId&gt;net.netpay&lt;/groupId&gt; &lt;artifactId&gt;netpay-parent&lt;/artifactId&gt; &lt;version&gt;0.0.5-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../netpay-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt; 集成spring-boot相关包 需要我们注意子项目的 dependencies 中，不需要再次添加对 spring-boot-dependencies 的声明了，否则子项目 将无法编译通过。 这是因为 spring-boot-dependencies 根本就没有对应的jar包，它只是一个 pom 配置，可以去 maven仓库 看一下。 同时有了parent的 spring-boot-dependencies ，我们在子项目中使用到的相关依赖，就不需要声明version了。 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"问题解决","slug":"问题解决","permalink":"https://centmeng.github.io/tags/问题解决/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://centmeng.github.io/tags/spring-boot/"}]},{"title":"SpringBoot+Dubbo+Zookeeper实现微服务架构","date":"2017-10-29T04:45:06.000Z","path":"2017/10/29/SpringBoot-Dubbo-Zookeeper实现微服务架构/","text":"以自己的netpay项目为例，向大家介绍。项目背景，之前项目比较大，要进行拆分，而且放弃之前的架构模式，重新搭架构。基于之前整个系统都使用dubbo进行RPC，所以决定继续使用Dubbo，不适用springcloud。如有问题，还请多多指教。 整体框架图 netpay-parent netpay项目的parent项目，只有pom文件 netpay-api 存放netpay项目所有服务都会用到的公共Entity netpay-common 存放netpay项目所有服务都会用到的公共工具类和组件 netpay-merchant-facade 存放netpay-merchant对外暴露的服务和entity netpay-merchant-service netpay-merchant服务实现 相关技术流程 maven私有库搭建 zookeeper集群部署 按框架图创建项目 spring-boot集成dubbo spring-boot集成mybatis spring-boot多profile配置 maven私有库搭建我们需要把创建的api和common及项目等要以maven方式引用，所以需要搭建maven私有库。具体方法参照Maven安装和发布项目到私服 zookeeper集群部署众所周知,zookeeper是注册中心同时也可以作为分布式锁来使用，对于它的部署和使用可参照Zookeeper简介说明 创建项目 groupId统一为net.netpay netpay-parent、netpay-api、netpay-common、netpay-merchant-facade都以创建maven项目方式，netpay-merchant-service以创建spring-boot项目方式。 其中netpay-api、netpay-common、netpay-merchant-facade、netpay-merchant-service的parent都继承netpay-parent。 123456&lt;parent&gt; &lt;groupId&gt;net.netpay&lt;/groupId&gt; &lt;artifactId&gt;netpay-parent&lt;/artifactId&gt; &lt;version&gt;0.0.5-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../netpay-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; netpay-merchant-service为spring-boot项目，关于不使用默认spring-boot项目方法请参考Spring Boot 不使用默认的 parent，改用自己的项目的 parent spring-boot集成dubbo 部署dubbo-admin，下载地址链接: https://pan.baidu.com/s/1geHVnZt 密码: yai8 创建生产者 pom引用包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; properties文件 12345678910111213 ## Dubbo配置###应用名称dubbo.application.name=netpay-merchant###注册中心类型dubbo.registry.protocol=zookeeper###注册中心地址dubbo.registry.address=127.0.0.1:2181###暴露服务方式dubbo.protocol.name=dubbo###暴露服务端口dubbo.protocol.port=20880###Zookeeper地址zookeeper.address=192.168.60.203:2180 创建Service暴露的服务接口 12345678910111213 package net.netpay.merchant.facade; /** * @author Vincent.M * @mail mengshaojie@188.com * @date 17/9/20 * @copyright ©2017 孟少杰 All Rights Reserved * @desc */public interface TestService &#123; public String getInfo(String id);&#125; 创建暴露服务的具体实现类 123456789101112131415161718192021 import net.netpay.merchant.entity.query.WzPayRecord;import net.netpay.merchant.facade.TestService;import net.netpay.merchant.facade.query.WzPayRecordService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * @author Vincent.M * @mail mengshaojie@188.com * @date 17/9/20 * @copyright ©2017 孟少杰 All Rights Reserved * @desc */@Componentpublic class TestServiceImpl implements TestService &#123; @Override public String getInfo(String id) &#123; System.out.println(\"****\"+id); return \"aaa\"; &#125;&#125; 创建resources/dubbo/dubbo-netpay-merchant.xml 1234567891011121314151617181920212223 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"$&#123;dubbo.application.name&#125;\" /&gt; &lt;!-- 注册中心暴露服务地址 --&gt; &lt;!--&lt;dubbo:registry address=\"multicast://224.5.6.7:1234\" /&gt;--&gt; &lt;!--&lt;dubbo:registry protocol=\"zookeeper\" address=\"10.170.219.98:2181,10.173.55.173:2181\" /&gt; --&gt; &lt;dubbo:registry protocol=\"$&#123;dubbo.registry.protocol&#125;\" address=\"$&#123;dubbo.registry.address&#125;\" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"$&#123;dubbo.protocol.name&#125;\" port=\"$&#123;dubbo.protocol.port&#125;\" /&gt; &lt;!-- 用户服务接口 --&gt;&lt;dubbo:service interface=\"net.netpay.merchant.facade.TestService\" ref=\"testService\" /&gt; &lt;bean id=\"testService\" class=\"net.netpay.merchant.service.TestServiceImpl\"/&gt; &lt;/beans&gt; 修改启动类Application 12345678910111213 @SpringBootApplication@EnableScheduling@EnableAsync@MapperScan(\"net.netpay.merchant.dao\")//MyBatis配置@ComponentScan(&#123;\"net.netpay\"&#125;)//组件扫描@ImportResource(value = &#123;\"classpath:dubbo/dubbo-netpay-merchant.xml\",\"classpath:configs/application-memcached.xml\"&#125;)//引入dubbo配置和memcache的配置，后续引入其他配置都可以添加//@PropertySource(\"classpath:dubbo/dubbo.properties\") //引入properties的配置举例，此处屏蔽没有用到@EnableConfigurationProperties(&#123;BaseConfig.class&#125;)//自定义的一些配置public class NetpayMerchantApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NetpayMerchantApplication.class, args); &#125;&#125; 启动spring-boot，查看dubbo-admin 创建消费者 pom引入的包和properties的配置文件一样，只不过应用名不同,这里只介绍下controller中的引用和dubbo配置文件引用消费者 1.dubbo配置文件引用消费者 1234567891011121314151617181920 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"$&#123;dubbo.application.name&#125;\" /&gt; &lt;!-- 注册中心暴露服务地址 --&gt; &lt;!--&lt;dubbo:registry address=\"multicast://224.5.6.7:1234\" /&gt;--&gt; &lt;!--&lt;dubbo:registry protocol=\"zookeeper\" address=\"10.170.219.98:2181,10.173.55.173:2181\" /&gt; --&gt; &lt;dubbo:registry protocol=\"$&#123;dubbo.registry.protocol&#125;\" address=\"$&#123;dubbo.registry.address&#125;\" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"$&#123;dubbo.protocol.name&#125;\" port=\"$&#123;dubbo.protocol.port&#125;\" /&gt; &lt;dubbo:reference id=\"testService\" interface=\"net.netpay.merchant.facade.TestService\" check=\"false\" timeout=\"60000\"/&gt; 2.具体引用Controller 注意：老版本dubbo引用需使用@Autowired 123456789101112131415import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import javax.annotation.Resource;@Controllerpublic class TestController &#123; @Resource//老版本的dubbo需要使用@Autowired private TestService testService; @RequestMapping(value = \"/\" ,produces = \"application/json;charset=utf-8\") @ResponseBody public String test()&#123; return testService.getInfo(\"msj\"); &#125;&#125; 3.dubbo-admin查看 spring-boot集成mybatis之前用的一直都是JPA，但由于对项目改造，老项目用的iBatis为了尽量减少工作量采用MyBatis进行数据持久化。MyBatis的配置比较简单，可能根据需求不同，也有所不同，这里就大概介绍下，多数据源的问题，大家可以查看下其他相关资料。 pom引入 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; properties配置 1234567## Mybatis 配置#此处可以不配置#mybatis.typeAliasesPackage=net.netpay.merchant.entity## 两个*表示扫描子文件夹classpath目录在resource下mybatis.mapper-locations=classpath:mapper/**/*.xml## 此处可以配置一些别名，如果不需要也可以不配置#mybatis.config-location=classpath:configs/mybatis-config.xml Application启动类 123456789101112@SpringBootApplication@EnableScheduling@EnableAsync@MapperScan(\"net.netpay.merchant.dao\")//MyBatis配置mapper扫描包@ComponentScan(&#123;\"net.netpay\"&#125;)//组件扫描@ImportResource(value = &#123;\"classpath:dubbo/dubbo-netpay-merchant.xml\",\"classpath:configs/application-memcached.xml\"&#125;)//引入dubbo配置和memcache的配置@EnableConfigurationProperties(&#123;BaseConfig.class&#125;)//自定义的一些配置public class NetpayMerchantApplication &#123;public static void main(String[] args) &#123; SpringApplication.run(NetpayMerchantApplication.class, args);&#125;&#125; spring-boot多profile配置在本项目中，引入了三个环境，生产（prod）、测试（test）、开发（dev），只需要创建三个application.properties即可，如下图 application.properties指定 1spring.profiles.active=test Ok,以上就是整个项目的集成过程。如有错误点，希望大家多多指教。","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://centmeng.github.io/tags/spring-boot/"}]},{"title":"Java架构师-Maven安装和发布项目到私服","date":"2017-08-14T08:01:48.000Z","path":"2017/08/14/Java架构师-Maven安装和发布项目到私服/","text":"私服是架设在局域网的一种特殊的远程仓库，目的是代理远程仓库及部署第三方构件。有了私服之后，当 Maven 需要下载构件时，直接请求私服，私服上存在则下载到本地仓库；否则，私服请求外部的远程仓库，将构件下载到私服，再提供给本地仓库下载。我们可以使用专门的 Maven 仓库管理软件来搭建私服，比如：Apache Archiva，Artifactory，Sonatype Nexus。这里我们使用 Sonatype Nexus。 安装Maven 此处不是重点，大家可以自行百度 安装Nexus Nexus 专业版是需要付费的，这里我们下载开源版 Nexus OSS。http://www.sonatype.org/nexus/go 环境准备：Linux服务器，JDK1.8 下载最新版本，解压放到/usr/local/nexus312tar -zxvf nexus-3.5.0-02-unix.tar.gzmv nexus-3.5.0-02 /usr/local/nexus3 启动Nexus12# 进入nexus3/bin目录./nexus run &amp; 另外中途遇到一个坑，由于习惯不使用root用户，单独创建个用户，即使添加到root组依然不能执行sudo命令。需要在/etc/sudoers中添加创建的用户，保存使用wq! 验证启动默认网址:http://192.168.80.182:8081/(需换成自己ip) 默认用户名和密码：admin/admin123 发布项目到私服创建仓库 在创建仓库我们先了解下几个概念： 仓库类型 hosted 宿主仓库：主要用于部署无法从公共仓库获取的构件（如 oracle 的 JDBC 驱动）以及自己或第三方的项目构件； proxy 代理仓库：代理中央Maven仓库，当PC访问中央库的时候，先通过Proxy下载到Nexus仓库，然后再从Nexus仓库下载到PC本地。这样的优势只要其中一个人从中央库下来了，以后大家都是从Nexus私服上进行下来，私服一般部署在内网，这样大大节约的宽带。 group 仓库组：Nexus 通过仓库组的概念统一管理多个仓库，这样我们在项目中直接请求仓库组即可请求到仓库组管理的多个仓库。 具体创建步骤： 创建仓库： 创建宿主仓库： name输入msj-realease ，版本控制选择realease 重复第一二三步，创建msj-snapshots,版本控制选择snapshots，最终如下图 pom配置添加如下配置： 12345678910111213&lt;!-- 配置发布到私服 --&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;msj-realease&lt;/id&gt; &lt;name&gt;Release Repository of msj&lt;/name&gt; &lt;url&gt;http://192.168.80.182:8081/repository/msj-realease/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;msj-snapshots&lt;/id&gt; &lt;name&gt;Snapshot Repository of msj&lt;/name&gt; &lt;url&gt;http://192.168.80.182:8081/repository/msj-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; url是点对应仓库的copy按钮，会出现相应的url 配置本地maven（非服务器maven） settings.xml 中增加如下信息 123456789101112&lt;servers&gt; &lt;server&gt; &lt;id&gt;msj-realease&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;msj-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; 部署仓库项目根目录，执行mvn deploy命令 验证结果","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Swagger2集成","date":"2017-07-13T03:04:00.000Z","path":"2017/07/13/Swagger2集成/","text":"Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 Swagger2生成的api页面 Swagger集成（Spring boot） 添加Swagger2依赖 在pom.xml中加入Swagger2的依赖 123456789101112&lt;!-- swagger2 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- swagger2 --&gt; 创建Swagger2配置类 在Application.java同级创建Swagger2的配置类Swagger2 12345678910111213141516171819202122232425262728293031/** * @author Vincent.M * @mail mengshaojie@188.com * @date 17/7/12 * @copyright ©2017 孟少杰 All Rights Reserved * @desc @Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。 * 再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。 */@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.msj.fuxi&quot;)) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(&quot;Spring Boot中使用Swagger2构建RESTful APIs&quot;) .description(&quot;更多Spring Boot相关文章请关注：http://blog.didispace.com/&quot;) .termsOfServiceUrl(&quot;http://centmeng.github.io&quot;) .contact(&quot;孟少杰&quot;) .version(&quot;1.0&quot;) .build(); &#125;&#125; Controller中添加注解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@ApiOperation(value=&quot;菜单列表页面&quot;, notes=&quot;返回子菜单列表&quot;)@RequestMapping(value = &quot;menu&quot;, method = RequestMethod.GET)@PrivilegeRequired(value = &#123;&quot;admin&quot;,&quot;menu_detail&quot;&#125;)public ModelAndView listMenu() &#123; ModelAndView result = new ModelAndView(); List&lt;Menu&gt; subMenus = menuService.findBySubMenu(); result.addObject(&quot;subMenus&quot;,subMenus); result.setViewName(&quot;datadic/menu/list&quot;); return result;&#125;@ApiOperation(value=&quot;修改菜单列表&quot;, notes=&quot;返回菜单信息，和父菜单信息&quot;)@ApiImplicitParam(name = &quot;id&quot;, value = &quot;菜单id&quot;, required = true, dataType = &quot;String&quot;)@RequestMapping(value = &quot;menu/edit/&#123;id&#125;&quot;, method = RequestMethod.GET)@PrivilegeRequired(value = &#123;&quot;admin&quot;,&quot;menu_modify&quot;&#125;)public ModelAndView editZichanTypeDic(@PathVariable String id) &#123; ModelAndView result = new ModelAndView(); List&lt;Menu&gt; subMenus = menuService.findBySubMenu(); result.addObject(&quot;subMenus&quot;,subMenus); Menu menu = menuService.getById(id); if (menu == null) &#123; return new ModelAndView(&quot;datadic/menu/list&quot;); &#125; List&lt;Menu&gt; menus = menuService.findByParent(&quot;&quot;); result.setViewName(&quot;datadic/menu/edit&quot;); result.addObject(&quot;menu&quot;, menu); result.addObject(&quot;create&quot;, false); result.addObject(&quot;parentMenu&quot;, menus); return result;&#125;@RequestMapping(value = &quot;menu/create&quot;, method = RequestMethod.GET)@PrivilegeRequired(value = &#123;&quot;admin&quot;,&quot;menu_create&quot;&#125;)public ModelAndView createZichanTypeDic() &#123; ModelAndView result = new ModelAndView(); List&lt;Menu&gt; subMenus = menuService.findBySubMenu(); result.addObject(&quot;subMenus&quot;,subMenus); result.setViewName(&quot;datadic/menu/edit&quot;); Menu menu = new Menu(); List&lt;Menu&gt; menus = menuService.findByParent(&quot;&quot;); result.addObject(&quot;menu&quot;, menu); result.addObject(&quot;create&quot;, true); result.addObject(&quot;parentMenu&quot;, menus); return result;&#125;/** * @param pageSize * @param startIndex * @param sEcho * @return */@ApiOperation(value=&quot;菜单列表&quot;, notes=&quot;分页处理&quot;)@ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;iDisplayLength&quot;, value = &quot;每页条数&quot;, required = true, dataType = &quot;int&quot;), @ApiImplicitParam(name = &quot;iDisplayStart&quot;, value = &quot;起始数&quot;, required = true, dataType = &quot;int&quot;), @ApiImplicitParam(name = &quot;sEcho&quot;, value = &quot;&quot;, required = true, dataType = &quot;int&quot;)&#125;)@RequestMapping(value = &quot;menu/getData&quot;, method = RequestMethod.GET)@ResponseBody@PrivilegeRequired(value = &#123;&quot;admin&quot;,&quot;menu_detail&quot;&#125;)public TableData&lt;Menu&gt; getMenuData(@RequestParam(&quot;iDisplayLength&quot;) int pageSize, @RequestParam(&quot;iDisplayStart&quot;) int startIndex, @RequestParam(&quot;sEcho&quot;) int sEcho) &#123; Sort sort = new Sort(Sort.Direction.ASC, &quot;orderId&quot;); Pageable pageable = new PageRequest(startIndex / pageSize, pageSize, sort); PagedResult&lt;Menu&gt; pageableResult = menuService.list(pageable); return new TableData&lt;&gt;(pageableResult, sEcho + 1);&#125; 完成上述代码添加上，启动Spring Boot程序，访问：http://localhost:8080/swagger-ui.html。就能看到前文所展示的RESTful API的页面。我们也可以在此页面对接口进行测试。","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-Storm","date":"2017-06-27T02:17:54.000Z","path":"2017/06/27/Java架构师-Storm/","text":"Storm简介 Storm是Twitter开源的一个分布式的实时计算系统，用于数据的实时分析，持续计算，分布式RPC等等。 官网地址：http://storm-project.net/ 源码地址：https://github.com/nathanmarz/storm 实时计算需要解决的问题 最显而易见的就是实时推荐系统，比如我们在淘宝等电商购物网站去买东西，推荐的广告。Hadoop只是做离线的数据分析，无法做到实时分析计算。 车流量实时计算 股票 Hadoop与Storm对比 物理结构图 storm中运行的一个实时应用程序，因为各个组件间的消息流动形成逻辑上的一个拓扑结构。一个Topology（拓扑）是spouts和bolts组成的图，通过stream groupings将途中的sputs和bolts连接起来 Storm集群环境搭建 HelloWorld Topology不停，nextTuple会一直轮询 提交Topology命令：storm jar storm01.jar msj.topology.PWTTopology1 查看任务命令：storm list Storm API Topology（拓扑） Stream grouping（流分组、数据的分发方式） Spout（喷口、消息源） Bolt（螺栓、处理器） Worker（工作进程 jvm） Executor（执行器、Task的线程） Task（具体的执行任务） Configuration（配置） Strom拓扑配置 worker 对应jvm spout 对应线程池 拓扑是一个有向的计算（也就是在计算的过程中是有流向的去处理业务逻辑，节点之间的连接显示数据该如何进入下一个节点，他们是进行连接传递的） 拓扑运行只需要使用storm命令，把一个jar提交给nimbus节点，numbus就会把任务分配给具体的子节点（supervisor）去工作 Strom流分组Stream Grouping：为每个bolt指定应该接受哪个流作为输入，流分组定义了如何在bolt的任务直接进行分发。 Storm WordCount 对一段文字出现单词频率的个数的统计demo，分split，count，report三步 Storm Spout的可靠性Spout是Storm数据流的入口，在设计拓扑时，一件很重要的事情就是需要考虑消息的可靠性，如果消息不能被处理而丢失是很严重的问题。 通过示例：传递消息并且实时处理 来说明此问题。 Spout要implements IRichSpout，ack方法是成功回调，fail是失败回调，可以传递Tuple，从而重新发送 通过示例可知，如果在第一个bolt处理的时候出现异常，我们可以让整个数据进行重发，但是如果在第二个bolt处理的时候出现了异常，那么我们也会让响应的spout里的数据重发，这样就会出现事务的问题，我们就需要进行判断或者进行记录。 如果是数据入库的话，可以与原ID进行比对 如果是事务的话在编写代码时，尽量就不要进行拆分tuple 或者使用storm的Trident框架 架构设计考虑极端情况不包括代码问题或者可以通过代码改善的极端情况，可考虑断电等意外情况 Storm系统中有一组叫做“acker”的特殊的任务，他们负责跟踪DAG（有向无环图）中的每个消息 acker任务保存了spout消息id到一对值得映射。第一个值就是spout的任务id，通过这个id，acker就知道消息处理完成时该通知哪个spout任务。第二个值是一个64bit的数字，我们称之为“ack val”，它是树中所有消息的随机id的异或结果。ack val表示了整棵树的状态，无论这棵树多大，另需要这个固定大小的数字就可以跟踪整棵树。当消息被创建和被应答的时候都会有相同的消息id发送过来做异或。 每当acker发现一棵树的ack val值为0的时候，它就知道这棵树已经被完全处理了。因为消息的随机ID是一个64bit的值，因此ack val在树处理完之前被置为0的概率非常小。假设你每秒钟发送一万个消息，从概率上说，至少需要50000000年才会有机会发生一次错误。即使如此，也另有在这个消息确实处理失败的情况下才会有数据的丢失！ Storm异或运算：进入bolt时候记录一下tuple的id，bolt出来的时候记录一下tuple的id，这样相同的id就相抵掉 = 0，如果没抵掉就 != 0。 Storm DRPC 分布式RPC （distributed RPC,DRPC） Storm里面引入DRPC主要是利用storm的实时计算能力来并行化CPU密集型（CPU intensive）的计算任务。DRPC的storm topology以函数的参数流作为输入，而把这些函数调用的返回值作为topology的输出流。 DRPC其实不能算是storm本身的一个特性，它是通过组合storm的原语stream、spout、bolt、topology而成的一种模式（pattern）。本来应该把DRPC单独打成一个包的，但是DRPC实在是太有用了，所以我们把它和storm捆绑在一起。 DRPC 是通过一个“DRPC Server”来实现 DRPC Server的整体工作流程如下： 接收一个RPC请求 发送请求到storm topology 从storm topology接收结果 把结果发回给等待的客户端 Storm DRPC配置和示例 Storm提供了一个称作LinearDRPCTopologyBuilder的topology builder，它把实现DRPC的几乎所有步骤都自简化了。 相关代码地址：https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/BasicDRPCTopology.java 实现DRPC步骤： 需要修改配置文件内容为（分别修改每台机器配置）： vim /usr/local/apache-storm-0.9.2/conf/storm.yaml drpc.servers: - “192.168.1.114” 需要启动storm的drpc服务，命令：storm drpc &amp; 把相应的topology代码上传到storm服务器上 1storm jar storm04.jar msj.drpc.BasicDRPCTopology exc storm04.jar 在本地调用远程topology即可 Storm DRPC示例场景 主要使用storm的并行计算能力来进行，我们在微博、论坛进行转发帖子的时候，是对url进行转发，分析给粉丝（关注我的人），那么每一个人的粉丝（关注着可能会有重复的情况），这个例子就是统计一下帖子（url）的转发人数。 相关代码地址：https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/ReachTopology.java 示例地址：DrpcReach 实现步骤如下： 获取当前转发帖子的人 获取当前人的粉丝（关注者） 进行粉丝去重 统计人数 最后使用drpc远程调用topology返回执行结果 kafka作为数据源，storm进行数据处理，来分析日志。Storm和Kafka配合比较好 Storm Trident 基本使用使用示例：TridentFunction Function:继承BaseFunction 1234567891011121314151617181920212223242526272829//继承BaseFunction类，重新execute方法 public static class SumFunction extends BaseFunction &#123; @Override public void execute(TridentTuple tuple, TridentCollector collector) &#123; System.out.println(\"传入进来的内容为：\" + tuple); //获取a、b俩个域 int a = tuple.getInteger(0); int b = tuple.getInteger(1); int sum = a + b; //发射数据 collector.emit(new Values(sum)); &#125; &#125; //继承BaseFunction类，重新execute方法 public static class Result extends BaseFunction &#123; @Override public void execute(TridentTuple tuple, TridentCollector collector) &#123; //获取tuple输入内容 System.out.println(); Integer a = tuple.getIntegerByField(\"a\"); Integer b = tuple.getIntegerByField(\"b\"); Integer c = tuple.getIntegerByField(\"c\"); Integer d = tuple.getIntegerByField(\"d\"); System.out.println(\"a: \"+ a + \", b: \" + b + \", c: \" + c + \", d: \" + d); Integer sum = tuple.getIntegerByField(\"sum\"); System.out.println(\"sum: \"+ sum); &#125; &#125; build Topology 123456789101112131415161718192021222324252627282930TridentTopology topology = new TridentTopology(); //设定数据源 FixedBatchSpout spout = new FixedBatchSpout( new Fields(\"a\", \"b\", \"c\", \"d\"), //声明输入的域字段为\"a\"、\"b\"、\"c\"、\"d\" 4, //设置批处理大小为1 //设置数据源内容 //测试数据 new Values(1, 4, 7, 10), new Values(1, 1, 3, 11), new Values(2, 2, 7, 1), new Values(2, 5, 7, 2)); //指定是否循环 spout.setCycle(false); //指定输入源spout Stream inputStream = topology.newStream(\"spout\", spout); /** * 要实现流sqout - bolt的模式 在trident里是使用each来做的 * each方法参数： * 1.输入数据源参数名称：\"a\", \"b\", \"c\", \"d\" * 2.需要流转执行的function对象（也就是bolt对象）：new SumFunction() * 3.指定function对象里的输出参数名称：sum */ inputStream.each(new Fields(\"a\", \"b\", \"c\", \"d\"), new SumFunction(), new Fields(\"sum\")) /** * 继续使用each调用下一个function（bolt） * 第一个输入参数为：\"a\", \"b\", \"c\", \"d\", \"sum\" * 第二个参数为：new Result() 也就是执行函数，第三个参数为没有输出 */ .each(new Fields(\"a\", \"b\", \"c\", \"d\", \"sum\"), new Result(), new Fields()); return topology.build(); //利用这种方式，我们返回一个StormTopology对象，进行提交 过滤过滤示例：[TridentFilter](https://github.com/CentMeng/JavaFrameTest/tree/master/src/com/msj/storm/trident/example/TridentFilter.java） Filter:继承BaseFilter 123456789101112//继承BaseFilter类，重新isKeep方法 public static class CheckFilter extends BaseFilter &#123; @Override public boolean isKeep(TridentTuple tuple) &#123; int a = tuple.getInteger(0); int b = tuple.getInteger(1); if((a + b) % 2 == 0)&#123; return true; &#125; return false; &#125; &#125; build Topology 12345678910111213141516171819202122232425TridentTopology topology = new TridentTopology(); //设定数据源 FixedBatchSpout spout = new FixedBatchSpout( new Fields(\"a\", \"b\", \"c\", \"d\"), //声明输入的域字段为\"a\"、\"b\"、\"c\"、\"d\" 4, //设置批处理大小为1 //设置数据源内容 //测试数据 new Values(1, 4, 7, 10), new Values(1, 1, 3, 11), new Values(2, 2, 7, 1), new Values(2, 5, 7, 2)); //指定是否循环 spout.setCycle(false); //指定输入源spout Stream inputStream = topology.newStream(\"spout\", spout); /** * 要实现流sqout - bolt的模式 在trident里是使用each来做的 * each方法参数： * 1.输入数据源参数名称：subjects * 2.需要流转执行的function对象（也就是bolt对象）：new Split() */ inputStream.each(new Fields(\"a\", \"b\", \"c\", \"d\"), new CheckFilter()) //继续使用each调用下一个function（bolt）输入参数为subject和count，第二个参数为new Result() 也就是执行函数，第三个参数为没有输出 .each(new Fields(\"a\", \"b\", \"c\", \"d\"), new Result(), new Fields()); return topology.build(); //利用这种方式，我们返回一个StormTopology对象，进行提交 分组参考Learning Storm 第104页 示例：StrategyTopology Trident aggregators参考Learning Storm 第109页 The partition aggregate The aggregate The persistence aggregate 示例：WordCountTopology Batch和Spout与TranscationalTrident提供下面的语义来实现有且又一次被处理的目标（不出现重复，保持事务性） Tuples是被分成小的集合（一组tuple被称为一个batch）被批处理的 每一批tuples被给定一个唯一ID作为事务ID（txid），当这个batch被重发时，txid不变 batch和batch之间的状态更新是严格顺序的。比如batch3的状态的更新必须要等到batch2的状态更新成功之后才可以进行 有了这些定义，状态实现可以检测到当前batch是否以前处理过，并根据不同的情况进行不同的处理，这个处理取决于你的输入spout。有三种不同类型的容错spout： non-transactional（无事务支持的spout） transactional（事务支持spout） opaque transactional（不透明事务支持的spout） 示例来源Learning Storm 的126页 透明事务 不透明事务（比较难理解） 如果处理不成功，可以还原回来 透明事务，是只要这一批错误就将这一批数据重发 接口 实现ITridentSpout接口 最通用的API可以支持transactional or opaque transactional语义 实现IBatchSpout接口 一个non-transactional spout 实现IPartitional TridentSpout接口 一个transactional spout 实现IOpaquePartitionedTridentSpout接口 一个opaque transactional spout Storm与KafKa Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消费。 Kafka相关术语介绍 Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处） Partition：Partition是物理上的概念，每个Topic包含一个或多个Partition. Producer：负责发布消息到Kafka broker Consumer：消息消费者，向Kafka broker读取消息的客户端。 Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。 Kafka安装与使用 kafka下载地址：http://kafka.apache.org/downloads.html 解压命令：tar zxvf kafka_2.10-0.9.0.1.tgz -C /usr/local 改名命令：mv kafka_2.10-0.9.0.1/ kafka 进入解压后的目录，修改server.properties文件： 1vim /usr/local/kafka/config/server.properties 修改内容： 1broker.id=0 port=9092 host.name=192.168.1.114 advertised.host.name=192.168.1.114 log.dirs=/usr/local/kafka/kafka-logs num.partitions=2 zookeeper.connect=192.168.1.114:2181,192.168.1.115:2181,192.168.1.116:2181 建立日志文件夹：mkdir /usr/local/kafka/kafka-logs 启动kafka：/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties &amp; KafKaManager安装 下载kafka-manager-1.0-SNAPSHOT.zip 解压：unzip kafka-manager-1.0-SNAPSHOT.zip -d /usr/local/ 改名：mv kafka-manager-1.0-SNAPSHOT/ kafka-manager-1.0 编辑文件：vim /usr/local/kafka-manager-1.0/conf/application.conf 修改内容 1kafka-manager.zkhosts=&quot;192.168.1.114:2181,192.168.1.115:2181,192.168.1.116:2181&quot; 启动kafka-manager：nohup /usr/local/kafka-manager-1.0/bin/kafka-manager -Dconfig.file=/usr/local/kafka-manager-1.0/conf/application.conf &gt;/dev/null 2&gt;&amp;1 &amp; 默认端口为：9000 Kafka操作 操作kafka建立topic 1cd /usr/local/kafka/bin 创建topic主题命令：kafka-create-topic.sh –replica 1 –partition 1 –topic（创建名为test的topic， 1个分区分别存放数据，数据备份总共1份） 查看topic列表命令：kafka-topics.sh –zookeeper 192.168.1.114:2181 –list kafka命令发送数据：kafka-console-producer.sh –broker-list 192.168.1.114 –topic test然后我们就可以编写数据发送出去了 kafka命令接受数据：kafka-console-consumer.sh –zookeeper 192.168.1.114 –topic test –from-beginning然后我们就可以看到消费的信息了 示例KafkaTopology Kafka示例：Kafka Redis使用 Redis存储作为一个Spout RedisTopology","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-solr","date":"2017-06-27T02:14:35.000Z","path":"2017/06/27/Java架构师-solr/","text":"Solr技术简介 Solr基于Lucene的全文搜索服务器。Solr提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展，并对索引、搜索性能进行了优化。 为什么使用Solr 单独使用Lucene实现站内搜索需要开发的工作量较大，主要表现在：索引维护、索引性能优化、搜索性能优化等，因此不建议使用 通过第三方搜索引擎提供的接口实现站内搜索，这样和第三方引擎系统以来紧密，不方便扩展，不建议使用 基于Solr实现站内搜索扩展性较好并且可以减少程序员的工作量，因为Solr提供了较为完备的搜索引擎解决方案，因此在门户、论坛等系统中常用此方案。 Solr可以独立运行，运行在Jetty、Tomcat等这些Servlet容器中，Solr索引的实现方法很简单，用POST方法向Solr服务器发送一个描述Field及其内容的XML文档，Solr根据xml文档添加、删除、更新索引。Solr搜索只需要发送HTTP GET请求，然后对Solr返回Xml、json等格式的查询结果进行解析，组织页面布局。Solr不提供构建UI的功能，Solr提供了一个管理页面，通过管理页面可以查询Solr的配置和运行情况。 Solr 下载与安装下载地址:http://www.apache.org/dyn/closer.lua/lucene/solr 安装步骤 Solr操作 搜索引擎全文检索步骤 信息源-&gt;本地即solr（进行加工和处理）-&gt;建立索引库（信息集合，一组文件的集合） 搜索的时候从本地的（索引库）信息集合中搜索 文本在建立索引和搜索时，都会先进行分词（使用分词器） 索引的结构： 索引表（存放具体的词汇，哪些词汇在哪些文档里存储，索引里存储的就是分词器分词之后的结果） 存放数据（文档信息集合） 用户搜索时：首先经过分词器进行分词，然后去索引表里查找对应的词汇（利用倒排序索引），再找到对应的文档集合。 索引库位置（Directory） 信息集合里的每一条数据都是一个document（存储所有信息，他是一个Filed属性的集合） store是否进行存储（可以不存储，也可以存储） index是否进行存储（可以不索引，也可以索引，索引的话分为分词后索引，或者直接索引） 添加中文分词器 无论是Solr还是Lucene，都对中文分词不太好，所以我们一般索引中文的话需要使用IK中文分词器 下载IK Analyzer 2012FF_hf1.zip 进行解压 安装：把IKAnalyzer2012FF_u1.jar拷贝到tomcat的solr应用服务下 cd /usr/local/software &amp;&amp; cp IKAnalyzer2012FF_u1.jar /usr/local/apache-tomcat-7.0.29/webapps/solr/WEB-INF/lib/ 创建文件夹：/usr/local/apache-tomcat-7.0.29/webapps/solr/WEB-INF/classes 把IKAnalyzer.cfg.xml和stopword.dic拷贝到新创建的classes目录下即可 修改solr core的schema文件，默认是位置 vim /usr/local/solr-4.10.3/example/solr/collection1/conf/schema.xml 添加如下配置： 123456&lt;fieldType name=\"text_ik\" class=\"solr.TextField\"&gt;&lt;!-- 索引时候的分词器--&gt;&lt;analyzer type=\"index\" isMaxWordLength=\"false\" class=\"org.wltea.analyzer.lucenne.IKAnalyzer\" /&gt;&lt;!-- 查询时候的分词器--&gt;&lt;analyzer type=\"query\" isMaxWordLength=\"true\" class=\"org.wltea.analyzer.lucenne.IKAnalyzer\" /&gt;&lt;/fieldType&gt; 启动solr：/usr/local/apache-tomcat-7.0.2/bin/startup.sh 进入页面在分词器选择ik中文分词器，进行输入：互联网应用架构。 自定义词库 修改 /usr/local/apache-tomcat-7.0.29/webapps/solr/WEB-INF/classes/IKAnalyzer.cfg.xml目录下的IKAnalyzer.cfg.xml配置文件，添加如下配置 1234&lt;!--使用的分词,一个词一行--&gt;&lt;entry key=\"ext_dict\"&gt;ext.dic;&lt;/entry&gt;&lt;!--进制使用的分词--&gt;&lt;entry key=\"ext_stopwords\"&gt;stopword.dic;&lt;/entry&gt; 新建ext.dic文件，在里面添加内容（注意：ext.dic的编码必须是Encode in UTF-8 without BOM，否则自定义的词库不会被识别） Solr基础Solr索引操作 Solr搜索 Solr模式 Solr添加信息对象 Solr查询详细使用 查询分页start（起始位置）、rows（数据条数）、sort（排序） 查询操作拼接：可使用AND、OR、NOT进行拼接联合查询 查询操作区间：“price:[5 TO 10]”表示包含，“price:{5 TO 10}”为不包含5到10的数据 查询操作过滤器：addFilterQuery提高查询效率 查询操作开启高亮设置：setHighlight*等方法，可以高亮显示结果信息 查询操作分片处理：可以进行统计分析单词出现次数 ## Solor管理员命令两种手段 直接使用curl命令进行操作solr数据：如 删除：curl http://localhost:8080/solr/update –data-binary”id:1“ -H ‘Content-type:text/xml;charset=utf-8’ 提交：curl http://localhost:8080/solr/update –data-binary”“ -H ‘Content-type:text/xml;charset=utf=8’ 进入：/usr/local/solr-4.10.3/example/exampledocs 下执行java -jar post.jar命令进行维护数据操作 删除：java -Ddata=args -jar post.jar”42“ 帮助：java -jar post.jar -help Solr集群搭建 与Zookeeper做协调 Solr实例 Solr有全量同步和增量同步两种 Solr的DIH 全量同步 第七步：Solr服务器的时间要和mysql服务器的时间统一 Solr的DIH增量同步 通过last_modify字段做判断是否更新，即根据时间来确定","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-ZooKeeper","date":"2017-05-11T05:02:39.000Z","path":"2017/05/11/Java架构师-ZooKeeper/","text":"Zookeeper简介说明什么是Zookeeper？Zookeeper是一个高效的分布式协调服务，它暴露了一些公共服务，比如命名/配置管理/同步控制/群组服务等。我们可以使用ZK来实现比如达成共识/集群管理/leader选举（选举通过PAXOS算法）等。 Zookeeper是一个高可用的分布式管理与协调框架，基于ZAB算法（原子消息广播协议）的实现。该框架能够很好地保证分布环境中数据的一致性。也正是基于这样的特性，使得Zookeeper成为了解决分布式一致性的问题的利器。 顺序一致性：从一个客户端发起的事务请求，最终将会严格地按照其发起的顺序被应用到zookeeper中去。原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群所有的机器都成功应用了某一事务，要么都没有应用，一定不会出现部分机器应用了该事务，而另一部分没有应用的情况（一个Leader节点，两个F节点，当对F1做修改数据操作，Consumer是无法对两个F节点和Leader节点做修改，只有当F1操作完毕并且同步给Leader和F2之后，Consumer才可以做操作）。单一视图：无论客户端连接的是哪一个zookeeper服务器，其看到的服务器端数据模型都是一致的。可靠性：一旦服务器成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务器端状态将会被一致保留下来。除非有另外一个事务对其更改。实时性：通常所说的实时性就是指一旦事务被成功应用，那么客户端就能立刻从服务器上获取变更后的新数据，zookeeper仅仅能保证在一段时间内，客户端最终一定能从服务器端读取最新的数据状态。 Zookeeper设计目标 目标1：简单的数据结构。Zookeeper就是以简单的树形结构来进行相互协调的（也叫树形名字空间）。 目标2：可以构建集群。一般Zookeeper集群通常由一组机器构成，一般3~5台机器就可以组成一个Zookeeper集群。只要集群中超过半数以上的机器能够正常工作，那么整个集群就能正常对外提供服务。 目标3：顺序访问。对于来自每一个客户端的每一个请求，Zookeeper都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序，应用程序可以使用Zookeeper的这个特性来实现更高层次的同步。 目标4：高性能。由于Zookeeper将全量数据存储在内存中，并直接服务于所有的非事务请求，因此尤其是在读操作为主的场景下性能非常突出。在JMater压力测试下(100%读请求场景下)，其结果大约在12-13w的QPS(每秒查询率)。 Zookeeper的结构 Zookeeper会维护一个具有层次关系的数据结构，它非常类似于一个标准的文件系统。 Zookeeper的数据模型 每个子目录项如NameService都被称作为znode，这个znode是被它所在的路径唯一标识，如Server1这个znode的标识为/NameService/Service1。 znode可以有子节点目录，并且每个znode可以存储数据，注意EPHEMERAL类型的目录节点不能有子节点目录。 znode是有版本的，每个znode中存储的数据可以有多个版本，也就是一个访问路径中可以存储多份数据。 znode可以是临时节点，一旦创建这个znode的客户端与服务器失去联系，这个znode也将自动删除，Zookeeper的客户端和服务器通信采用长连接方式，每个客户端和服务器通过心跳来保持连接，这个连接状态称为session，如果znode是临时节点，这个session失效，znode也就删除了。 znode的目录名可以自动编号，如App1已经存在，再创建的话，将会自动命名为App2。 znode可以被监控，包括这个目录节点中存储的数据的修改，子节点目录的变化等，一旦变化可以通知设置监控的客户端，这个是Zookeeper的核心特性，Zookeeper的很多功能都是基于这个特性实现的，后面再典型的应用场景中会有实例介绍。 Zookeeper组成ZK server根据其身份特性分为三种 leader，Follower，Observer，其中Follower和Observer又统称Learner（学习者）。 Leader：负责客户端的writer类型请求 Follower：负责客户端的reader类型请求，参与leader选举等。 Observer：特殊的”Follower”，其可以接受客户端reader请求，但不参与选举。（扩容系统支撑能力，提高了读取速度。因为它不接受任何同步的写入请求，只负责与leader同步数据） 应用场景 Zookeeper从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper就将负责同志已经在Zookeeper上注册的那些观察者做出相应的反应，从而实现集群中类似Master/Slave管理模式。 配置管理:配置的管理在分布式应用环境中很常见，比如我们在平常的应用系统中，经常会碰到这样的需求：如机器的配置列表、运行时的开关配置、数据库配置信息等。这些全局配置信息通畅具备以下3个特性： 数据量比较小 数据内容在运行时动态发生变化 集群中各个节点共享信息，配置一致 集群管理：Zookeeper不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个”总管“，让这个总管来管理集群，这就是Zookeeper的另一个功能Leader，并实现集群容错功能。 希望知道当前集群中究竟有多少机器工作 对集群中每天集群的运行时状态进行数据收集 对集群中每台集群进行上下线操作 发布与订阅：Zookeeper是一个典型的发布/订阅模式的分布式数控管理与协调框架，开发人员可以使用它来进行分布式数据的发布与订阅。 数据库切换：比如我们初始化Zookeeper的时候读取其节点上的数据库配置文件，当配置一旦发生变更时，Zookeeper就能帮助我们把变更的通知发送到各个客户端，每个客户端在接收到这个变更通知后，就可以重新进行最新数据的获取。 分布式日志的收集：我们可以做一个日志系统收集集群中所有的日志信息，进行统一管理。 分布式锁、队列管理等等。Zookeeper的特性就是在分布式场景下高可用，但是原生的API实现分布式功能非常困难，团队去实现也太浪费时间，即使实现了也未必稳定。那么可以采用第三方的客户端的完美实现，比如Curator框架，他是Apache的定级项目。 ZAB和Paxos算法搭建Zookeeper与配置文件说明结构：一共三个节点(zk服务器集群规模不小于3个节点),要求服务器之间系统时间保持一致，搭建时候集群规模是奇数即3，5，7。 上传zk 进行解压： tar zookeeper-3.4.5.tar.gz 重命名： mv zookeeper-3.4.5 zookeeper 修改环境变量： vi /etc/profile 1export ZOOKEEPER_HOME=/usr/local/zookeeper export PATH=.:$HADOOP_HOME/bin:$ZOOKEEPER_HOME/bin:$JAVA_HOME/... 刷新： source /etc/profile 到zookeeper下修改配置文件 1cd /usr/local/zookeeper/conf mv zoo_sample.cfg zoo.cfg 修改conf: vi zoo.cfg 修改两处 （1）dataDir=/usr/local/zookeeper/data （2）最后面添加 1server.0=msj（ip可以用192.168.1.121替换）:2888:3888 server.1=hadoop1:2888:3888 server.2=hadoop2:2888:3888 服务器标识配置： 创建文件夹：mkdir data 创建文件myid并填写内容为0：vimyid (内容为服务器标识 ： 0) server.0 写0，server.1写1，server.2写2 进行复制zookeeper目录到hadoop01和hadoop02还有/etc/profile文件 把hadoop01、hadoop02中的myid文件里的值修改为1和2路径(vi /usr/local/zookeeper/data/myid) 启动zookeeper： 路径：/usr/local/zookeeper/bin 执行：zkServer.sh start(注意这里3台机器都要进行启动) 状态：zkServer.sh status(在三个节点上检验zk的mode,一个leader和俩个follower) 操作zookeeper (shell) 可以使用工具进行管理ZooInspector zkCli.sh 进入zookeeper客户端 根据提示命令进行操作： 查找：ls / ls /zookeeper 创建并赋值：create /msj hadoop 获取：get /msj 设值：set /msj mengshaojie 可以看到zookeeper集群的数据一致性 创建节点有俩种类型：短暂（ephemeral）、持久（persistent）zoo.cfg详解： tickTime： 基本事件单元，以毫秒为单位。这个时间是作为 Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每隔 tickTime时间就会发送一个心跳。 dataDir：存储内存中数据库快照的位置，顾名思义就是 Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。 clientPort： 这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper会监听这个端口，接受客户端的访问请求。 initLimit： 这个配置项是用来配置 Zookeeper接受客户端初始化连接时最长能忍受多少个心跳时间间隔数，当已经超过 10 个心跳的时间（也就是 tickTime）长度后Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是10*2000=20 秒。 syncLimit： 这个配置项标识 Leader 与 Follower之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime的时间长度，总的时间长度就是 5*2000=10 秒 server.A = B:C:D : A表示这个是第几号服务器, B 是这个服务器的 ip 地址； C 表示的是这个服务器与集群中的 Leader服务器交换信息的端口； D 表示的是万一集群中的 Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader java操作Zookeeper Zookeeper的官方API并不太好用，建议使用Curator 同步创建时创建过程中进行阻塞，异步则创建时候后续代码继续执行 delete时候版本号，是做检查，如果不是同一个版本，就不删除了。-1是跳过检查 get时候只支持获取一层（假如/test下面有/test/a1、/test/a2、/test/a3，a1中有b1,则/test的getChildren方法只能获取a1,a2,a3不能获取b1） 在ZK中，只允许删除叶子节点信息，也就是说如果当前节点不是叶子节点则无法删除，或必须先删除其下所有子节点 连接、创建、修改、删除ZooKeeper 原生API不允许递归创建/删除节点（即没有父节点，直接路径创建子节点），但Curator有API支持 ZooKeeper不支持序列化对象，但可以使用Kryo框架实现 exists方法意义在于无论节点是否存在，都可以进行注册watcher，能够对节点的创建、删除和修改进行监听，但是其子节点发送各种变化，都不回通知客户端。 关于参数watcher 的boolean值，因为watcher的监控是一次性的，如果继续使用watcher则传true，关于参数watcher对象，如果使用新的watcher则传入新watcher。 Watcher、ZK状态、事件类型 示例：ZooKeeper Watcher zookeeper有watch操作，是一次性触发的，当watch监视的数据发生变化时，通知设置了该watch的client，即watcher。 同样，其watcher是监听数据发生了某些变化，那就一定会有对应的事件类型，和状态类型。 事件类型：（znode节点相关的） EventType.NodeCreated EventType.NodeDataChanged EventType.NodeChildrenChanged EventType.NodeDeleted 状态类型：（是跟客户端实例相关的） KeeperState.Disconnected KeeperState.SyncConnected KeeperState.AuthFailed KeeperState.Expired watcher的特性：一次性、客户端串行执行、轻量 一次性：对于ZK的watcher，你只需要记住一点:zookeeper有watch事件，是一次性触发的，当watch监视的数据发生变化时，通知设置了该watch的client，即watcher，由于zookeeper的监控都是一次性的所以每次必须设置监控。 客户端串行执行：客户端watcher回调的过程是一个串行同步的过程，这为我们保证了顺序，同时需要开发人员注意一点，千万不要因为一个Watcher的处理逻辑影响了整个客户端的Watcher回调。 轻量：WatchedEvent是ZK整个Watcher通知机制的最小通知单元，整个结构只包含三部分：通知状态、时间类型和节点路径。也就是Watcher通知非常的简单，只会告诉客户端发生了事件而不会告知其具体内容，需要客户自己去进行获取，比如NodeDataChanged事件，ZK只会通知客户端指定节点的数据发生了变更，而不会直接提供具体的数据内容。 ZooKeeper的ACL（AUTH） 示例：ZooKeeperAuth 应用场景实例ZooKeeper分布式锁实现 利用临时节点来实现分布式锁，因为临时节点效率高。ZooKeeper存在内存中，get效率很高 ZooKeeper创建的时候如果已经创建会抛异常，所以创建的时候也要如果时间过长，可能出现抛异常情况 ZooKeeper实现多个Client端使用同一个文件 示例：ZKWatcher zkClient客户端ZKClient是由Datameer的工程师StefanGroschupf和Peter voss一起开发的。在原生API接口基础上进行了封装，简化了ZK的复杂性。 示例：ZKClientBase 创建客户端方法：ZKClient（Arguments） 参数1：zkServers zookeeper服务器的地址，用”，“隔开 参数2：session Timeout 超时会话，为毫秒，默认为30000ms 参数3：connection Timeout 连接超时会话 参数4：IZKConnection 接口的实现类 参数5：zkSerializer 自定义序列化实现 创建节点方法create、createEphemeral、createEphemeralSequential、createPersistent、createPersistentSequential 参数1：path 路径 参数2：data 数据内容，可以传null 参数3：mode，节点类型，为一个枚举类型，4种形式 参数4：acl策略 参数5：callback 回调函数 参数6：context上下文对象 参数7：createParents 是否创建父节点 删除节点方法delete、deleteRecursive读取子节点数据方法：getChildren读取节点数据方法：readData 参数1：path路径 参数2：returnNullIfPathNotExists（避免为空节点抛出异常，直接返回null） 参数3：节点状态 更新数据方法writeData检查节点是否存在方法existssubscribeChildChanges方法（watcher） ZKClient并没有类似watcher、watch参数，这也就是说我们开发人员无需关心反复注册Watcher的问题，ZKClient给我们提供了一套监听方式，我们可以使用监听节点的方式进行操作，剔除了繁琐的watcher操作，简化了代码的复杂程度。 示例：ZkClientWatcher1 参数1：path路径 参数2：实现了IZKChildListener接口的类（如：实例化IZKChildListener类）只需要重写其handleChildChangs（Sting parentPath，List currentChilds）方法。其中参数parentPath为所监听节点全路径，currentChilds为最新的子节点列表（相对路径）。 IZKChildListener事件针对于下面三个事件触发：（数据变更有DataChange的API） 新增子节点 减少子节点 删除节点 subscribeDataChanges方法 监控数据变更的api 方便性 ZKClient支持地柜创建/删除 读写可以直接传Object对象 Curator框架 Curator框架已经是Apache的顶级项目，里面提供了更多丰富的操作，例如session超时重连、主从选举、分布式计算器、分布式锁等等适用于各种复杂的zookeeper场景的API封装。 maven依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactld&gt;curator-framework&lt;/artifactld&gt; &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt; Curator框架的使用Curator框架中使用链式编程风格，易读性更强，使用工程方法创建连接对象。 示例：curator 1.使用CuratorFrameworkFactory的两个静态工厂方法（参数不同）来实现： 参数1：connectString，连接串 参数2：retryPolicy，重试连接策略。有四种实现分别为：ExponentialBackoffRetry、RetryNTimes、RetryOneTimes、RetryUntilElapsed 参数3：sessionTimeoutMs 会话超时时间，默认为60000ms 参数4：connectionTimeoutMs 连接超时时间，默认为15000ms 注意：对于retryPolicy策略通过一个接口来让用户自定义实现 2.创建节点create方法，可选链式项：creatingParentsIfNeeded、withMode、forPath、withACL等 3.删除节点delete方法，可选链式项：deletingChildrenIfNeeded、guaranteed、withVersion、forPath等等 4.读取和修改数据getData、setData方法5.异步绑定回调方法。比如创建节点时绑定一个回调函数，该回调函数可以输出服务器的状态码以及服务器事件类型。还可以加入一个线程池进行优化操作。 如果大规模或者频繁对节点做操作的话，使用线程池 6.读取子节点方法getChildren7.判断节点是否存在方法checkExistsCurator监听 如果要使用类似Watcher的监听功能Curator必须依赖一个jar包，Maven依赖： 12345&lt;dependency&gt;&lt;groupId&gt;&lt;/groupId&gt;&lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;&lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt; 有了这个依赖包，我们使用NodeCache的方式去客户端实例中注册一个监听缓存，然后实现对应的监听方法即可，这里我们主要有两种监听方式： NodeCacheListener：监听节点的新增、修改操作 PathChildrenCacheListener：监听子节点（一级节点）的新增、修改、删除操作 ZKClient也免去了重复注册的代码，但他底层还是重复注册的代码封装，而Curator是通过在Client端增加Cache，如果服务端有变更，则拿cache做对比，有变化重新覆盖cache。 Curator场景应用分布式锁功能 在分布式场景中，我们为了保证数据的一致性，经常在程序运行的某一个点需要进行同步操作（java可提供synchronized或者Reentrantlock实现）比如我们看一个小示例，这个示例会出现分布式不同步的问题：因为我们之前所说的是在高并发下访问一个程序，现在我们则是在高并发下访问多个服务器节点（分布式）。我们使用Curator基于ZK的特性提供的分布式锁来处理分布式场景的数据一致性，ZK本身的分布式是有写问题的，我以前在实现的时候遇到过。。。这里强烈推荐使用Curator的分布式锁。 示例：lock2 分布式计数器功能 一说到分布式计数器，你可能脑海里想到了AtomicInteger这种经典的方式，如果针对于一个jvm的场景当然没有问题，但是我们现在是分布式场景下，就需要利用Curator框架的DistributeAtomicInteger了。 示例：CuratorAtomicInteger 分布式Barrier使用 设置同时开始同时结束；类似CountDownLatch 示例：CuratorBarrier 分布式数据共享 ZooKeeper文件做修改，Client端会接收到通知 示例：cluster","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-Dubbo","date":"2017-05-11T04:58:49.000Z","path":"2017/05/11/Java架构师-Dubbo/","text":"Dubbo Dubbo是一个被国内很多互联网公司广泛使用的开源分布式服务框架，即使从国际视野来看应该也是一个非常全面的SOA基础框架。作为一个重要的技术研究课题，当当网根据自身的需求，为Dubbo实现了一些新的功能，并将其命名为Dubbox（即Dubbo eXtensions） Dubbo简介Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的冻冻，说白了就是个远程服务调用的分布式框架（告别Web Service模式中的WSdl，以服务者与消费者的方式在dubbo上注册） 其核心部分包含： 远程通讯：提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 集群容错：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 自动发现：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 Dubbo的用途 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 服务自动注册与实现，不在需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。 Dubbo用户指南 Dubbo架构 HelloWorldsample-provider.xml12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;!-- 具体的实现bean --&gt; &lt;bean id=\"sampleService\" class=\"msj.dubbo.sample.provider.impl.SampleServiceImpl\" /&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"sample-provider\" /&gt; &lt;!-- 使用zookeeper注册中心暴露服务地址 --&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;!-- 声明需要暴露的服务接口 写操作可以设置retries=0 避免重复调用SOA服务 --&gt; &lt;dubbo:service retries=\"0\" interface=\"msj.dubbo.sample.provider.SampleService\" ref=\"sampleService\" /&gt;&lt;/beans&gt; sample-consumer.xml12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt; &lt;dubbo:application name=\"sample-consumer\" /&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 生成远程服务代理，可以像使用本地bean一样使用demoService 检查级联依赖关系 默认为true 当有依赖服务的时候，需要根据需求进行设置 --&gt; &lt;dubbo:reference id=\"sampleService\" check=\"false\" interface=\"msj.dubbo.sample.provider.SampleService\" /&gt;&lt;/beans&gt; 管控台 dubbo-admin-xxx.war 放到tomcat的webapp中 dubbo.properties 修改注册中心（zookeeper）和登录密码 dubbo管控台版本必须要与dubbo版本对应 使用demo一个服务依赖另一个服务Provider1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;dubbo:annotation package=\"bhz\" /&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"dependency-provider\" /&gt; &lt;!-- 使用zookeeper注册中心暴露服务地址 --&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20890\" /&gt; &lt;!-- 注意这里，我们在使用DependencyService的时候，这个服务可能需要依赖某一个服务，比如SampleService 检查级联依赖关系 默认为true 当有依赖服务的时候，需要根据需求进行设置 --&gt; &lt;dubbo:reference id=\"sampleService\" check=\"true\" interface=\"msj.dubbo.sample.provider.SampleService\" /&gt; Consumer12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt; &lt;dubbo:application name=\"dependency-consumer\" /&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 生成远程服务代理，可以像使用本地bean一样使用demoService 检查级联依赖关系 默认为true 当有依赖服务的时候，需要根据需求进行设置 --&gt; &lt;dubbo:reference id=\"dependencyService\" interface=\"msj.dubbo.dependency.provider.DependencyService\" /&gt;&lt;/beans&gt; 直连提供者 不经过注册中心（zookeeper），直接点对点 Provider12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;!-- 具体的实现bean --&gt; &lt;bean id=\"directService\" class=\"bhz.dubbo.direct.provider.impl.DirectServiceImpl\" /&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"direct-provider\" /&gt; &lt;!-- 使用zookeeper注册中心暴露服务地址 只订阅的方式：register=\"false\"--&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;!-- 直连配置特殊点： 直连服务提供者：是在消费端进行配置的，而不是在服务提供端，所以这里不需要任何配置 --&gt; &lt;dubbo:service retries=\"0\" interface=\"msj.dubbo.direct.provider.DirectService\" ref=\"directService\" /&gt;&lt;/beans&gt; Consumer1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd \"&gt; &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt; &lt;dubbo:application name=\"direct-consumer\" /&gt; &lt;dubbo:registry address=\"zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181\" /&gt; &lt;!-- 直连提供者配置，在这里（也就是消费端进行配置） url=\"\" --&gt; &lt;dubbo:reference id=\"directService\" check=\"false\" url=\"dubbo://localhost:20880\" interface=\"msj.dubbo.direct.provider.DirectService\" /&gt;&lt;/beans&gt; 属性说明启动时检查集群配置负载均衡 一般情况下不会将负载均衡配置到dubbo上，可以在控制台修改 轮询方式如果一个节点出现问题，那么所有轮询到这个节点的请求都会积压线程模型 配置说明重点配置 version retries connections(当前service对每个提供者的最大连接数) token async （consumer调用provider，是阻塞还是异步直接返回，异步方式不太好，默认是false） weight（权重） executes 生产者： threadpool 消费者： actives","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-RocketMQ","date":"2017-04-17T14:09:42.000Z","path":"2017/04/17/Java架构师-RocketMQ/","text":"RocketMQ概述 推荐博客：http://www.jianshu.com/p/453c6e7ff81c RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 Metaq3.0版本改名，产品名称改为RocketMQ(1.0，2.0之前是用zookeeper，3.0使用namesrv) 选用理由 强调集群无单点，可扩展，任意一点高可用，水平可扩展 海量消息堆积能力，消息堆积后，写入低延迟 支持上万个队列 消息失败重试机制 消息可查询 开源社区活跃 成熟度（经过双十一考验） 开发指南 先阅读开发指南 Producer Group和Consumer Group使RocketMQ天然支持负载均衡 消息中间件通常采用集中持久化方式： 持久化到数据库，例如Mysql 持久化到KV存储，例如levelDB，伯克利DB等 文件记录形式持久化，例如Kafka，RocketMQ 对内存数据做一个持久化镜像，例如beanstalkd，VisiNotify 1,2,3 三种持久化方式都具有将内存队列Buffer进行扩展的能力，4只是一个内存的镜像，作用是当Broker挂掉重启后仍然能将之前内存的数据恢复出来。 Broker的Buffer满了怎么办？RocketMQ同其他MQ有非常显著的区别，RocketMQ的内存Buffer抽象成一个无限长度的队列，不管有多少数据进来都能装的下，这个无限是有前提的，Broker会定期删除过期的数据，例如Broker只保存3天的消息，那么这个Buffer虽然长度无限，但是3天前的数据会被从队尾删除。 消息优先级：由于RocketMQ 所有消息都是持久化的,所以如果按照优先级来排序，开销会非常大，因此RocketMQ没有特意支持消息优先级，但是可以通过变通的方式实现类似功能，即单独配置一个优先级高的队列，和一个普通优先级的队列，将不同优先级发送到不同的队列即可。 RocketMQ环境搭建（以多Master为例，用户指南有其他例子）用户手册 搭建方式 多master方式，推荐这种方式，性能最好 多master多slave，异步复制（可以保证实时消费） 多master多slave，同步双写（可以保证实时消费，并且保证数据不丢失，但是性能会较同步复制稍微慢） 异步复制和同步双写： 异步复制是发送消息给主节点，主节点和从节点进行同步。这样如果主节点毫秒级别挂掉的话，那么会导致消息在进行复制的过程，有少量消息没有复制过来。 同步双写：发送消息给主节点的同时也发送给从节点，只有主节点和从节点都收到消息那么这个消息才是发送成功了。（涉及到钱的话建议采用这种方式） Linux重启网卡命令 service network restart Linux命令：ln 对某个文件/文件夹创建一个连接 RocketMQ 最小的堆是1G nohup 启动方式会生成nohup.out来查看日志 文档中，部署了两台机器并在各自机器分别部署了一个NameServer和一个Broker，启动时候，先启动两台机器的NameServer，然后再启动两台机器的Broker（虽然两台机器都有多个properties配置文件，但是启动的时候一台用broker-a.properties,一台用broker-b.properties），关闭的时候，先关闭两台机器的Broker，在关闭两台机器的NameServer。(可以写个脚本) RocketMQ没有管控页面，需要在tomcat部署rocketmq-console.war。并且修改rocketmq-console/WEB-INF/classes/config.properties文件，将RocketMQ节点ip和端口号用分号间隔都添加进去。 同步刷盘和异步刷盘区别：异步刷盘写完PAGECACHE直接返回，而同步刷盘需要等待刷盘完成才返回（详情见用户指南的刷盘策略）。 RocketMQ与Kafka对比（18项差异） 淘宝内部的交易系统使用了淘宝自主研发的Notify消息中间件，使用Mysql作为消息存储媒介，可完全水平扩容，为了进一步降低成本，我们认为存储部分可以进一步优化，2011年初，Linkin开源了Kafka这个优秀的消息中间件，淘宝中间件团队在对Kafka做过充分Review之后，Kafka无限消息堆积，高效的持久化速度吸引了我们，但是同时发现这个消息系统主要定位于日志传输，对于使用在淘宝交易、订单、充值等场景下还有诸多特性不满足，为此我们重新用Java语言编写了RocketMQ，定位于非日志的可靠消息传输（日志场景也OK），目前RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。 HelloWorld RocketMQ架构 NameServer 节点与节点做协调类似于Zookeeper Broker 存储数据 filterServer 过滤，开源的有问题，收费的没问题 Client store 专注与存储，broker调store的api存储数据 common 公共方法 serverUtil 处理心跳，交换 tools 涉及到管理员命令 RocketMQ详解基本设计 消费者指定GroupName是为了做到负载均衡，生产者指定GroupName是为了发送消息失败后，MQ能够通知其他相同GroupName的节点重新发送消息 Producer 可以指定Tag来进行过滤 Consumer 在RocketMQ里，consumer被分为2类：MQPullConsumer和MQPushConsumer（大部分情况用此模式），其实本质都是拉模式（pull），即consumer轮询从broker拉取消息。 push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage（）来消费，对用户而言，感觉消息是被推送过来的。 pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取得开始offset，直到取完了，再换另一个MessageQueue。（每隔5秒钟会与broker同步offet位置，所以拉取间隔要大于5秒） Consumer配置参数 Filter 我们如果想用RocketMQ的Filter组件，则必须启动mqfiltersrv 启动的顺序为：namesrv、broker、mqfiltersrv （使用命令nohup sh mqfiltersrv -c filter.properties 启动mqfiltersrv，配置文件的配置 sh mqfiltersrv -p） 然后我们需要实现MessageFilter接口，进行重写match方法，我们可以针对自己想要过滤的消息进行细粒度的处理 最后我们需要把自己实现Filter类，通过消费端的订阅方式，加入到我们消费端即可 RocketMQ API详解 官方Git上有example包含顺序发送消息，filtersrv等 更多详情请查看博客：http://www.jianshu.com/p/453c6e7ff81c Producer消息分为三种不同模式（普通，顺序，事务） 顺序消息 demo 顺序是指1，2，3共3条消息，第1条消息处理完之后，再执行第二条消息，第二条消息执行完后再执行第3条消息。 RocketMQ怎样实现顺序消费： 首先Producer端发送消息进入同一个队列里【一个Topic默认有4个队列】 然后Consumer端要实现另一个MessageOrder接口，他能指定一个线程从一个队列里拿数据，不允许其他线程去队列里拿数据。 分布式事务消息（以支付宝转10000元给余额宝为例） demo RocketMQ实现发送事务消息（如上图）：RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事务，第三阶段拿到的地址去访问消息，并修改消息的状态。 如果“确认消息发送”失败了怎么办？在3.0.8之前（好像是），RocketMQ会定期扫描消息集群中的事务消息，如果发现了Prepared消息，它会向消息发送端（生产者）确认，确认支付宝的钱到底减少没有？如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。3.0.8之后此功能做了阉割。 消费失败了怎么办？阿里给的答案：人工解决 应用案例 Consumer业务系统与各个系统通讯用netty 集群监控与运维 RocketMQ运维指令整理 其他打包项目 里面配置的release.xml打包机制 数据可靠性 RocketMQ支持异步实时刷盘，同步刷盘，同步Replication，异步Replication Kafka使用异步刷盘方式，异步Replication/同步Replication 总结：RocketMQ的同步刷盘在单机可靠性上比Kafka更高，不会因为操作系统Crash，导致数据丢失。Kafka同步Replication理论上性能低于RocketMQ的同步Replication，原因是Kafka的数据以分区为单位组织，意味着一个Kafka实例上会有几百个数据分区，RocketMQ一个实例上只有一个数据分区，RocketMQ可以充分利用IO Group Commit机制，批量传输数据，配置同步Replication与异步Replication相比，性能损耗约20%~30%，Kafka没有亲自测试过，但是个人认为理论上会低于RocketMQ。 性能对比 Kafka单机写入TPS约在百万条/秒，消息大小10个字节 RocketMQ单机写入TPS单实例约7万条/秒，单机部署3个Broker，可以跑到最高12万条/秒，消息大小10个字节 总结：Kafka的TPS跑到单机百万，主要是由于Producer端将多个小消息合并，批量发向Broker。 RocketMQ为什么没有这么做？ Producer通常使用Java语言，缓存过多消息，GC是个很严重的问题 Producer调用发送消息接口，消息未发送到Broker，向业务返回成功，此时Producer宕机，会导致消息丢失，业务出错 Producer通常为分布式系统，且每台机器都是多线程发送，我们认为线上的系统单个Producer每秒产生的数据量有限，不可能上万。 缓存的功能完全可以由上层业务完成。 单机支持的队列数 Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长。Kafka分区数无法过多的问题 RocketMQ单机支持最高5万个队列，Load不会发生明显变化 队列多有什么好处？ 单机可以创建更多Topic，因为每个Topic都是由一批队列组成 Consumer的集群规模和队列数成正比，队列越多，Consumer集群可以越大 消息投递实时性 Kafka使用短轮询方式，实时性取决于轮询间隔时间，0.8以后版本支持长轮询。 RocketMQ使用长轮询，同Push方式实时性一致，消息的投递延时通常在几个毫秒。 消费失败重试 Kafka消费失败不支持重试。 RocketMQ消费失败支持定时重试，每次重试间隔时间顺延 总结：例如充值类应用，当前时刻调用运营商网关，充值失败，可能是对方压力过多，稍后再调用就会成功，如支付宝到银行扣款也是类似需求。 这里的重试需要可靠的重试，即失败重试的消息不因为Consumer宕机导致丢失。 严格的消息顺序 Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序 RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序 Mysql Binlog分发需要严格的消息顺序 定时消息 Kafka不支持定时消息 RocketMQ支持两类定时消息 开源版本RocketMQ仅支持定时Level，定时Level用户可定制 阿里云ONS支持定时Level，以及指定的毫秒级别的延时时间 分布式事务消息 Kafka不支持分布式事务消息 阿里云ONS支持分布式定时消息，未来开源版本的RocketMQ也有计划支持分布式事务消息 消息查询 Kafka不支持消息查询 RocketMQ支持根据Message Id查询消息，也支持根据消息内容查询消息（发送消息时指定一个Message Key，任意字符串，例如指定为订单Id） 总结：消息查询对于定位消息丢失问题非常有帮助，例如某个订单处理失败，是消息没收到还是收到处理出错了。 消息回溯 Kafka理论上可以按照Offset来回溯消息 RocketMQ支持按照时间来回溯消息，精度毫秒，例如从一天之前的某时某分某秒开始重新消费消息 总结：典型业务场景如consumer做订单分析，但是由于程序逻辑或者依赖的系统发生故障等原因，导致今天消费的消息全部无效，需要重新从昨天零点开始消费，那么以时间为起点的消息重放功能对于业务非常有帮助。 消费并行度 Kafka的消费并行度依赖Topic配置的分区数，如分区数为10，那么最多10台机器来并行消费（每台机器只能开启一个线程），或者一台机器消费（10个线程并行消费）。即消费并行度和分区数一致。 RocketMQ消费并行度分两种情况 顺序消费方式并行度同Kafka完全一致 乱序方式并行度取决于Consumer的线程数，如Topic配置10个队列，10台机器消费，每台机器100个线程，那么并行度为1000。 消息轨迹 Kafka不支持消息轨迹 阿里云ONS支持消息轨迹 开发语言友好性 Kafka采用Scala编写 RocketMQ采用Java语言编写 Broker端消息过滤 Kafka不支持Broker端的消息过滤 RocketMQ支持两种Broker端消息过滤方式 根据Message Tag来过滤，相当于子topic概念 向服务器上传一段Java代码，可以对消息做任意形式的过滤，甚至可以做Message Body的过滤拆分。 消息堆积能力理论上Kafka要比RocketMQ的堆积能力更强，不过RocketMQ单机也可以支持亿级的消息堆积能力，我们认为这个堆积能力已经完全可以满足业务需求。 开源社区活跃度 Kafka社区更新较慢 RocketMQ的github社区有250个个人、公司用户登记了联系方式，QQ群超过1000人。 商业支持 Kafka原开发团队成立新公司，目前暂没有相关产品看到 RocketMQ在阿里云上已经开放公测近半年，目前以云服务形式免费供大家商用，并向用户承诺99.99%的可靠性，同时彻底解决了用户自己搭建MQ产品的运维复杂性问题 成熟度 Kafka在日志领域比较成熟 RocketMQ在阿里集团内部有大量的应用在使用，每天都产生海量的消息，并且顺利支持了多次天猫双十一海量消息考验，是数据削峰填谷的利器。","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-ActiveMQ","date":"2017-04-17T13:58:17.000Z","path":"2017/04/17/Java架构师-ActiveMQ/","text":"ActiveMQJMS Java消息服务（JMS）定义了Java中访问消息中间件的接口。JMS只是接口，并没有给予实现，实现JMS接口的消息中间件成为JMS Provider，已有MOM（面向消息的中间件）系统包括Apache的ActiveMQ，以及阿里巴巴的RocketMQ，IBM的MQSeries，微软的MSMQ和BEA的MessageQ，RabbitMQ等等。他们基本都遵循JMS规范。 JMS属于 Provider（MessageProvider）：生产者 Consumer（MessageConsumer）：消费者 PTP:Point to Point，即点对点的消息模型 Pub/Sub：Publish/Subscribe，即发布/订阅的消息模型 Queue：队列目标 Topic：主题目标 ConnectionFactory：连接工厂，JMS用它创建连接 Connection：JMS客户端到JMS Provider的连接 Destination：消息的目的地 Session：会话，一个发送或接收消息的线程 消息格式 StreamMessage Java原始值的数据流 MapMessage 一套名称-值对 TextMessage 一个字符串对象 ObjectMessage 一个序列化的Java对象 BytesMessage 一个未解释字节的数据流 配置 activemq.xml（可以配置持久化【mysql或者kahadb】,并发量不大可以用mysql，并发量大用kahadb或leveldb） jetty.xml 默认端口号：8161 jetty-realm.properties 登录的用户名和密码 控制台（可以查看消息队列或者删除等） localhost:8161/admin 用户名，密码从properties文件中看 HelloWorld 第一步：建立ConnectionFactory工厂对象，需要填入用户名、密码、以及要连接的地址，均使用默认即可，默认端口为”tcp://localhost:61616” 第二步：通过ConnectionFactory工厂对象我们创建一个Connection连接，并且调用Connection的start方法开启连接，Connection默认是关闭的。 第三步：通过Connection对象创建Session会话（上下文环境对象），用于接收消息，参数配置1为是否启用是事务，参数配置2为签收模式，一般我们设置自动签收。 第四步：通过Session创建Destination对象，指的是一个客户端用来指定生产消息目标和消费消息来源的对象，在PTP模式中，Destination被称作Queue即队列；在Pub/Sub模式，Destination被称作Topic即主题。在程序中可以使用多个Queue和Topic。 第五步：我们需要通过Session对象创建消息的发送和接收对象（生产者和消费者）MessageProducer/MessageConsumer。 第六步：我们可以使用MessageProducer的setDeliveryMode方法为其设置持久化特性(存储到kahadb，jdbc等等)和非持久化特性（DeliveryMode)。 1producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); 第七步：最后我们使用JMS规范的TextMessage形式创建数据（通过Session对象），并用MessageProducer的send方法发送数据。同理客户端使用receive方法进行接收数据。最后不要忘记关闭Connection连接。 ActiveMQ安全机制(添加访问用户名和密码) activeMQ的web管理页面：http://127.0.0.1:8161/admin activeMQ管控台使用jetty部署，所以需要修改密码则需要到相应的配置文件（/conf/jetty-realm.properties） activeMQ设置有安全机制，只有符合认证的用户才能进行发送和获取消息，所以我们需要在activemq.xml里去添加安全验证配置（conf/activemq.xml,在第123行之后添加配置！【添加一个插件配置即可】） 1234567&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username=\"msj\" password=\"msj\" groups=\"users,admins\"/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt; &lt;/plugins&gt; Connection方法使用 当一个Connection被创建时，他的传输默认是关闭的，必须使用start方法开启。一个Connection可以建立一个或多个Session。 当一个程序执行完成后，必须关闭之前创建的Connection，否则ActiveMQ不能释放资源，关闭一个Connection同样也关闭了Session，MessageProducer和MessageConsumer。 Session方法使用 Session可以被事务化，也可以不被事务化。通常，可以通过向Connection上的适当创建方法传递一个布尔参数对此进行设置。Session createSession(boolean transacted,int acknowledgeMode); 其中transacted为使用事务标识，acknowledgeMode为签收模式。 结束事务有两种方法：提交或者回滚。当一个事务提交，消息被处理。如果事务中有一个步骤失败，事务就回滚，这个事务中的已经执行的动作将被撤销。在发送消息最后也必须要使用session.commit()方法表示提交事务。 签收模式有三种形式： Session.AUTO_ACKNOWLEDGE 当消费者从receive或onMessage成功返回时，Session自动签收消费者的这条消息的收条。 Session.CLIENT_ACKNOWLEDGE 消费者通过调用消息（Message）的acknowledge方法签收消息。在这种情况下，签收发生在Session层面：签收一个已消费的消息会自动地签收这个Session所有已消费消息的收条。 Session.DUPS_OK_ACKNOWLEDGE 此选项只是Session不必确保对传送消息的签收。它可能引起消息的重复，但是降低了Session的开销，所以只有消费者能容忍重复的消息（并发情况下，可能c1,c2,c3等多个消费者同时拿到某个消息），才可使用。 MessageProducer ActiveMq无法保证优先级顺序（即优先级高的先执行），所以为了保证顺序，在ActiveMQ和消费者之间加多个顺序排队系统保证严格的顺序消费。RocketMQ支持优先级顺序。（在ActiveMQ4.x中可以采用Exclusive Consumer或者Exclusive Queues避免这种情况，Broker会从消息队列中一次发送消息给一个消息消费者保证顺序） MessageConsumer 消息的同步和异步接收： 消息的同步接收是指客户端主动去接收消息，客户端可以采用MessageConsumer的receive方法去接收下一个消息。 Message receive() Message receive(long timeout) Message receiveNoWait() 消息的异步接收是指当消息到达时，ActiveMQ主动通知客户端，可以通过注册一个实现MessageListener接口的对象到MessageConsumer。MessageListener只有一个必须实现的方法—-onMessage，它只接收一个参数，即Message。在为每个发送到Destination的消息实现onMessage时，将调用该方法。 Message 创建临时消息ActiveMQ通过create TemporaryQueue和create TemporaryTopic创建临时目标，这些目标持续到创建它的Connection关闭。只有创建临时目标的Connection所创建的客户端才可以从临时目标中接收消息，但是任何的生产者都可以向临时目标中发送消息。如果关闭了创建此目标的Connection，那么临时目标被关闭，内容也将小时。 TemporaryQueue createTemporaryQueue TemporaryTopic createTemporaryTopic 高级主题P2P publish-subscribe 与spring进行整合http://blog.csdn.net/jiangxuchen/article/details/8004570 http://blog.163.com/czg_elog/static/4610456120133943548952/ 集群Zookeeper+ActiveMQZookeeper+ActiveMQ 最好用的模式：network connector网络连接模式 MQ用途 消息中间件 异步处理任务机制（异步消费数据、异步发送邮件、异步查询操作等） ActiveMQ和RocketMQ ActiveMQ过滤效果不是很好，消费量大的时候会有问题，承载性能不好 其他补充 maven默认密码admin123","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-Redis","date":"2017-04-17T13:33:03.000Z","path":"2017/04/17/Java架构师-Redis/","text":"NOSQL(Redis)简介，Redis安装与部署NOSQL简介NOSQL，泛指非关系型的数据库，NoSql数据库的四大分类： 键值（Key-Value）存储数据库：这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。如Redis，Voldemort，Oracle BDB 列存储数据库：这部分数据库通常是用来应对分布式存储的海量数据。键依然存在，但是它们的特点是指向了多个列。如HBase，Riak 文档型数据库：该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB，MongoDB 图形数据库：图形结构的数据库同其他行列以及刚性结构的Sql数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSql数据库没有标准的查询语言（SQL），因此进行数据库查询需要制定数据模型。许多NoSql数据库都有REST式的数据接口或者查询API。如：Neo4J,InfoGrid，Infinite Graph 非关系型数据库特点 数据模型比较简单 需要灵活性更强的IT系统 对数据库性能要求较高 不需要高度的数据一致性 对于给定key，比较容易映射复杂值的环境 Redis简介是以key-value形式存储，和传统的关系型数据库不一样，不一定遵循传统数据库的一些基本要求（非关系型的、分布式的、开源的、水平可扩展的） 优点： 对数据高并发读写 对海量数据的高效率存储和访问 对数据的可扩展性(横向扩展【从节点扩充】和纵向扩展【主节点变成子节点】)和高可用性（存储到内存中，断电消失，刷数据到硬盘上【有RDB（同步到硬盘）和AOF（日志方式恢复）两种方式来实现】） 缺点： redis（ACID处理非常简单） 无法做到太复杂的关系数据库模型 Redis是以key-value store存储，data structure service 数据结构服务器。键可以包含：（string）字符串，哈希，（list）链表，（set）集合，（zset）有序集合。这些数据集合都支持push/pop、add/remove及取交集和并集以及更丰富的操作，redis支持各种不同的方式排序，为了保证效率，数据都是缓存在内存中，它也可以周期性的把更新的数据写入磁盘[RDB方式]或者把修改操作写入追加到文件[AOF方式]。 memorycache实例是并行的，redis实例是串行的。 Redis慢了怎么办？ 原因可能因为：开启AOF模式，多并发情况下会影响写的性能，因为需要记录日志 解决方案1：2.0可以调虚拟机参数，3.0出了集群参数基本无用了。可以采取多加，分担写的高并发压力。 解决方法2：采用另外一种NoSql数据库，ssdb（写的性能比较好） Redis安装与部署下载地址：http://redis.io/download 安装步骤： 首先需要安装gcc，把下载好的redis-3.0.0-rc2.tar.gz 放到linux /usr/local文件夹下 进行解压 tar -zxvf redis-3.0.0-rc2.tar.gz 进入到redis-3.0.0目录下，进行编译 make 进入到src下进行安装 make install 验证(ll查看src下的目录，有redis-server 、redis-cil即可) 建立俩个文件夹存放redis命令和配置文件 mkdir -p /usr/local/redis/etc mkdir -p /usr/local/redis/bin 把redis-3.0.0下的redis.conf 移动到/usr/local/redis/etc下， cp redis.conf /usr/local/redis/etc/ 把redis-3.0.0/src里的mkreleasehdr.sh、redis-benchmark、redis-check-aof、redis-check-dump、redis-cli、redis-server文件移动到bin下，命令： mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-dump redis-cli redis-server /usr/local/redis/bin(如果没有redis-check-dump尝试cp redis-check-rdb /usr/local/redis/bin) 启动时并指定配置文件：./redis-server /usr/local/redis/etc/redis.conf（注意要使用后台启动，所以修改redis.conf里的 daemonize 改为yes) 验证启动是否成功： ps -ef | grep redis 查看是否有redis服务 或者 查看端口：netstat -tunpl | grep 6379 进入redis客户端 ./redis-cli 退出客户端quit 退出redis服务三种方式： （1）pkill redis-server 、 （2）kill 进程号、 （3）/usr/local/redis/bin/redis-cli shutdown rdb文件是redis存放数据的文件 命令redis-cli(进入redis客户端) keys *（查看redis内容） set name msj（插入内容key是name，value是msj） get name（查看key为name的内容） del name（删除key为name的内容） quit（关闭redis客户端） redis-cli shutdown（进入redis-cli文件所在夹，此命令关闭redis服务） Redis基础数据类型详解redis一共分为五种数据类型：String、Hash、List、Set、ZSet String类型String类型是包含很多种类型的特殊类型，并且是二进制安全的。比如序列化的对象进行存储，比如一张图片进行二进制存储，比如一个简单的字符串，数值等等。 set和get方法： 设置值：set name msj 取值 get name（设置name多次会覆盖） 删除值：del name 使用setnx（not exist） name 如果不存在进行设置，存在就不需要进行设置了，返回0 使用setzreex （expired） setex color 10 red 设置color的有效期为10秒，10秒后返回nll（在redis里nll表示空） 使用setrange 替换字符串 set email mengshaojie@188.com setrange email 10 ww（10表示从第几位开始替换（是下标值即正常值-1），后面跟上替换的字符串，后面字符串有几位则替换几位） 使用一次性设置多个和获取多个值的mset，mget方法： mset key1 msj key2 msj2 key3 28; 对应的 mget key1 key2 key3 方法，对应的也有msetnx和mget方法 一次性设置和取值的getset方法： set key4 cc getset key4 changchun 返回旧值并设置新值的方法 incr和decr方法：对某一个值进行递增和递减等同于i++，i–incrby和decrby方法：对某个值进行指定长度的递增和递减 (语法：incrby key [步长]) 等同于 i += 步长append[name]方法：字符串追加方法strien[name]方法：获取字符串的长度Hash类型 存储一个对象，对象有几十个字段，假如频繁取一个字段，那么不适宜把字段放到对象中缓存，影响效率（根据不同业务做不同的策略）。 1234567hset user name msjhset user age 18hset user sex manhget user(报错)--》查看键值使用hkeys user，查看value使用hvals user，查看键值和value使用hgetall userhmget user name age sex（查看多个值）hlen userhdel user List类型List类型是一个链表结构的结合，其主要功能有push、pop、获取元素等。更详细的说，List类型是一个双端链表的结构，我们可以通过相关操作进行集合的头部或者尾部添加删除元素，list的设计非常简单精巧，既可以作为栈，又可以作为队列。 Ipush方法：从头部加入元素（栈）先进后出 lpush list1 “hello” lpush list1 “world” lrange list1 0 -1(表示从头取到末尾) rpush方法：从尾部加入元素（队列）先进先出 rpush list2 “beijing” rpush list2 “sxt” lrang list2 0 -1 linsert方法：插入元素 linsert list3 before [集合的元素][插入的元素] lset方法：将指定下标的元素替换掉 lset list1 two 2lrem方法：删除元素，返回删除的个数（下标） lset list1 移除几个 移除的字段ltrim方法：保留指定key的值范围内的数据 ltrim list 2 3 （加入队列有8个元素，则只保留了下标是2-下标3的元素）lpop方法：从list的头部删除元素，并返回删除元素 lpop list1rpop方法：从list的尾部删除元素，并返回删除元素 rpop list1rpoplpush：第一步从尾部删除元素，然后第二步并从头部加入元素lindex方法：返回名称为key的list中index未知的元素llen方法：返回元素的个数 set（无序）类型和zset（有序）类型set集合是string类型的无序集合，set是通过hashtable实现的，对集合我们可以取交集、并集、差集。 sadd方法：向名称为key的set中添加元素 set集合不允许重复元素 smembers查看set集合的元素 srem方法：删除set集合元素spop方法：随机返回删除的keysdiff方法：返回两个集合的不同元素（哪个集合在前面就以哪个集合为标准）sdiffstore方法：将返回的不同元素存储到另外一个集合里 这里是把set1和set2的不同元素（以set1为准）存储到set3集合里 sdiffstore set3 set1 set2 sinter方法：返回集合的交集sinterstore方法：返回交集结果，存入set3中sunion方法：取并集sunionstore：取得并集，存入set3中smove方法：从一个set集合移动到另一个set集合里 将set1中的元素移动到set2中（相当于剪切粘贴） smove set1 set2 scard方法：查看集合里元素个数sismember方法：判断某元素是否为集合中的元素 返回1代表是集合中的元素，0代表不是 srandmember方法：随机返回一个元素zadd向有序集合中添加一个元素，该元素如果存在，则更新顺序 在重复插入的时候 会根据顺序属性更新 想查看索引则使用 zrange zset1 0 -1 withscores zrem 删除名称为key的zset中的元素memberzincrby 以指定值去自动递增或者减少，用法和之前的incrby类似zrangebyscore 找到指定区间范围的数据进行返回zremrangebyrank 删除1到1（只删除索引1）zremrangebyscore 删除指定序号zrank返回排序索引 从小到大排序（升序排序之后再找索引） 注意 一个是顺序号 一个是索引 zrank返回的是索引 zrevrank 返回排序索引 从大到小排序（降序排列之后再找索引）zrangebyscore zset1 2 3 withscores 找到指定区间范围的数据进行返回zcard 返回集合里所有元素的个数zcount 返回集合中score在给定区间中的数量zremrangebyrank zset 【from】【to】（删除索引）zremrangebyscore zset [from] [to] (删除指定序号)Redis高级命令 返回满足的所有键keys （可以模糊查询 keys list） exists 是否存在指定的key expire 设置某个key的过期时间，使用ttl查看剩余时间 12expire name 5ttl name persist 取消过期时间 select 选择数据库 数据库为0到15（一共16个数据库）默认进入的是0数据库【是逻辑划分不是物理划分即不是第一个数据库1个G，第二个数据库1个G，而是16个数据库供多少G，然后逻辑划分】 1234567set name msjset name1 msj1keys *select 0keys *select 1keys * move [key][数据库下标] 将当前数据中的key转移到其他数据库中 123move name 2select 2keys * randomkey 随机返回数据库里的一个key rename 重命名key 1rename name name3 echo 打印命令 dbsize 查看数据库的key数量 1dbsize info获取数据库信息 123info其中的信息解释：cluster_enabled:0 0表示没开启，此处表示没开启集群模式 config get 实时存储收到的请求（返回相关的配置信息） 1config get *返回所有配置 flushdb 清空当前数据库，flushall清空所有数据库 Redis的安全性因为redis速度相当快，所以在一台比较好的服务器下，一个外部用户在一秒内可以进行15w次的密码尝试，这意味着你需要设定非常强大的密码来防止暴力破解。 vi编辑redis.conf 文件，找到下面进行保存修改 12#requirepass foobaredrequirepass ****(密码) 重启服务器 pkill redis-server 再次进入127.0.0.1：6379&gt;keys *(error)NOAUTH Authentication required 会发现没有权限进行查询127.0.0.1:6379&gt; auth bhz OK 输入密码则成功进入 每次进入的时候都要输入密码，还有种简单的方式： 直接登录授权：redis-cli -abhz 主从复制(主服务器可以读写，从服务器只可读)推荐博客：http://blog.csdn.net/hechurui/article/details/49508813 场景电子商务网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是”多读少写”。 优点 读写分离，不仅可以提高服务器的负载能力（配置好后自动做负载均衡），并且可以根据读请求的规模自由增加或者减少从库的数量 数据被复制成了了好几份，就算有一台机器出现故障，也可以使用其他机器的数据快速恢复。 主从复制： Master可以拥有多个slave 多个slave可以连接同一个master外，还可以连接到其他的slave[即主连多个从，从又连多个从，这种情况一般不用] 主从复制不会阻塞master在同步数据时，master可以继续处理client请求 提供系统的伸缩性 主从复制过程： slave与master建立连接 master会开启一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 后台完成保存后，就将文件发送给slave slave将此文件保存到硬盘上 主从复制配置clone服务器之后修改slave的IP地址还要修改mac地址 修改配置文件（从服务器）：/usr/local/redis/etc/redis.conf slaveof masterauth scp -r 本地路径/ 远程路径 （copy文件或文件夹到远程电脑路径下）例如：scp -r redis 192.168.1.123:/usr/local/ 使用info查看role角色即可知道是主服务或从服务 哨兵有了主从复制的实现以后，我们如果想对主从服务器进行监控，那么在redis2.6以后提供了一个“哨兵”机制，在2.6版本中的哨兵为1.0版本，并不稳定，会出现各种各样的问题。在2.8以后的版本哨兵功能稳定起来。 redis哨兵的启动和redis实例的启动没有关系。所以可以在任何机器上启动redis哨兵。至少要保证有两个哨兵在运行[主节点可以被多个哨兵监控]，要不然宕机后哨兵会找不到主节点。 哨兵是单独的，并不是某个服务器，只是在某个服务器中运行，一个哨兵可以监控多个服务器。主从服务器和哨兵没关系，哨兵是负责监控主从服务器 顾名思义，哨兵的含义就是监控Redis系统的运行状况。其主要功能有两点： 监控主数据库和从数据库是否正常运行 主数据库出现故障时，可以自动将从数据库转换为主数据库，实现自动切换。实现步骤：在其中一台从服务器配置sentinel.conf copy文件sentinel.conf到/usr/local/redis/etc中 修改sentinel.conf文件： 步骤2 mymaster可以随便起，后续沿用此名称 down-after-milliseconds 选项指定了 Sentinel 认为服务器已经断线所需的毫秒数（判定为主观下线SDOWN） failover-timeout 过期时间，当failover开始后，在此时间内仍然没有触发任何failover操作,当前sentinel将会认为此次failoer失败。 paraHel-syncs 选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长，但越大就意味着越多的从服务器因为复制而不可用。可以通过将这个值设为 1 来保证每次只有一个从服务器处于不能处理命令请求的状态。 can-failover 当前sentinel实例是否允许实施“failover”(故障转移) no表示当前sentinel为“观察者”(只参与”投票”.不参与实施failover)，全局中至少有一个为yes Sentinel.conf详解##sentinel实例之间的通讯端口 ##redis-0 port 26379 ##sentinel需要监控的master信息：&lt;mastername&gt; &lt;masterIP&gt; &lt;masterPort&gt; &lt;quorum&gt; ##&lt;quorum&gt;应该小于集群中slave的个数,只有当至少&lt;quorum&gt;个sentinel实例提交&quot;master失效&quot; ##才会认为master为O_DWON(&quot;客观&quot;失效) sentinel monitor def_master 127.0.0.1 6379 2 sentinel auth-pass def_master 012_345^678-90 ##master被当前sentinel实例认定为“失效”的间隔时间 ##如果当前sentinel与master直接的通讯中，在指定时间内没有响应或者响应错误代码，那么 ##当前sentinel就认为master失效(SDOWN，“主观”失效) ##&lt;mastername&gt; &lt;millseconds&gt; ##默认为30秒 sentinel down-after-milliseconds def_master 30000 ##当前sentinel实例是否允许实施“failover”(故障转移) ##no表示当前sentinel为“观察者”(只参与&quot;投票&quot;.不参与实施failover)， ##全局中至少有一个为yes sentinel can-failover def_master yes ##当新master产生时，同时进行“slaveof”到新master并进行“SYNC”的slave个数。 ##默认为1,建议保持默认值 ##在salve执行salveof与同步时，将会终止客户端请求。 ##此值较大，意味着“集群”终止客户端请求的时间总和和较大。 ##此值较小,意味着“集群”在故障转移期间，多个salve向客户端提供服务时仍然使用旧数据。 sentinel parallel-syncs def_master 1 ##failover过期时间，当failover开始后，在此时间内仍然没有触发任何failover操作， ##当前sentinel将会认为此次failoer失败。 sentinel failover-timeout def_master 900000 ##当failover时，可以指定一个“通知”脚本用来告知系统管理员，当前集群的情况。 ##脚本被允许执行的最大时间为60秒，如果超时，脚本将会被终止(KILL) ##脚本执行的结果： ## 1 -&gt; 稍后重试，最大重试次数为10; ## 2 -&gt; 执行结束，无需重试 ##sentinel notification-script mymaster /var/redis/notify.sh ##failover之后重配置客户端，执行脚本时会传递大量参数，请参考相关文档 # sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; 测试shutdown掉主节点1，看是否选择了从节点为主节点2。 再重新启动主节点1（主节点1变成了从节点） Redis事务 redis的事务非常简单，使用方法如下： 首先是使用multi方法打开事务，然后进行设置，这时设置的数据都会放入队列里进行保存，最后使用exec执行，把数据依次存储到redis中，使用discard方法取消事务。 redis的事务不能保证同时成功或失败进行提交或回滚，所以redis的事务目前还是比较简单的。 持久化机制 快照和aof两种方式只能选一种，一般使用aof并且是always模式，因为3.0之后采用集群，所以有多个主节点，减轻写操作的压力。对于2.x的版本也可以结合ssdb使用。 发布和订阅消息（观察者模式） 使用subscribe [频道]进行订阅监听 使用publish [频道] [发布内容] 进行发布消息广播 虚拟内存的使用 redis会暂时把不经常访问的数据从内存交换到磁盘中，腾出宝贵的空间，用于其他需要访问的数据，这需要对vm相关进行配置。（3.0版本是不带VM特性的 配置无效） 修改配置文件：redis.conf Redis与java的使用 业务量不大不需要用redis用spring cache就可以 Jedis就是redis支持java的第三方类库，我们可以使用Jedis类库操作redis数据库。Jedis2.7才支持集群。 TestSingleRedis TestClusterRedis 利用set和map，来查询类似sql语句“select * from user where age = 25 and name = ‘zs’”的效果 Redis集群搭建主从复制模式需要最少有3个主节点，哨兵模式有1个主节点就可以也可以多个主多个从。 在redis3.0以前，提供了Sentinel工具来监控各Master的状态，如果Master异常，则会做主从切换，将slave作为master，将master作为slave。其配置也是稍微的复杂，并且各方面表现一般。现在redis3.0已经支持集群的容错功能，并且非常简单。 用哨兵可能会出现闪断问题（主节点down掉，进行主从节点切换，网络不好情况可能需要1-2秒），所以java端应该try catch 捕获cluster is down异常，并且在catch中continue，最好sleep 1到2秒。 如果不想java代码try catch，那么还可以使用keepalived。 如果搭建集群？（此处用一台机器模拟多个节点）集群搭建：至少要三个master 创建一个文件夹redis-cluster，然后在其下面分别创建6个文件夹如下： mkdir -p /usr/local/redis-cluster mkdir 7001、mkdir 7002、mkdir 7003、mkdir 7004、mkdir 7005、mkdir 7006 把之前的redis.conf配置文件分别copy到700*下，进行修改各个文件内容，也就是对700*下的每一个copy的redis.conf进行修改。如下： daemonize yes (后台启动) port 700*（分别对每个机器的端口号进行设置） bind 192.168.1.171(必须要绑定当前机器的ip，不然会无限悲剧下去，比如set和get值非常慢，深坑勿入) dir /usr/local/redis-cluster/700*/(指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据，深坑勿入，不同机器不会出现) cluster-enabled yes （启动集群模式，开始玩耍） cluster-config-file nodes-700*.conf(这里700*最好和port对应上，这个文件是让各节点知道自己的配置类似共享自己的信息给其他节点) cluster-node-timeout 5000 appendonly yes （开启aof模式） 把修改后的配置文件，分别copy到各个文件夹下，注意每个文件要修改端口号，并且nodes文件也要不相同！ 由于redis集群需要使用ruby命令，所以我们需要安装ruby yum install ruby yum install rubygems gem install redis(安装redis和ruby的接口) 分别启动6个redis实例，然后检测是否启动成功 /usr/local/redis/bin/redis-server /usr/local/redis-cluster/700*/redis.conf ps -el | grep redis 查看是否启动成功 首先到redis3.0的安装目录下，然后执行redis-trib.rb命令 cd /usr/local/redis3.0/src ./redis-trib.rb create –replicas 1 192.168.1.171:7001 192.168.1.171.7002 192.168.1.171.7003 192.168.1.171.7004 192.168.1.171.7005 192.168.1.171.7006 （显示的信息主节点又slots【槽】，从节点没有slots，因为从节点不支持写操作） 搭建成功，验证： 连接任意一个客户端即可：./redis=cli -c -h -p(-c表示集群模式，指定ip地址和多口号) 如：/usr/local/redis/bin/redis=cli -c -h 192.168.1.171 -p 700* 进行验证：cluster info(查看集群信息)、cluster nodes(查看节点列表) 进行数据操作验证 关闭集群则需要逐个进行关闭，使用命令：/usr/local/redis/bin/redis-cli -c -h 192.168.1.171 -p 700* shutdown 补充 当出现集群无法启动时，删除临时的数据文件，再次重新启动每一个redis服务，然后重新构造集群环境 redis-trib.rb 官方操作命令：http://redis.io/topics/cluster=tutorial 推荐博客：http://blog.51ylp.com/nosql/1726.html/comment-page-1 假如7001登录客户端，set信息，信息不一定就会保存到7001，因为集群是个整体，根据槽分配；但是get事后，任何一个客户端都可以获取 集群模式创建一遍就可以了，下回直接启动集群服务器就行了 Linux命令 关闭防火墙：service iptables stop 验证：service iptables status 关闭防火墙的自动运行： chkconfig iptables off 验证：chkconfig –list | grep iptables Redis集群操作文档 新建节点并热更新添加到集群中（大概注意点，详情参照文档） 新建节点 redistrib.rb命令使用 redis-trib.rb add-node 192.168.1.171:7007（新增节点） 192.168.1.171:7001（已知存在节点） 查看集群状态： cluster nodes（当添加节点成功以后，新增的节点不会有任何数据，因为它没有分配任何的slot（hash槽）。我们需要为新节点手工分配slot。） 分配slot槽（/usr/local/redis3.0/src/redis-trib.rb reshard 192.168.1.171:7001）【此处有注意点查看文档】 添加从节点（7008）到集群中去（/usr/local/redis3.0/src/redis-trib.rb add-node 192.168.1.171:7008 192.168.1.171:7001） 将从节点（7008）master改成slave（cluster replicate 382634a4025778c040b7213453fd42a709f79e28（主节点id）） 热更新删除从节点和主节点（大概注意点，参照文档） 删除从节点（/usr/local/redis3.0/src/redis-trib.rbdel-node 192.168.1.171:7008 97b0e0115326833724eb0ffe1d0574ee34618e9f） 主节点删除需要注意：主节点的里面是有分配了slot槽的，所以我们这里必须先把7007里的slot槽放入到其他的可用主节点中去，然后再进行移除节点操作才行，不然会出现数据丢失问题。 Redis集群与spring的整合/TomcatRedis的Session共享","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-JVM","date":"2017-03-30T06:21:12.000Z","path":"2017/03/30/Java架构师-JVM/","text":"Java虚拟机概述和基本概念网站推荐：http://blog.csdn.net/u013256816/article/details/51484031 虚拟机可以分为系统虚拟机和程序虚拟机，VisualBox，VMare属于系统虚拟机，他们完全是对物理计算机的仿真，提供了一个可运行完整操作系统的软件平台。程序虚拟机典型代表就是Java虚拟机，它专门为执行单个计算机程序而设计，在java虚拟机中执行的指令我们称为java字节码指令。无论是系统虚拟机还是程序虚拟机，在上面运行的软件都被限制于虚拟机提供的资源中。Java发展至今，出现过很多虚拟机，最初Sun使用的一款叫Classic的Java虚拟机，到现在引用最广泛的是HotSpot虚拟机，除了Sun以外，还有BEA的JRockit，目前JRockit和HosSpot都被Oracle收入旗下。 java虚拟机基本结构 类加载子系统：负责从文件系统或者网络中加载Class信息，加载的信息存放在一块称之为方法区的内存空间。 方法区：就是存放类信息、常量信息、常量池信息、包括字符串字面量和数字常量等。 java堆：在java虚拟机启动的时候建立java堆，它是java程序最主要的内存工作区域，几乎所有的对象实例都存放到java堆中，堆空间是所有线程共享的。java堆实在jvm启动的时候就建立的，这块内存区域 存放了对象实例及数组(所有new的对象)也就是 Object object = new Object(); 这里object只是一个引用是放在栈里面的，new Object() 被放在了 堆内存里面，由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。 直接内存：Java的NIO库允许Java程序使用直接内存，从而提高性能，通常直接内存速度优于java堆。读写频繁的场合可能会考虑使用。 每个虚拟机线程都有一个私有的栈，一个线程的java栈在线程创建的时候被创建，java栈中保存着局部变量、方法参数、同时java的方法调用，返回值等。 本地方法栈和java栈非常类似，最大不同为本地方法栈用于本地方法调用。java虚拟机允许java直接调用本地方法（通常使用C编写）。 垃圾收集系统是java的核心，也是必不可少的，java有一套自己进行垃圾清理的机制，开发人员无需手工清理。 PC（Program Counter）寄存器也是每个线程私有的空间，java虚拟机会为每个线程创建PC寄存器，在任意时刻，一个java线程总是在执行一个方法，这个方法被称为当前方法，如果当前方法不是本地方法，PC寄存器就会执行当前正在被执行的指令，如果是本地方法，则PC寄存器值为undefined，寄存器存放如当前执行环境指针、程序计数器、操作栈指针、计算的变量指针等信息。 虚拟机最核心的组件就是执行引擎了，它负责执行虚拟机的字节码。一般会先进行编译成机器码后执行。 堆、栈、方法区堆、栈、方法区概念和联系 堆解决的事数据存储的问题，即数据怎么放，放在哪。 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。 方法区则是辅助对战的快永久区（Perm），解决堆栈信息的产生，是先决条件。 我们创建一个新的对象，User：那么User类的一些信息（类信息，静态信息都存放于方法区中）而User类被实例化出来之后，被存储到java堆中，一块内存空间。当我们去使用的时候，都是使用User对象的引用，形如 User user = new User（）；这里的User就是存放在java栈中的，即User真实对象的一个引用。 java堆java堆是和java应用程序关系最密切的内存空间，几乎所有的对象都存放在其中，并且java堆完全是自动化管理的，通过垃圾回收机制，垃圾对象会自动清理，不需要显示的释放。 根据垃圾回收机制不同，java堆有可能拥有不同的结构。最为常见的就是将整个java堆分为新生代和老年代。其中新生代存放新生的对象或者年龄不大的对象，老年代则存放老年对象。（新生代和老年代都会经历垃圾回收，只不过是频率差异） 绝大多数情况下，对象首先分配在eden区，在一次新生代回收后，如果对象还存活，则会进入s0或者s1区，之后经过一次新生代回收，如果对象存活则它的年龄增加1，当对象达到一定的年龄后，则进入老年代。(为什么会有2块s区，因为java进行垃圾回收算法时候使用的是复制算法) java栈java栈是一块线程私有的内存空间，一个栈，一般由三部分组成：局部变量表、操作数栈和帧数据区 局部变量表：用于报错函数的参数和局部变量。 操作数栈：主要保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。 帧数据区：除了局部变量表和操作数栈以外，栈还需要一些数据来支持常量池的解析，这里帧数据区保存着访问常量池的指针，方便程序访问常量池，另外，当函数返回或者出现异常时，虚拟机必须有一个异常处理表，方便发送异常的时候找到异常的代码，因此异常处理表也是帧数据区的一部分。java方法区java方法区和堆一样，方法区是一块所有线程共享的内存区域，它保存系统的类信息，比如类及其父类的全限定名（java.lang.Object没有父类）、类的类型（Class or Interface）、访问修饰符（public, abstract, final）、实现的接口的全限定名的列表、字段信息、方法信息、静态变量、ClassLoader引用、Class引用、常量池。方法区的大小决定了系统可以保存多少个类，如果系统定义太多的类，导致方法区溢出。虚拟机同样会抛出内存溢出错误。方法区可以理解为永久区（Perm）。（默认是64MB）了解虚拟机参数虚拟机参数配置，其实主要围绕堆、栈、方法区进行配置。堆分配参数 -XX:+PrintGC 使用这个参数，虚拟机启动后，只要遇到GC就会打印日志 -XX:+UseSerialGC 配置串行回收器 -XX:+PrintGCDetails 可以查看详细信息，包括各个区的情况 -Xms： 设置java程序启动时初始堆大小 -Xmx： 设置java程序能获得的最大堆大小 -Xmx20m -Xms5m -XX:+PrintCommandLineFlags：可以将隐式或者显示传给虚拟机的参数输出。 示例：Test01 总结：在实际工作中，我们可以直接将初始的堆大小与最大堆大小设置相等，这样的好处是可以减少程序运行时的垃圾回收，从而提高性能。 新生代配置： -Xmn:可以配置新生代的大小，设置一个比较大的新生代会减少老年代的大小，这个参数对系统性能以及GC行为有很大的影响，新生代大小一般会设置整个堆空间的1/3到1/4左右(如果业务需要时常回收对象的话，就把新生代设置的大小大一点，如果希望多存放存久的数据，则老年代大点)。 -XX：SurvivorRatio：用来设置新生代中eden空间和from/to空间的比例。含义：-XX：SurvivorRatio=eden/from=eden/to例如：-XX:SurvivorRatio=2 （eden区/s0区=2，即eden区2份，s0区1份，则s1也是1份，因为s0和s1是等大互换的） 示例Test02 总结：不同的堆分布情况，对系统执行会产生一定的影响，在实际工作中，应该根据系统的特点做出合理的配置，基本策略：尽可能将对象预留在新生代，减少老年代的GC次数。 除了可以设置新生代的绝对大小（-Xmn），还可以使用（-XX：NewRatio）设置新生代和老年代的比例：-XX：NewRatio=老年代/新生代 堆溢出处理在java程序的运行过程中，如果堆空间不足，则会抛出内存溢出的错误（Out Of Memory）OOM,一旦这类问题发生在生产环境，可能引起严重的业务中断，java虚拟机提供了-XX：+HeapDumpOnOutOfMemoryError，使用该参数可以在内存溢出时导出整个堆信息，与之配合使用的还有参数，-XX：HeapDumpPath，可以设置导出堆的存放路径。 内存分析工具：Memory Analyzer 1.5.0 地址：http://download.eclipse.org/mat/1.5/update-site/ 示例：Test03 栈配置Java虚拟机提供了参数-Xss来指定线程的最大栈空间，整个参数也直接决定了函数可调用的最大深度(方法被循环调用的次数)。 示例Test04 方法区和java堆一样，方法区是一块所有线程共享的内存区域，它用于保存系统的类信息，方法区（永久区）可以保存多少信息可以对其进行配置，在默认情况下，-XX：MaxPermSize为64MB，如果系统运行时生产大量的类，就需要设置一个相对合适的方法区，以免出现永久区内存溢出的问题。 -XX：PermSize=64MB -XX：MaxPermSize=64MB 直接内存配置直接内存广泛用于NIO中，直接内存跳过了java堆，使java程序可以直接访问原生堆空间，因此在一定程度上加快了内存空间的访问速度。但是说直接内存一定就可以提高内存访问速度也不见得，具体情况具体分析。(JDK1.7及以上不需要配置) -XX:MaxDirectMemorySize，如果不设置默认值为最大堆空间，即-Xmx。直接内存使用达到上限时，就会触发垃圾回收，如果不能有效的释放空间，也会引起系统的OOM. Client和Server虚拟机工作模式（1.6以前分工作模式，1.7 64位都是Server模式，不提供Client模式）java虚拟机支持Client和Server两种运行模式，使用参数-client可以指定使用Client模式，使用g-server可以指定使用Server模式。可以直接在命令行查看当前计算机系统自动选择的运行模式。java -version即可。 二者区别：Client模式相对Server启动较快，如果不追求系统的长时间使用性能仅仅是测试，可以使用Client模式。而Server模式则启动比较慢，原因是会对其进行复杂的系统性能信息收集和使用更复杂的算法对程序进行优化，一般我们的生产环境都会使用Server模式，长期运行其性能要远远快于Client模式。 垃圾回收概念和算法、及对象的分代转换GC（Garbage Collection）中的垃圾，特指存于内存中，不会再被使用的对象。垃圾回收有很多算法：引用计数法、标记压缩法、复制算法、分代、分区的思想。 垃圾收集算法 新生代采用复制算法，老年代采用标记压缩法。 新生代和老年代为什么采用不同的垃圾回收算法？ 因为新生代的存活率比较低即回收的对象比较多，老年代经过多次垃圾回收存活下来，所以存活率比较高即回收的对象比较少。 垃圾回收时的卡顿现象垃圾回收器的任务是识别和回收垃圾对象进行内存清理，为了让垃圾回收器可以高效的执行，大部分情况下，会要求系统进入一个停顿的状态。停顿的目的是终止所有应用线程，只有这样系统才不会有新的垃圾产生，同时停顿保证了系统状态在某一个瞬间的一致性，也有益于更好的标记垃圾对象。因此在垃圾回收时，都会产生应用程序的停顿。 对象如何进入老年代年龄配置：-XX:MaxTenuringThreshold，默认情况下为15。 示例：[Test05]（https://github.com/CentMeng/JavaFrameTest/tree/master/src/com/msj/jvm/Test05.java） 总结：根据设置MaxTenuringThreshold参数，可以指定新生代对象经过多少次回收后进入老年代。另外，大对象（新生代eden区无法装入时，也会直接进入老年代）。JVM里有个参数可以设置对象的大小超过在指定大小之后，直接晋升老年代。-XX:PertenureSizeThreshod 示例：[Test06]（https://github.com/CentMeng/JavaFrameTest/tree/master/src/com/msj/jvm/Test06.java） 总结：使用PretenureSizeThreshod可以进行指定进入老年代的对象大小，但是要注意TLAB区域有限分配空间。 TLABTLAB全称是Thread Local Allocation Buffer 即线程本地分配缓存。 从名字上看是一个线程专用的内存分配区域，是为了加速对象分配而生的。每一个线程都会产生一个TLAB，该线程独享的工作区域，java虚拟机使用这种TLAB区来避免多线程冲突问题，提高了对象分配的效率。TLAB空间一般不会太大，当大对象无法在TLAB分配时，则会直接分配到堆上。（建议不要修改，在JDK1.7之后，会自动调整) -XX:+UseTLAB 使用TLAB -XX:+TLABSize 设置TLAB大小 -XX:TLABRefillWasteFraction 设置维护进入TLAB空间的单个对象大小，他是一个比例值，默认为64，即如果对象大于整个空间的1/64，则在堆创建对象。 XX:+PrintTLAB 查看TLAB信息 XX:ResizeTLAB 自调整TLABRefillWasteFraction阀值。 示例Test07 对象创建流程图jvm根据数据的大小，参数的设置，决定如何创建分配，以及其位置 垃圾收集器串行垃圾回收器串行回收器是指使用单线程进行垃圾回收的回收器。每次回收时，串行回收器只有一个工作线程，对于并行能力较弱的计算机来说，串行回收器的专注性和独占性往往有更好的性能表现。串行回收器可以在新生代和老年代使用，根据作用于不同的堆空间，分为新生代回收器和老年代回收器。 使用-XX:+UseSerialGC 参数可以设置使用新生代串行回收器和老年代串行回收器 并行垃圾回收器并行回收器在串行回收器基础上做了改进，他可以使用多个线程同时进行垃圾回收，对于计算能力强的计算机而言，可以有效的缩短垃圾回收所需的实际时间。 ParNew回收器ParNew回收器是一个工作在新生代的垃圾收集器，他只是简单的将串行回收器多线程化，他的回收策略和算法和串行回收器一样。 使用：-XX:+UseParNewGC 新生代ParNew回收器，老年代则使用串行回收器。ParNew回收器工作时的线程数量可以使用 -XX:ParallelGC Threads参数指定，一般最好和计算机的CPU相当，避免过多的想成影响性能。 ParallelGC回收器（侧重于吞吐量，适合于电商平台多并发的情况）新生代ParallelGC回收器，使用了复制算法的收集器，也是多线程独占形式的收集器，但ParallelGC回收器有个非常重要的特点，就是它非常关注系统的吞吐量。 提供了俩个非常关键的参数控制系统的吞吐量： -XX:MaxGCPauseMillis：设置最大垃圾收集停顿时间，可用把虚拟机在GC停顿的时间控制在MaxGCPauseMillis范围内，如果希望减少GC停顿时间可以将MaxGCPauseMillis设置的很小，但是会导致GC频繁，从而增加了GC的总时间，降低了吞吐量。所以需要根据实际情况设置改值。 -XX:GC TimeRatio：设置吞吐量大小，它是一个0到100之间的整数，默认情况下他的取值是99，那么系统将花费不超过1/(1+n)的时间用于垃圾回收，也就是1/(1+99)=1%的时间。 另外还可以指定-XX:+UseAdaptiveSizePolicy打开自适应模式，在这种模式下，新生代的大小、eden、from/to的比例，以及晋升老年代的对象年龄参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。 老年代ParallelOldGC回收器也是一种多线程的回收器，和新生代的ParallelGC回收器一样，也是一种关注吞吐量的回收器，它使用了标记压缩算法进行实现。 XX:+UseParallelOldGC 进行设置 XX:+ParallelGC Threads 也可以设置垃圾收集时的线程数量。 CMS回收器（最主流）CMS 全称为：Concurrent Mark Sweep 意为并发标记清除，它使用的是标记清除法，主要关注系统停顿时间。 使用：+XX:+UseConcMarkSweepGC 进行设置 使用：+XX:+ConcGCThreads 设置并发线程数量。 CMS并不是独占的回收器（GC过程中，应用程序仍然在不停地工作，但这样又会有新的垃圾不断的产生，所以在使用CMS的过程中应该确保内存足够可用）。CMS不会等到应用程序饱和的时候才去回收垃圾，而是在某一阀值的时候开始回收，回收阀值可用指定的参数进行设置，-XX:CMSInitiatingOccupancyFraction来设定，默认为68，也就是说当老年代的空间使用率达到68%的时候，会执行CMS回收。如果内存使用率增长的很快，在CMS执行的过程中，已经出现了内存不足的情况，此时CMS回收就会失败，虚拟机将启动老年代串行回收器进行垃圾回收，这会导致应用程序中断，直到垃圾回收完成后才会正常工作，这个过程GC的停顿时间可能较长，所以-XX:CMSInitiatingOccupancyFraction的设置要根据实际的情况。 我们知道，标记清除算法有个缺点就是存在内存碎片的问题，那么CMS有个参数设置-XX:+UseCMSCompactAtFullCollection可以使CMS回收完成之后进行一次碎片整理，-XX:+CMSFullGCsBeforeCompaction参数设置进行多少次CMS回收之后，对内存进行一次压缩。 G1回收器 Tomcat性能影响体验、性能监控工具通过JMeter对Tomcat增加压力 不同的虚拟机参数应该会有不同的表现 测试代码：web程序","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-网络编程和netty","date":"2017-03-24T05:55:13.000Z","path":"2017/03/24/Java架构师-网络编程和netty/","text":"网络编程基础篇Socket Socket又称“套接字”，应用程序通常通过“套接字”向网络发送请求或者应答网络请求。 Socket和ServerSocket类库位于java.net包中。ServerSocket用于服务器端，Socket是建立网络连接时使用的。在连接成功时，应用程序两端都会产生一个Socket实例，操作这个实例，完成所需的会话。对于一个网络连接来说，套接字是平等的，不因为在服务器端或在客户端而产生不同的级别。不管是Socket还是ServerSocket它们的工作都是通过SocketImpl类及其子类完成的。 套接字之间的连接过程可以分为四个步骤：服务器监听，客户端请求服务器，服务器确认，客户端确认，进行通信。 服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。 客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后向服务器端套接字提出连接请求。 服务器端连接确认：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就相应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端。 客户端连接确认：一旦客户端确认了此描述，连接就建立好了。双方开始通信。而服务器端套接字继续处于监听状态，继续接受其他客户端套接字的连接请求。 windows 一般支持1000个线程，Linux辞职2000个线程。 jdk1.5之前，利用伪异步方式（线程池+队列），解决socket创建client端过多，服务器撑爆问题。jdk1.6通过nio方式。伪异步IO 采用线程池和任务队列可以实现一种伪异步的IO通信框架。我们学过连接池的使用和队列的使用，其实就是将客户端的socket封装成一个task任务（实现runnable接口的类）然后投递到线程池中去，配置相应的队列进行实现。 基本概念 IO（BIO）和NIO区别IO:阻塞型IO,面向流，无选择器NIO:非阻塞型IO,面向缓冲，选择器 阻塞概念：应用程序在获取网络数据时候，如果网络传输数据很慢，那么程序就一直等着，直到传输完为止。 非阻塞概念：应用程序直接可以获取已经准备就绪好的数据，无需等待。 BIO为同步阻塞形式，NIO为同步非阻塞形式。NIO并没有实现异步，在JDK1.7之后，升级NIO包，支持异步非阻塞通信模型即NIO2.0(AIO)。 同步时，应用程序会直接参与IO读写操作，并且我们的应用程序会直接阻塞到某一个方法上，直到数据准备就绪；或者采用轮询的策略实时检查数据的就绪状态例如NIO，如果就绪则获取数据。 异步时，则所在的IO读写操作交给操作系统处理，与我们的应用程序没有直接关系，我们应用程序不需要关心IO读写，当操作系统完成了IO读写操作时，会给我们应用程序发送通知，我们应用程序直接拿走数据即可。 NIONIO本质就是避免原始的TCP建立连接使用3次握手的操作，减少连接的开销。 Buffer（缓冲区）Buffer是一个对象，它包含一些要写入或者要读取的数据。在NIO类库中加入Buffer对象，体现了新库与原IO的一个重要的区别。在面向流的IO中，可以将数据直接写入或读取到Stream对象中。在NIO库中，所有数据都是用缓冲区处理的（读写）。缓冲区实质上是一个数组，通常它是一个字节数组（ByteBuffer），也可以使用其他类型的数组。这个数组为缓冲区提供了数据的访问读写等操作属性，如位置、容量、上限等概念，参考api文档。 Buffer类型：我们最常用的就是ByteBuffer，实际上每一种java基本类型都对应了一种缓冲区（除了Boolean类型） 。ByteBuffer，CharBuffer，ShortBuffer，intBuffer，LongBuffer，FloatBuffer，DoubleBuffer。 put方法执行完，要调用下flip方法来恢复未知 Channel(通道) 通道（Channel），它就像自来水管道一样，网络数据通过Channel读取和写入，通道与流不同之处在于通道是双向的，而流只是一个方向上移动（一个流必须是InputStream或者OutputStream的子类），而通道可以用于读、写或者二者同时进行，最关键的是可以与多路复用器结合起来，有多种的状态位，方便多路复用器去识别。事实上通道分为两大类，一类是网络读写的（SelectableChannel），一类是用于文件操作的（FileChannel），我们使用的SocketChannel和ServerChannel都是SelectableChannel的子类。 Selector（选择器，多路复用器） NIO编程的基础，非常重要。多路复用器提供选择已经就绪的任务的能力。简单说，就是Selector会不断地轮询注册在其上的通道（Channel），如果某个通道发生了读写操作，这个通道就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以取得就绪的Channel集合，从而进行后续的IO操作。 一个多路复用器可以负责成千上万Channel通道，没有上限，这也是JDK使用了epoll代替了传统的select实现，获得连接句柄没有限制。这也就意味着我们只要一个线程负责Selector的轮询，就可以接入成千上万个客户端，这是JDK NIO库的巨大进步。 Selector线程就类似一个管理者（Master），管理了成千上万个管道，然后轮询哪个管道的数据已经准备好，通知cpu执行IO的读取或写入操作。 Selector模式：当IO事件（管道）注册到选择器以后，selector会分配给每个管道一个值，相当于标签。selector选择器是以轮询的方式进行查找注册的所有IO事件（管道），当我们的IO事件（管道）准备就绪后，select就会识别，会通过key值来找到相应的管道，进行相关的数据处理操作（从管道里读或写数据，写到我们的数据缓冲区中）。 每个管道都会对选择器进行注册不同的事件状态，以便选择器超找。SelectionKey.OP_CONNECT, SelectionKey.OP_ACCEPT,SelectionKey.OP_READ,SelectionKey.OP_WRITE。 NIO通信步骤 AIOAIO编程，在NIO基础之上引入了异步通道的概念，并提供了异步文件和异步套接字通道的实现，从而在真正意义上实现了异步非阻塞，之前我们学习的NIO只是非阻塞而并非异步。而AIO它不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写，从而简化了NIO编程模型。也可以称之为NIO2.0，这种模式才真正的属于我们异步非阻塞的模型。 AsynchronousServerSocketChannel AsynchronousScoketChannel 总结 Socket进化史 BIO（同步阻塞）:就是传统Socket编程，有一个阻塞模型。只要client端和server端要建立一个tcp连接都需要三次握手，三次握手本身性能上就很浪费性能，然后每次我开始必须服务器端先启动，服务器端有个accept方法，使服务器整个程序阻塞着，然后有一个client端进来，accept方法就返回一个Socket对象，然后通过一个新的Thread做数据处理。 NIO（同步非阻塞）:有一个Client端想接入Server端，两端不是直接连接，通过一个selector。服务器端的通道注册到这个Selector上，然后客户端的一些通道都得注册到这个Selector。然后轮询这个Selector，把里面Channel根据不同状态处理相对应的事务。一个Selector（也就是可以通过一个线程）接入成千上万个客户端，接入过程需要自己实现。 AIO（异步非阻塞）:自己有一堆线程组，轮询过程不用代码写，里面已经封装好了，有一个client端过来，通过线程组某一个线程和client端接入。接入之后，会有代码和client端读写实际处理操作。在BIO里面，读写操作是new一个Thread去单独交互，这样很浪费性能。在AIO是new一个对象ServerCompletionHandler，但是只支持接入一个对象，接入一个对象后程序就停了，所以如果想接入第二个对象，需要在handler里面进行递归操作。并且在Handler里面处理读写 Netty为什么选择Netty？简单，实现Socket通信不必去需写复杂的代码逻辑，不用去考虑性能，不需要考虑编解码问题，半包读写问题等。得到成百上千的商业/商用项目验证，如Hadoop的RPC框架Avro，和JMS框架，RocketMQ，还有主流的分布式通信框架Dubbox等等。 学习网址：http://ifeve.com/netty5-user-guide/ 示例：test Netty初步 Netty框架 Netty特性 Netty实现通信的步骤 创建两个NIO线程组，一个专门用于网络事件处理(接受客户端连接)，另一个则进行网络通信读写（实际业务处理）。 创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出数据的缓存大小等等。 创建一个实际处理数据的类ChannelInitializer,并进行初始化的准备工作，比如设置接受传出数据的字符集、格式、已经实际处理数据的接口。 绑定接口，执行同步阻塞方法等待服务器启动即可。 Netty使用场景 放到Tomcat里 利用maven打成jar包，直接放到系统中运行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&lt;build&gt; &lt;!-- 配置文件 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;/classes&lt;/targetPath&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;/classes/META-INF&lt;/targetPath&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;spring-context.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 解决Maven插件在Eclipse内执行了一系列的生命周期引起冲突 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt; &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;lifecycleMappingMetadata&gt; &lt;pluginExecutions&gt; &lt;pluginExecution&gt; &lt;pluginExecutionFilter&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;versionRange&gt;[2.0,)&lt;/versionRange&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;/pluginExecutionFilter&gt; &lt;action&gt; &lt;ignore /&gt; &lt;/action&gt; &lt;/pluginExecution&gt; &lt;/pluginExecutions&gt; &lt;/lifecycleMappingMetadata&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!-- 打包jar文件时，配置manifest文件，加入lib包的jar依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classesDirectory&gt;target/classes/&lt;/classesDirectory&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;tpri.mina.execute.Main&lt;/mainClass&gt; &lt;!-- 打包时 MANIFEST.MF文件不记录的时间戳版本 --&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;.&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;type&gt;jar&lt;/type&gt; &lt;includeTypes&gt;jar&lt;/includeTypes&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/lib &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; HelloWorld 对于ChannelOption.SO_BACKLOG的讲解 服务器端TCP内核模块维护2个队列，我们称之为A，B 客户端向服务器端connect的时候，会发送带有SYN标志的包（第一次握手） 服务器收到客户端发来的SYN的时，向客户端发送SYN ACK确认（第二次握手） 此时TCP内核模块把客户端连接加入到A队列中，然后服务器收到客户端发过来的ACK时（第三次握手）， TCP内核模块把客户端连接从A队列移到B队列，连接完成，应用程序的accept回返回。 也就是accept从B队列中取出完成三次握手的连接。 A队列和B队列的长度之和是BACKLOG。当A,B队列的长度之和大于BACKLOG的时候，新连接将会被TCP内核拒绝。 所以，如果BACKLOG过小，可能会出现accept速度跟不上，A，B队列满了，导致新的客户端无法连接 要注意的是：BACKLOG对程序支持的连接数并没有影响，BACKLOG只是影响了还没有被accept取出的连接。 ChannelHandlerAdapter的channelRead方法中的Object，如果没有write方法，最后要释放。 1ReferenceCountUtil.release(msg); 一个ServerBootstrap可以绑定多个端口，增加了接收数据能力 Netty核心技术之（TCP拆包和粘包问题）熟悉TCP编程的可能都知道，无论是服务器端还是客户端，当我们读取或者发送数据的时候，都需要考虑TCP底层的粘包/拆包机制。 TCP是一个“流”协议，所谓流就是没有界限的遗传数据。大家可以想象下如果河里的水就好比数据，他们是连成一片的，没有分界线，TCP底层并不了解上层的业务数据具体的含义，它会根据TCP缓冲区的实际情况进行包的划分，也就是说，在业务上，我们一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的TCP粘包、拆包问题。（例如，实际业务发送“ABC DEF GHI”这些数据分成“ABC”.”DEF”,”GHI”三个包发送,但实际TCP是“流”协议，实际发送可能是“AB”,”DEFG”,”HI”） TCP粘包、拆包问题产生的原因： 应用程序write写入的字节大小大于套接口发送缓冲区的大小 进行MSS大小的TCP分段 以太网帧的payload大于MTU进行IP分片 TCP粘包、拆包问题解决方案（前两种解决方案netty已经实现） (1) 消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。（netty解决方案：FixedLengthFrameDecoder【定长】） 12345678910.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; //设置定长字符串接收 sc.pipeline().addLast(new FixedLengthFrameDecoder(5)); //设置字符串形式的解码,write时候还是buffer但是handler接收时候可以直接强转成string sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ServerHandler()); &#125; &#125;); (2) 在包尾部增加特殊字符进行分割，例如加回车等（netty解决方案：分隔符类DelimiterBasedFrameDecoder【自定义分隔符】） 1234567891011 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; //设置特殊分隔符 ByteBuf buf = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); //设置字符串形式的解码,write时候还是buffer但是handler接收时候可以直接强转成string sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ServerHandler()); &#125;&#125;); (3) 将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理（自定义协议【百度搜索netty自定义协议】） Netty核心技术之（编解码技术【传递对象】）编解码技术，说白了就是java序列化技术，序列化的目的就两个，第一进行网络传输，第二对象持久化。 虽然我们可以使用java进行对象序列化，netty去传输，但是java序列化的硬伤太多，比如java序列化没法跨语言、序列化后码流太大、序列化性能太低等等。 主流的编解码框架 JBoss的Marshalling包 google的Protobuf 基于Protobuf的Kyro（dubbo中会讲解） MessagePack框架 最简单的跨平台传递对象方法是使用json 序列化的时候，客户端，服务端都要有要序列化的对象，并且包名，类名都一样 兼容操作系统的分隔符：File.separatorChar JBoss MarshallingJBoss Marshalling是一个java对象序列化包，对JDK默认的序列化框架进行了优化，但又保持跟java.io.Serializable接口的兼容，同时增加了一些可调的参数和附加特性。类库：jboss-marshalling-1.3.0、jboss-mashalling-serial-1.3.0 下载地址：https://www.jboss.org/jbossmarshalling/downloads 示例：Netty+Marshalling 1234567.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder()); sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder()); sc.pipeline().addLast(new ServerHandler()); &#125; &#125;); MarshallingFactory 123456789101112131415161718192021222324252627282930313233343536/** * Marshalling工厂 */public final class MarshallingCodeCFactory &#123; /** * 创建Jboss Marshalling解码器MarshallingDecoder * @return MarshallingDecoder */ public static MarshallingDecoder buildMarshallingDecoder() &#123; //首先通过Marshalling工具类的精通方法获取Marshalling实例对象 参数serial标识创建的是java序列化工厂对象。 final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory(\"serial\"); //创建了MarshallingConfiguration对象，配置了版本号为5 final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); //根据marshallerFactory和configuration创建provider UnmarshallerProvider provider = new DefaultUnmarshallerProvider(marshallerFactory, configuration); //构建Netty的MarshallingDecoder对象，俩个参数分别为provider和单个消息序列化后的最大长度，解码大于这个长度就不处理 MarshallingDecoder decoder = new MarshallingDecoder(provider, 1024 * 1024 * 1); return decoder; &#125; /** * 创建Jboss Marshalling编码器MarshallingEncoder * @return MarshallingEncoder */ public static MarshallingEncoder buildMarshallingEncoder() &#123; final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory(\"serial\"); final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); MarshallerProvider provider = new DefaultMarshallerProvider(marshallerFactory, configuration); //构建Netty的MarshallingEncoder对象，MarshallingEncoder用于实现序列化接口的POJO对象序列化为二进制数组 MarshallingEncoder encoder = new MarshallingEncoder(provider); return encoder; &#125;&#125; Netty的UDP实现Netty的WebSocket实现webSocket将网络套接字引入到了客户端和服务端，众所周知，我们实现聊天功能，可能需要古老的Socket技术，亦或者是古老的DWR框架，方向Ajax技术，再有可能就是Comet服务器推技术，H5的webSocket很轻松的可以进行聊天功能实现，Netty和H5的WebSocket结合非常的简单，Netty为我们封装了其协议类，我们可以很方便的进行使用。 ws特点： 单一的TCP连接，双方可通信 对代理，防火墙和路由器透明 无头部信息、Cookie和身份验证 无安全开销 通过ping/pong帧保持链路激活 服务器可主动传递消息给客户端，不再需要客户端轮询 最佳实践（数据通信，心跳检测）数据通信 我们需要考虑的问题是两台机器（甚至多台）使用Netty是怎样进行通信，个人大体上分为三类： 第一种，使用长连接通道不断开的形式进行通信，也就是服务器和客户端的通道一直处于开启状态，如果服务器性能足够好，并且我们的客户端数量也比较少的情况下，还是推荐这种方式的。 第二种，一次性批量提交数据，采用短连接方式。也就是我们会把数据保存在本地临时缓冲区或者临时表里，当达到临界值时进行一次性批量提交，又或者根据定时任务轮询提交，这种情况弊端是做不到实时性传输，在对实时性要求不高的应用程序中可以推荐使用。 第三种，我们可以使用一种特殊的长连接，在指定某一时间之内（比如设置60秒），服务器与某台客户端没有任何通信（60秒内没有任何通信），则断开连接。下次连接则是客户端向服务器发送请求的时候，再次建立连接。但是，这种模式我们需要考虑2种因素： (1）如何在超时（即服务器和客户端没有任何通信）后关闭通道？关闭通道后我们又如何再次建立连接？ 解决方案:如下代码 1234567891011121314151617181920 public void connect()&#123; try &#123; this.cf = b.connect(\"127.0.0.1\", 8765).sync(); System.out.println(\"远程服务器已经连接, 可以进行数据交换..\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;public ChannelFuture getChannelFuture()&#123; if(this.cf == null)&#123; this.connect(); &#125; if(!this.cf.channel().isActive())&#123; this.connect(); &#125; return this.cf;&#125; （2）客户端宕机，我们无需考虑，下次客户端重启之后我们就可以与服务器建立连接，但是服务器宕机时，我们的客户端如何与服务器建立连接？ 解决方案:写个脚本，定时轮询，给服务器发连接，看服务器是否启动，启动了就重新创立连接。如果客户端是java的，可以通过spring的定时任务，定时看服务器好没好，好则保持通讯 //两端都需要加，当服务器端与客户端在指定时间以上没有任何进行通信，则会关闭响应的通道，主要为减小服务端资源占用 sc.pipeline().addLast(new ReadTimeoutHandler(5)); 两端如果client端和server端设置超时时间不一样，则短的一方先单一断开，等时间长的一方时间到，双方才会断开连接。 心跳检测我们使用Socket通信一般经常会处理多个服务器之间的心跳检测，一般来讲我们去维护服务器集群，肯定有一台（或几台）服务器主机（Master），然后还应该有N台从节点（Slave），那么我们主机肯定要时时刻刻知道自己下面的从服务器的各方面情况，然后进行实时监控的功能，这个在分布式架构里叫做心跳检测或者说心跳监控。最佳处理方案，建议使用一些通信框架进行实现,Netty就可以去做这样一件事。一般每隔5秒-10秒心跳一次。 如果跨域的话，还要考虑安全问题，可以采用SSL或者其他方案解决。 从节点调用通道激活方法，把auth发送给主节点 主节点认证后，主从节点才可以通信 使用sigar.jar包方法获取系统信息。Sigar API 提供一个方便的接口来收集系统信息，如： 系统内存，页面交换，cpu，平均负载，运行时间，登录信息 每个进程占用的内存，cpu，帐号信息，状态，参数，环境，打开的文件 文件系统探测和度量 网络接口探测，配置信息和度量 网络路由和连接表 使用sigar.jar需要把hyperic-sigar-1.6.4.zip文件中找到sigar-bin/lib目录下对应系统的文件到JAVA_HOME/bin目录下或者JAVA_HOME/jre/bin目录,否则获取不到信息 Netty实现文件服务器（基于HTTP协议） Netty文件上传","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"Java架构师-并发编程","date":"2017-03-19T12:17:58.000Z","path":"2017/03/19/Java架构师-并发编程/","text":"并发编程1.线程基础线程安全 线程安全概念：当多个线程访问某一个类（对象或方法）时，这个类始终都能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。 synchronized:可以在任意对象及方法上加锁，而加锁的这段代码称为“互斥去”或“临界区” 当多个线程访问myThread的run方法时，以排队的方式进行处理(这里排队是按照CPU分配的先后顺序而定的)，一个线程想要执行synchronized修饰的方法里的代码，首先是尝试获得锁，如果拿到锁，执行synchronized代码体内容；拿不到锁，这个线程就会不断的尝试获得这把锁，直到拿到为止，而且是多个线程同时去竞争这把锁。（也就是会有锁竞争的问题）。 多个线程同时竞争一把锁会增加cpu的消耗，有可能出现计算缓慢，严重宕机，所以一定要规划好线程的数目 关键字synchronized取得的锁都是对象锁，而不是把一段代码（方法）当做锁，哪个线程先执行synchronized关键字的方法，哪个线程就持有该方法所属对象的锁（Lock），两个对象，线程获得的就是两个不同的锁，他们互不影响（如果两个对象使用一把锁，可以在锁前面添加static,如果是对象也可以使用static volatile这样可以不用synchronized）见MultiSyncCommonOneTest.java）。 脏读 在我们对一个对象的方法加锁的时候，需要考虑业务的整体性，即为setValue/getValue方法同时加载synchronized同步关键字，保证业务(service)的原子性，不然会出现业务错误。 数据库特性：A(原子性)C(一致性)I（隔离性）D（持久性） synchronized代码块及细节 Oracle写存储过程的时候，要加BEGIN和END才能处理EXCEPTION 多线程有异常终止操作两种方式 使用InterruptedException 在异常体里面throw new RuntimeException() 使用synchronized声明的方法在某些情况下是有弊端的，比如A线程调用同步的方法执行一个很长时间的任务，那么B线程就必须等待比较长的时间才能执行，这样的情况下可以使用synchronized代码块去优化代码执行时间，也就是通常所说的减小锁的粒度。 锁注意事项： synchronized可以使用任意的Object进行加锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 public class ObjectLock &#123; public void method1()&#123; synchronized (this) &#123; //对象锁 try&#123; System.out.println(\"do mehtod1\"); Thread.sleep(2000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; public void method2()&#123; synchronized (ObjectLock.class) &#123; //类锁 try&#123; System.out.println(\"do mehtod2\"); Thread.sleep(2000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; Object lock = new Object(); public void method3()&#123; synchronized (lock) &#123; //任何对象锁 try&#123; System.out.println(\"do mehtod3\"); Thread.sleep(2000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args)&#123; final ObjectLock objectLock = new ObjectLock(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; objectLock.method1(); &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; objectLock.method2(); &#125; &#125;); Thread t3 = new Thread(new Runnable() &#123; @Override public void run() &#123; objectLock.method3(); &#125; &#125;); t1.start(); t2.start(); t3.start(); &#125;&#125; 不要使用String的常量加锁，会出现死循环的问题 12345678910111213141516171819202122232425262728synchronized (\"常量锁\") //死循环，因为常量引用的是同一个地址&lt;!--synchronized (new String（\"常量锁\"）) //这种方式不会死循环--&gt;&#123; try&#123; System.out.println(\"do mehtod3\"); Thread.sleep(2000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;``` - 锁对象改变的问题，当使用一个对象进行加锁的时候，要注意对象本身发生改变的时候，那么持有的锁就不同。如果“对象本身”不发生改变，那么依然是同步的，即使是对象的属性（例如User对象的name和age属性）发生了改变（属性改变不影响锁的同步）。如果对象本身改变了，则不是同步，其他线程就进入了。```JavaString lock = \"lock\";public void method()&#123; synchronized (lock) &#123; try&#123; System.out.println(\"do mehtod); //锁对象发生了改变，则其他等待的线程可以进入 lock = \"change lock\"; Thread.sleep(2000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; 2. Volatile关键字概念，线程优化执行流程，内部原理讲解 volatile概念：volatile关键字的主要作用是使变量在多个线程间可见。 volatile关键字的非原子性 JDK1.5以后，对每个线程(Thread)做了一个优化,加了一块独立的内存运行空间，这一块独立内存空间存放主内存的一些引用，也就是当前线程引用的一些变量。线程使用的时候，直接从自身的独立内存空间取数据。所以下图中，while循环不会被终止（创建在子线程，改的值改的是主线程的isRunning的值，所以不会终止）。上图，如果想停止，解决办法1private volatile boolean isRunning = true; volatile虽然拥有多个线程的可见性，但是却不具备同步性（也就是原子性)（count++方法，每次叠加1000次，分10个线程执行，最后一个线程执行完毕最终值不是10000）。可以算是一个轻量级的synchronized,性能要比synchronized强很多，不会造成阻塞（在很多开源框架里，比如netty的底层代码就大量使用volatile，可见netty性能一定是不错的）。这里需要注意：一般volatile用于只针对于多个线程可见的变量操作，并不能代替synchronized的同步功能。如果保证原子性可以用AtomicInteger. 123private static AtomicInteger count = new AtomicInter(0); //count初始化值0//使用incrementAndGet（)方法叠加count.incrementAndGet(); volatile只具有可见性，没有原子性。要实现原子性建议使用atomic类的系列对象，支持原子性操作（注意atomic类只保证本身方法的原子性，并不保证多次操作的原子性）。 并发编程下的多线程间通信概念wait，notify，线程经典面试题 使用wait/notify方法实现线程间通信。（这两个方法都是object的类的方法，换句话说java的所有的对象都提供了这两个方法） wait和notify必须配合synchronized关键字使用 wait方法释放锁，notify方法不释放锁（wait方法调用后，其他线程可以拿到锁执行方法；notify方法则必须等到此线程synchronized代码块执行完，其他线程才能拿到锁进行执行） 使用示例：参考waitnotify 模拟底层阻塞队列（queue）实现讲解上面内容实践操作，示例：MyQueue ThreadLocal ThreadLocal:线程局部变量，是一种多线程间并发访问变量的解决方案。与其synchronized等加锁的方式不同，ThreadLocal完全不提供锁，而使用以空间换时间的手段，为每个线程提供变量的独立副本，以保障线程安全。 从性能上说，ThreadLocal不具有绝对的优势，在并发不是很高的时候，加锁的性能会更好，但作为一套与锁无关的线程安全解决方案，在高并发量或者竞争激烈的场景，使用ThreadLocal可以在一定程度上减少锁竞争。 单例和多线程结合使用单例模式：最常见的就是饥饿模式和懒汉模式。一个直接实例化对象，一个在调用方法时进行实例化对象。在多线程模式中，考虑到性能和线程安全问题，我们一般选择下面两种比较经典的单例模式，在性能提高的同时,又保证了线程安全。 dubble check instance 123456789101112131415161718192021public class DubbleSingleton &#123;private static DubbleSingleton ds;public static DubbleSingleton getInstance()&#123; if(ds == null)&#123; try &#123; //模拟初始化对象的准备时间... Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (DubbleSingleton.class) &#123; if(ds == null)&#123; ds = new DubbleSingleton(); &#125; &#125; &#125; return ds; &#125;&#125; static inner class (简单，安全) 1234567891011public class InnerSingleton &#123; private static class Singletion &#123; private static Singletion single = new Singletion(); &#125; public static Singletion getInstance()&#123; return Singletion.single; &#125; &#125; 3 同步类容器同步类容器 同步类容器都是线程安全的，但在某些场景下可能需要加锁来保护复合操作。复合类操作如：迭代、跳转、以及条件运算。这些复合操作在多线程并发地修改容器时，可能会表现出意外的行为，最经典的便是ConcurrentModificationException。原因是当容器迭代的过程中，被并发地修改了内容，这是由于早起迭代器设计的时候并没有考虑并发修改的问题。 同步类容器：如古老的Vector,HashTable。这些容器的同步功能其实都是有JDK的Collections.synchronized ** 等方法去创建实现的。其底层的机制无非就是用传统的synchronized关键字对每个公用的方法都进行同步，使得每次只能有一个线程访问容器的状态。这很明显不满足我们今天互联网时代高并发的需求，在保证线程安全的同时，也必须有足够好的性能 12//HashMap线程不安全，但被修饰后返回的就是线程安全的mapMap&lt;Object,Object&gt; map = Collections.synchronizedMap(new HashMap&lt;&gt;()); 并发类容器：在jdk5.0之后提供了多种并发类容器来替代同步类容器从而改善性能。同步类容器的状态都是串行化的。他们虽然实现了线程安全，但是严重降低了并发性，在多线程环境时，严重降低了应用程序的吞吐量。 并发类容器是专门针对并发设计的，使用ConcurrentHashMap来代替给予散列的传统的HashTable，而且在ConcurrentHashMap中，添加了一些常见复合操作的支持。以及使用了CopyOnWriteArrayList代替Vector，并发地CopyOnWriteArraySet，以及并发的Queue，ConcurrentLinkedQueue和LinkedBlockingQueue，前者是高性能的队列，后者是以阻塞形式的队列。 Concurrent集合类讲解与底层原理实现 ConcurrentMap两个重要实现 ConcurrentHashMap ConcurrentSkipListMap（支持并发排序功能，密闭ConcurrentHashMap） ConcurrentHashMap内部使用段（Segment）来表示这些不同的部分，每个段其实就是一个小的HashTable，他们有自己的锁。只要多个修改操作发生在不同的段上，他们就可以并发进行。把一个整体分成了16个段（Segment）。也就是最高支持16个线程的并发修改操作。这也是在多线程场景时减少锁的粒度从而降低锁竞争的一种方案。并且代码中大多共享变量使用volatile关键字声明，目的是第一时间获取修改的内容，性能非常好。 Copy-On-Write简称COW，是一种用于程序设计中的优化策略。JDK里的COW容器有两种：CopyOnWriteArrayList和CopyOnWriteArraySet，COW容器非常有用，可以在非常多的并发场景中使用到。适用于读多写少的操作。写多的情况建议使用ArrayList，Set加锁方式实现同步 CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里刚添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发地读，而不需要加锁，因为当前容器不会添加任何元素。而且COW容器的写操作已经加锁，不会出现写操作数据不一致问题情况。CopyOnWrite也是一种读写分离的思想，读和写不同的容器。 各类并发Queue MQ适用场景：生产端快，消费端慢的情况或生产端产生大量数据，消费端来不及消费的情况。消费者快的情况可以用netty或者mina这种基于点对点tcp通讯的框架。 阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往空的队列插入新的元素。同样，试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，直到其他的线程使队列重新变得空闲起来，如从队列中移除一个或者多个元素，或者完全清空队列. ConcurrentLinkedQueue：适用于高并发场景下的队列，通过无锁的方式，实现了高并发状态下的高性能。是高性能队列但不是阻塞队列。先进先出原则，queue里面元素不能为null。 add()和offer() 都是加入元素。（ConcurrentLinkQueue中，这两种方法没有任何区别）。 poll()和peek（） 都是取头元素节点，区别在于前者会删除元素，后者不会 BlockingQueue接口 ArrayBlockingQueue:阻塞队列，有界队列，不能读写分离。（队列满了再添加会抛出Queue full异常）。适用于Queue大，有峰值的情况。 LinkedBlockingQueue：阻塞队列，无界队列，能读写分离。适合Queue不大情况。 SynchronousQueue：不允许添加任何元素（不可以add()和offer()，只有阻塞了add（）才不会报异常，如下图。这是因为不是往队列添加，而是直接丢给阻塞的线程处理）。适用于数据量少，即来即走的情况。 DelayQueue：带有延迟时间的Queue，元素只有当其执行的延迟时间到了，才能从队列中获取到该元素。没有大小限制，使用场景，比如对缓存超时的数据进行移除，任务超时处理，空闲连接的关闭等等。(参考UseDelayQueue) PriorityBlockingQueue：不遵循先进先出原则，遵循比较原则，优先级由传入的对象Compator对象决定，也就是传入队列的对象必须实现Comparable接口。（参考UsePriorityBlockingQueue）循环输出并没有排序，只有每次take时候就排序，取出优先级最高的。 Deque 双端队列，允许在队列的头部或尾部进行出队和入队操作。 LinkedBlockingDeque是一个线程安全的双端队列实现，可以说他是最为复杂的一种队列，在内部实现维护了前端和后端节点，但是其没有实现读写分离，因此同一时间只能有一个线程对其进行操作。在高并发中性能远低于其他BlockingQueue。更要低于ConcurrentLinkedQueue，在jdk早期有一个非线程安全的Deque就是ArrayDeque，java6里添加了LinkedBlockingDeque来弥补多线程场景下线程安全的问题。 4. 多线程的设计模式Future模式讲解，即异步加载(见future ) Future模式类似于商品订单。比如在网购时，当看中某一件商品时，就可以提交订单，当订单处理完成后，在家里等待商品送货上门即可。或者说更形象的我们发送Ajax请求的时候，页面是异步的进行后台处理，用户无须一直等待请求的结果，可以继续浏览或操作其他内容。 Master-Worker模式(见masterworker) 并行计算，使用多线程对同一个对象进行队列操作，处理完出队 Master-Worker模式是常用的并行计算模式。它的核心思想是系统由两类进程协作工作：Master进程和Worker进程。Master负责接收和分配任务，Worker负责处理子任务。当各个Worker子进程处理完成后，会将结果返回给Master，由Master做归纳和总结。其好处是能将一个大任务分解成若干个小任务，并行执行，从而提高系统的吞吐量。 Master-Worker开发引导图 生产者-消费者模式(见productorconsumer) 生产者和消费者也是一个非常经典的多线程模式，我们在实际开发中应用非常广泛的思想概念。在生产-消费模式中，通常有两类线程，即若干个生产者的线程和若干个消费者的线程。生产者线程负责提交用户请求，消费者线程则负责具体处理生产者提交的任务，在生产者和消费者之间通过共享内存缓存区进行通信。 5. 线程池Executor框架 Executors创建线程池的方法： newFixedThreadPool()方法，该方法返回一个固定数量的线程池（创建几个就几个），该方法的线程数始终不变。当有一个任务提交时，若线程池中空闲，则立即执行，若没有，则会被暂缓在一个任务队列中等待有空闲的线程去执行。 newSingleThreadExecutor()方法，创建一个线程的线程池，若空闲则执行，若没有空闲线程则暂缓在任务队列中。 newCachedThreadPool()方法，返回一个可根据实际情况调整线程个数的线程池，不限制最大线程数量，若有空闲的线程执行则执行任务，若无任务则不创建线程。并且每一个空闲线程会在60秒后自动回收。 newScheduledThreadPool()方法，该方法放回一个ScheduledExecutorService对象，但该线程可以指定线程的数量。 自定义线程池(见executors) 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 自定义拒绝策略： 方案1：高峰期过程中，通过HttpUrlConnection创建一个请求，通过这个请求发回传数据方，告诉他一会再发（高峰期不建议这样使用，因为资源已经很紧张了，再发送请求的话也是占用资源的，不过使用HttpClient可以配置请求的线程池数）。 方案2：输出日志或将队列缓存其他地方（不建议缓存其他地方，因为这样还不如给队列扩容），然后有个调度的 job把日志记录的再重新跑一遍。 6. Concurrent.util常用类 CyclicBarrier使用： 假设有一个场景：每个线程代表一个跑步运动员，当运动员都准备好后，才一起出发，只要有一个人没有准备好，大家都等待。示例：UseCyclicBarrier CountDownLatch使用： 他经常用于监听某些初始化操作，等初始化执行完毕后，通知主线程继续工作。使用场景使用于：例如方法中包含1，2方法，1方法要多线程执行，执行完毕后才能执行2方法。在1方法后执行await(),await后面写2方法。示例：UseCountDownLatch Callbale和Future使用： 这个例子其实就是我们之前实现的Future模式。jdk给予一个实现的封装，使用非常简单。示例：UseFuture Future模式非常适合处理耗时很长的业务逻辑时进行使用，可以有效的减少系统的响应时间，提高系统的吞吐量。 Executor的submit()和execute()区别 submit可以传入实现Callable接口的实例对象 submit方法有返回值 7. 高并发 信号量信号量可以用来解决限流（控制系统流量）。拿到信号量的线程可以进入，否则就等待。示例见：UseSemaphore。一般使用Redis进行限流，比如用将用户信息放到Redis缓存里，然后记录用户访问的url，加入1分钟只允许访问60次，如果超过60次提示访问频繁。 解决高并发 网络端 服务器层面（ngix负载均衡（ngix最大只支持2000万并发，超过2000万可以通过ngix结合使用lvs或者haprox来进行负载均衡）-&gt;多个tomcat分流） 业务（业务模块化，在业务上进行并发分流，细粒度） Java层面限流 采用非关系型数据库对关系型数据库降压 峰值计算，进行多轮压力测试后，采用80/20原则，即80%的访问请求在20%的时间内达到。 1峰值qps = （总PV * 80%）/(60*60*24*20%) 例如：100次请求需要10秒完成，则80次请求需要8秒，但希望在20%的时间内完成即1.6秒完成。然后再将总的峰值qps除以单台机器所能承受的最高的gps值，就是所需要机器的数量：1机器数 = 总的峰值qps /峰值qps 秒杀方案 一个单独独立的子系统(和商城主系统独立)，这样即使服务挂了，也不影响主服务。 8. 锁重入锁在需要同步的代码上部分加入锁定，但最后一定不要忘记释放锁定，不然会造成锁永远无法释放，其他线程永远进不来的情况。示例：UseReentrantLock 锁与等待/通知(类似synchronized中的wait和notify，notifyall)我们再使用Lock的时候，可以使用一个新的等待/通知的类，它就是Condition。这个Condition一定是针对具体某一把锁。也就是在只有锁的基础之上才会产生Condition.Condition比synchronized的wait，notify要灵活。因为Condition可以根据一个Lock创建多个Condition,见UseManyCondition。使用场景：两个方法并行计算，方法1中有的方法需要等待方法2计算完毕后，才能继续执行。示例：UseCondition 公平锁与非公平锁12//默认非公平锁Lock lock = new ReentranLock(boolean fair); 公平锁是哪个线程代码先调用则锁放开后调用哪个线程 公平锁浪费性能 ReentrantReadWriteLock读写锁 实现读写分离的锁。在高并发的情况下，尤其是读多写少的情况下，性能要远高于重入锁。示例：ReentrantReadWriteLock 之前学synchronized，ReentrantLock时，我们知道，同一时间内，只能有一个线程进行访问被锁定的代码，那么读写锁则不同，其本质是分成两个锁，即读锁，写锁。在读锁下，多个线程可以并发的进行访问，但是在写锁的时候，只能一个个的顺序访问。 分布式锁 一个服务部署到两台服务器上，相同的服务实现同步。可以使用zookeeper的分布式锁。 锁的优化 避免死锁 减少锁的持有时间 减小锁的粒度 锁的分离 尽量使用无锁的操作，如原子类（Atomic系列类），voliate 无锁并行计算框架（Disruptor） 全球最快最好用的无锁并行计算框架。Martin Fowler在自己网站上写了一篇LMAX架构的文章，在文章中他介绍了LMAX是一种新型零售金融交易平台，它能够以很低的延迟产生大量交易。这个系统是建立在JVM平台上，其核心是一个业务逻辑处理器，它能够在一个线程里每秒处理6百万订单。业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。业务逻辑处理器的核心是Disruptor。 Disruptor是一个高性能的异步处理框架，或者可以认为是最快的消息框架（轻量的JMS），也可以认为是一个观察者模式的实现，或者事件监听模式的实现。 官方学习网站：http://ifeve.com/disruptor-getting-started/ 在Disruptor中，我们想实现hello world 需要如下几步骤： 第一：建立一个Event类 第二：建立一个工厂Event类，用于创建Event类实例对象 第三：需要有一个监听事件类，用于处理数据（Event类） 第四：我们需要进行测试代码编写。实例化Disruptor实例，配置一系列参数。然后我们对Disruptor实例绑定监听事件类，接受并处理数据。 第五：在Disruptor中，真正存储数据的核心叫做RingBuffer(环型缓存)，我们通过Disruptor实例拿到它，然后把数据生产出来，把数据加入到RingBuffer的实例对象中即可。 Disruptor术语说明 RingBuffer: 被看作Disruptor最主要的组件，然而从3.0开始RingBuffer仅仅负责存储和更新在Disruptor中流通的数据。对一些特殊的使用场景能够被用户(使用其他数据结构)完全替代。 Sequence: Disruptor使用Sequence来表示一个特殊组件处理的序号。和Disruptor一样，每个消费者(EventProcessor)都维持着一个Sequence。大部分的并发代码依赖这些Sequence值的运转，因此Sequence支持多种当前为AtomicLong类的特性。 Sequencer: 这是Disruptor真正的核心。实现了这个接口的两种生产者（单生产者和多生产者）均实现了所有的并发算法，为了在生产者和消费者之间进行准确快速的数据传递。 SequenceBarrier: 由Sequencer生成，并且包含了已经发布的Sequence的引用，这些的Sequence源于Sequencer和一些独立的消费者的Sequence。它包含了决定是否有供消费者来消费的Event的逻辑。 WaitStrategy：决定一个消费者将如何等待生产者将Event置入Disruptor。 Event：从生产者到消费者过程中所处理的数据单元。Disruptor中没有代码表示Event，因为它完全是由用户定义的。 EventProcessor：主要事件循环，处理Disruptor中的Event，并且拥有消费者的Sequence。它有一个实现类是BatchEventProcessor，包含了event loop有效的实现，并且将回调到一个EventHandler接口的实现对象。 EventHandler：由用户实现并且代表了Disruptor中的一个消费者的接口。 Producer：由用户实现，它调用RingBuffer来插入事件(Event)，在Disruptor中没有相应的实现代码，由用户实现。 WorkProcessor：确保每个sequence只被一个processor消费，在同一个WorkPool中的处理多个WorkProcessor不会消费同样的sequence。 WorkerPool：一个WorkProcessor池，其中WorkProcessor将消费Sequence，所以任务可以在实现WorkHandler接口的worker吃间移交 LifecycleAware：当BatchEventProcessor启动和停止时，于实现这个接口用于接收通知。 Disruptor印象 把一个个生产的对象（生产一堆）传到Disruptor中的RingBuffer容器中（环形结构），消费者在RingBuffer中注册监听事件，然后RingBuffer一旦有数据就会主动把生产对象传给消费者处理。 理解RingBuffer RingBuffer是一个环，可以把他用做在上下文（线程）间传递数据的buffer。大小必须是2的n次方，否则影响性能（个数是2的n次方更有利于基于二进制的计算机进行计算）。 基本来说，ringbuffer拥有一个序号（Sequence），这个序号指向数组中下一个可用元素。随着你不停地填充这个buffer（可能也会有相应的读取），这个序号会一直增长，直到绕过这个环。 要找到数组中当前序号指向的元素，可以通过mod操作：sequence mod array length = array index（取模操作）以上面的ringbuffer为例（java的mod语法）：12 % 10 = 2。 如果你看了维基百科里面的关于环形buffer的词条，你就会发现，我们的实现方式，与其最大的区别在于：没有尾指针。我们只维护了一个指向下一个可用位置的序号。这种实现是经过深思熟虑的—我们选择用环形buffer的最初原因就是想要提供可靠的消息传递。 我们实现的ring buffer和大家常用的队列之间的区别是，我们不删除buffer中的数据，也就是说这些数据一直存放在buffer中，直到新的数据覆盖他们。这就是和维基百科版本相比，我们不需要尾指针的原因。ringbuffer本身并不控制是否需要重叠。 因为它是数组，所以要比链表快，而且有一个容易预测的访问模式。 这是对CPU缓存友好的，也就是说在硬件级别，数组中的元素是会被预加载的，因此在ringbuffer当中，cpu无需时不时去主存加载数组中的下一个元素。 其次，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。 场景应用 在helloWorld的实例中，我们创建Disruptor实例，然后调用getRingBuffer方法去获取RingBuffer，其实在很多时候，我们可以直接使用RingBuffer，以及其他的API操作。我们一起熟悉下示例： 使用EventProcessor消息处理器 使用WorkerPool消息处理器 在复杂场景下使用RingBuffer（希望P1生产的数据给C1、C2并行执行，最后C1、C2执行结束后C3执行） 多生产者、消费者使用","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"Java架构师","slug":"Java架构师","permalink":"https://centmeng.github.io/tags/Java架构师/"}]},{"title":"再识RxJava庐山真面目","date":"2017-01-17T14:10:35.000Z","path":"2017/01/17/再识RxJava庐山真面目/","text":"再次来记录RxJava，是因为之前对他还是很迷茫。今天看了下相关资料，算是看山是山，看水是水的地步。但是还是没达到看山不是山，看水不是水的境界。下面再来记录下RxJava的庐山真面目。说白了，就是建立观察者和被观察者的关系，这篇文章不做系统讲解，只是mark下被大家忽略的地方。 观察者模式首先，还是老套路，要熟悉RxJava我们要了解观察者模式，在RxJava就是以下两个。通俗点讲，观察者和被观察者就是警察和小偷的区别。小偷动手了，警察才去抓小偷。 Observable 被观察者（小偷） Observer 观察者（警察） Observer和SubscriberObserver还有一个实现它的抽象类，Subscriber。那么他俩的区别在哪里？ Observer 和 Subscriber 是完全一样的。它们的区别对于使用者来说主要有两点： onStart(): 这是 Subscriber 增加的方法。它会在 subscribe 刚开始，而事件还未发送之前被调用，可以用于做一些准备工作，例如数据的清零或重置。这是一个可选方法，默认情况下它的实现为空。需要注意的是，如果对准备工作的线程有要求（例如弹出一个显示进度的对话框，这必须在主线程执行）， onStart() 就不适用了，因为它总是在 subscribe 所发生的线程被调用，而不能指定线程。要在指定的线程来做准备工作，可以使用 doOnSubscribe() 方法，具体可以在后面的文中看到。 unsubscribe(): 这是 Subscriber 所实现的另一个接口 Subscription 的方法，用于取消订阅。在这个方法被调用后，Subscriber 将不再接收事件。一般在这个方法调用前，可以使用 isUnsubscribed() 先判断一下状态。 unsubscribe() 这个方法很重要，因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用，这个引用如果不能及时被释放，将有内存泄露的风险。所以最好保持一个原则：要在不再使用的时候尽快在合适的地方（例如 onPause() onStop() 等方法中）调用 unsubscribe() 来解除引用关系，以避免内存泄露的发生。 Observer 和 Subscriber 具有相同的角色，而且 Observer 在 subscribe() 过程中最终会被转换成 Subscriber 对象 不完整定义的回调建立订阅关系的subscribe（）方法，除了 subscribe(Observer) 和 subscribe(Subscriber) ，subscribe() 还支持不完整定义的回调，RxJava 会自动根据定义创建出 Subscriber 。形式如下： 12345678910111213141516171819202122232425262728Action1&lt;String&gt; onNextAction = new Action1&lt;String&gt;() &#123; // onNext() @Override public void call(String s) &#123; Log.d(tag, s); &#125;&#125;;Action1&lt;Throwable&gt; onErrorAction = new Action1&lt;Throwable&gt;() &#123; // onError() @Override public void call(Throwable throwable) &#123; // Error handling &#125;&#125;;Action0 onCompletedAction = new Action0() &#123; // onCompleted() @Override public void call() &#123; Log.d(tag, &quot;completed&quot;); &#125;&#125;;// 自动创建 Subscriber ，并使用 onNextAction 来定义 onNext()observable.subscribe(onNextAction);// 自动创建 Subscriber ，并使用 onNextAction 和 onErrorAction 来定义 onNext() 和 onError()observable.subscribe(onNextAction, onErrorAction);// 自动创建 Subscriber ，并使用 onNextAction、 onErrorAction 和 onCompletedAction 来定义 onNext()、 onError() 和 onCompleted()observable.subscribe(onNextAction, onErrorAction, onCompletedAction); 简单解释一下这段代码中出现的 Action1 和 Action0。 Action0 是 RxJava 的一个接口，它只有一个方法 call()，这个方法是无参无返回值的；由于 onCompleted() 方法也是无参无返回值的，因此 Action0 可以被当成一个包装对象，将 onCompleted() 的内容打包起来将自己作为一个参数传入 subscribe() 以实现不完整定义的回调。这样其实也可以看做将 onCompleted() 方法作为参数传进了 subscribe()，相当于其他某些语言中的『闭包』。 Action1 也是一个接口，它同样只有一个方法 call(T param)，这个方法也无返回值，但有一个参数；与 Action0 同理，由于 onNext(T obj) 和 onError(Throwable error) 也是单参数无返回值的，因此 Action1 可以将 onNext(obj) 和 onError(error) 打包起来传入 subscribe() 以实现不完整定义的回调。事实上，虽然 Action0 和 Action1 在 API 中使用最广泛，但 RxJava 是提供了多个 ActionX 形式的接口 (例如 Action2, Action3) 的，它们可以被用以包装不同的无返回值的方法。 同理，FuncX 和 ActionX 的区别在 FuncX 包装的是有返回值的方法。 线程控制 —— Scheduler我个人认为，RxJava比较方便的一点，就是线程切换操作，只需要使用Scheduler就可以很简单实现切换线程。在不指定线程的情况下， RxJava 遵循的是线程不变的原则，即：在哪个线程调用 subscribe()，就在哪个线程生产事件；在哪个线程生产事件，就在哪个线程消费事件。如果需要切换线程，就需要用到 Scheduler （调度器）。 我们先了解几个内置的Scheduler： Schedulers.immediate(): 直接在当前线程运行，相当于不指定线程。这是默认的 Scheduler。 Schedulers.newThread(): 总是启用新线程，并在新线程执行操作。 Schedulers.io(): I/O 操作（读写文件、读写数据库、网络信息交互等）所使用的 Scheduler。行为模式和 newThread() 差不多，区别在于 io() 的内部实现是是用一个无数量上限的线程池，可以重用空闲的线程，因此多数情况下 io() 比 newThread() 更有效率。不要把计算工作放在 io() 中，可以避免创建不必要的线程。 Schedulers.computation(): 计算所使用的 Scheduler。这个计算指的是 CPU 密集型计算，即不会被 I/O 等操作限制性能的操作，例如图形的计算。这个 Scheduler 使用的固定的线程池，大小为 CPU 核数。不要把 I/O 操作放在 computation() 中，否则 I/O 操作的等待时间会浪费 CPU。 另外， Android 还有一个专用的 AndroidSchedulers.mainThread()，它指定的操作将在 Android 主线程运行。 有了这几个 Scheduler ，就可以使用 subscribeOn() 和 observeOn() 两个方法来对线程进行控制了。 subscribeOn(): 指定 subscribe() 所发生的线程，即 Observable.OnSubscribe 被激活时所处的线程。或者叫做事件产生的线程。 observeOn(): 指定 Subscriber 所运行在的线程。或者叫做事件消费的线程。 一言不合上代码： 123456789Observable.just(1, 2, 3, 4) .subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程 .observeOn(AndroidSchedulers.mainThread()) // 指定 Subscriber 的回调发生在主线程 .subscribe(new Action1&lt;Integer&gt;() &#123; @Override public void call(Integer number) &#123; Log.d(tag, &quot;number:&quot; + number); &#125; &#125;); 上面这段代码中，由于 subscribeOn(Schedulers.io()) 的指定，被创建的事件的内容 1、2、3、4 将会在 IO 线程发出；而由于 observeOn(AndroidScheculers.mainThread()) 的指定，因此 subscriber 数字的打印将发生在主线程 。事实上，这种在 subscribe() 之前写上两句 subscribeOn(Scheduler.io()) 和 observeOn(AndroidSchedulers.mainThread()) 的使用方式非常常见，它适用于多数的 『后台线程取数据，主线程显示』的程序策略。 下面说下subscribeOn（）和observeOn（）的注意点吧 通过 observeOn() 的多次调用，程序实现了线程的多次切换但subscribeOn() 它是只能调用一次的，不论它的位置放在那里。通俗点将就是，observeOn（）可以多次调用，并且都会切换线程，但subscribeOn（）无论你放在前面还是后面只会被调用一次。如果你调用多个subscribeOn（）只有第一个起作用。 延伸：doOnSubscribe()然而，虽然超过一个的 subscribeOn() 对事件处理的流程没有影响，但在流程之前却是可以利用的。 在前面讲 Subscriber 的时候，提到过 Subscriber 的 onStart() 可以用作流程开始前的初始化。然而 onStart() 由于在 subscribe() 发生时就被调用了，因此不能指定线程，而是只能执行在 subscribe() 被调用时的线程。这就导致如果 onStart() 中含有对线程有要求的代码（例如在界面上显示一个 ProgressBar，这必须在主线程执行），将会有线程非法的风险，因为有时你无法预测 subscribe() 将会在什么线程执行。 而与 Subscriber.onStart() 相对应的，有一个方法 Observable.doOnSubscribe() 。它和 Subscriber.onStart() 同样是在 subscribe() 调用后而且在事件发送前执行，但区别在于它可以指定线程。默认情况下， doOnSubscribe() 执行在 subscribe() 发生的线程；而如果在 doOnSubscribe() 之后有 subscribeOn() 的话，它将执行在离它最近的 subscribeOn() 所指定的线程。 还是一言不合上代码，千万别问代码是谁。 1234567891011Observable.create(onSubscribe) .subscribeOn(Schedulers.io()) .doOnSubscribe(new Action0() &#123; @Override public void call() &#123; progressBar.setVisibility(View.VISIBLE); // 需要在主线程执行 &#125; &#125;) .subscribeOn(AndroidSchedulers.mainThread()) // 指定主线程 .observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 如上，在 doOnSubscribe()的后面跟一个 subscribeOn() ，就能指定准备工作的线程了。 Ok，以上内容均来自大神们的博客，我只是做了搬运工和总结。如果想了解RxJava实际应用，请戳这里RxJava实际应用/)","categories":[{"name":"Android","slug":"Android","permalink":"https://centmeng.github.io/categories/Android/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://centmeng.github.io/tags/RxJava/"}]},{"title":"spring-boot项目部署到Tomcat上","date":"2017-01-07T06:45:46.000Z","path":"2017/01/07/spring-boot项目部署到Tomcat上/","text":"spring-boot默认提供内嵌的tomcat，所以打包直接生成jar包，用Java -jar命令就可以启动。但是，有时候我们更希望一个tomcat来管理多个项目，这种情况下就需要项目是war格式的包而不是jar格式的包。spring-boot同样提供了解决方案，只需要简单的几步更改就可以了，这里提供maven项目的解决方法： 1.将项目的启动类Application.java继承SpringBootServletInitializer并重写configure方法12345678910111213@SpringBootApplicationpublic class Application extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(Application.class); &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(Application.class, args); &#125;&#125; 2.在pom.xml文件中，project下面增加package标签1&lt;packaging&gt;war&lt;/packaging&gt; 3.在pom.xml文件中，dependencies下面添加12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 4.打包1mvn package","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://centmeng.github.io/tags/spring-boot/"}]},{"title":"Mysql重装问题","date":"2017-01-07T06:32:30.000Z","path":"2017/01/07/Mysql重装问题/","text":"这个问题，还是我大学学习Mysql遇到这个问题，当时做了总结记录下来。没想到朋友今天遇到相同问题，我还能找到自己总结的word文档。所以，打算放到自己博客上，帮助其他人能够看到解决，二是方便自己归档记录 当时用的还是Mysql5.1,所以这次总结也已此为主，其他版本无用，可不要怪我哦。 1、控制面板里的增加删除程序内进行删除2、删除MySQL文件夹下的my.ini文件，如果备份好，可以直接将文件夹全部删除3、注册表信息删除 HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Services\\Eventlog\\Application\\MySQL 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet002\\Services\\Eventlog\\Application\\MySQL 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Eventlog\\Application\\MySQL 目录删除 4、这一条是很关键的C:\\Documents and Settings\\All Users\\Application Data\\MySQL这里还有MySQL的文件，必须要删除 注意：Application Data这个文件夹是隐藏的，需要打开个文件夹选择菜单栏 工具→文件夹选项→查看→隐藏文件和文件夹 一项选上 显示所有文件和文件夹 确定 OK！以上4步完成，再次安装吧 当时自己还用的Windows所以这篇也是这对Winows系统。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://centmeng.github.io/categories/数据库/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://centmeng.github.io/tags/Mysql/"}]},{"title":"2016","date":"2016-12-30T15:48:23.000Z","path":"2016/12/30/2016/","text":"2016，时间去哪了 时光就像小偷，不知不觉又偷走了我们一年的年华。回首这一年，觉得什么也没做，但又觉得发生了许多。 这一年最大的事莫过于互联网的资本寒冬，受此寒流影响冰封住了“指点”的前进步伐。其实每次和人说起此事很轻松，但谁又能知道一个项目从第一行代码就由你自己去编写，并且后续由你去参与设计和规划。你看到他一步步的成长起来，突然有一天你却为他coding最后一行代码。这种心情其他人不知道，只有我自己知道。如今还能想起在那无聊的一天，一群”无聊“的人在个无聊的创业咖啡馆聊着”无聊“的梦想。 当然无聊的人并非只有这些，还有这么一群逗逼的结识。 没拍到环环 没错就是展望2016 是不是我最帅 小骚货们 总结以上就一句话“这个冬天有点冷”。下面说说开心的事： NO.1哥考上了研究生，对没错就是北航 为了它，不容易啊 合个影吧 15GD6大家庭 NO.2说走就走的旅行最初想法：环绕中国一周 临出发前想法：拿着5000元钱，走到哪是哪 最终实现：妈的，走累了，我要回家 最终路线： 北京（火车）–》大连（客船）–》蓬莱（客船）–》长岛（灰机）–》上海（客车）–》周庄（客车）–》苏州（动车）–》上海（灰机）–》包头（火车）–》北京 目的：北京（哥要说走就走，于是乎考完试就走了）–》大连（第二故乡，怎能不回来看看）–》蓬莱（听说烟台有到上海的廉价机票）–》长岛（他们推荐来的）–》上海（我要见见大都市）–》周庄（我要见见古镇，来到这里，不想走了，想呆两天回去）–》苏州（被同屋住的小伙伴拉过来的）–》上海（从这回家灰机便宜）–》包头（我要回家）–》北京（找工作） 事迹：北京（离职了，考完试了，没事了，我要粗发）–》大连（学校还是那个学校，就是没有了以前的人，见了很多老朋友）–》蓬莱（第一次住青旅，走了神仙路）–》长岛（在乡村一个人过的中元节）–》上海（终于见到东方之珠了）–》周庄（住了百年老店，还差98年。刚一进门，被珠珠（狗的名字）的热情给感染了，走不动了，不想走了，想家了。同时认识了几位新朋友，学会了些拍照技巧，话说我们三个从下午拍到半夜）–》苏州（同屋旅友说就来周庄不去苏州会后悔的，没几步地。最后结论是他们说的对）–》上海（来也匆匆，去也匆匆）–》包头（我要回家）–》北京（去找坑） 这装备，是不是够够的 粗发 回母校看看 人在囧途 第二站 烟台（蓬莱，长岛） 长岛 蓬莱青旅 第三站 魔都 第四站：周庄 珠珠 第五站 苏州 ok，说走就走，说回就回的旅行就此结束了。 NO.3买房了从此也是有欠款的人了 这房子，是不是很不错，哈哈 其实户型是这样的 最后的最后，撒上一把狗粮 回我对象老家玩了一把 16年总结完毕，我的本命年也马上结束了。跨年狂欢，未完待续。","categories":[{"name":"随笔集","slug":"随笔集","permalink":"https://centmeng.github.io/categories/随笔集/"}],"tags":[{"name":"随笔集","slug":"随笔集","permalink":"https://centmeng.github.io/tags/随笔集/"}]},{"title":"Android抓包","date":"2016-12-30T15:45:45.000Z","path":"2016/12/30/Android抓包/","text":"#手机上抓包 安卓系统上常用的抓包工具是 tcpdump，具体的操作步骤如下： 1) PC 上安装 adb，直接下载或者通过 eclipse 中的安卓开发环境自带的工具集获得。 2) 下载 tcpdump: http://www.strazzere.com/Android/tcpdump 网盘地址：链接: https://pan.baidu.com/s/1jHGmImq 密码: b15h 3) 检查设备连接情况。 1adb devices 4) 把 tcpdump 拷贝至 /data/local 目录，注意，/data/local 目录需要 root 权限才能拷入，所以先使用 adb push 拷贝至手机 /sdcard 目录，再使用 adb shell 进入命令行，使用 su 进入 root 状态， cp 至 /data/local 目录。 1234adb push ./tcpdump /sdcard/tcpdumpadb shellsucp /sdcard/tcpdump /data/local/tcpdump 5) 为 tcpdump 添加可执行权限 12cd /data/localchmod 6755 tcpdump 6) 启动抓包，使用命令 1/data/local/tcpdump -p -vv -s 0 -w /sdcard/capture.pcap “Got”后面的数字表示当前抓到的包的数量。如果在变化，表示有网络流量。 7) 我们刚刚把抓包的结果保存在了 /sdcard 目录下，导出抓包的结果到电脑。 大家看了这么多步骤是不是觉得很复杂，不过不要紧，我们自研的 GT 工具已经把 tcpdump 抓包功能集成进去了，后面介绍 GT 的章节里面会详细介绍抓包方法，在手机上有用户操作界面可以实现一键式抓包，另外 GT 也提供了命令行方式的接口启动抓包，启动命令为： 1adb shell am broadcast – a com.tencent.wstt.gt.plugin.tcpdump.startTest – es filepath “/sdcard/GT/Tcpdump/Capture/test.pcap” 停止抓包命令为： 1adb shell am broadcast -a com.tencent.wstt.gt.plugin.tcpdump.endTest 后面可以看到，命令行方式可以方便的做进自动化测试脚本中。 第三步：根据抓包文件统计流量 这里需要对抓包文件分析，获得抓取的报文总流量，目前 PC 上的抓包软件 wireshark 就提供这样的统计功能。用 wireshark 打开刚刚的抓包文件，点击 Statistics-&gt;Summary. 流量的数值为 Bytes 一行的 Displayed 一栏。 图 wireshark 流量统计详细页","categories":[{"name":"Android","slug":"Android","permalink":"https://centmeng.github.io/categories/Android/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://centmeng.github.io/tags/工具/"}]},{"title":"Hadoop安装和环境配置","date":"2016-12-02T12:43:30.000Z","path":"2016/12/02/Hadoop安装和环境配置/","text":"主要分为三步(前提是已安装HomeBrew和Java)，我们这里的安装通过HomeBrew进行安装 配置ssh localhost 免密码登陆 安装Hadoop已经进行配置文件设置 （伪分布式） 运行Hadoop 配置SSH为了确保在远程管理Hadoop以及Hadoop节点用户共享时的安全性, Hadoop需要配置使用SSH协议首先在系统偏好设置-&gt;共享-&gt;打开远程登录服务-&gt;右侧选择允许所有用户访问 先验证下是否可以免登陆 ssh localhost,这时候如果出现如下错误1ssh: connect to host localhost port 22: Connection refused 我们只需执行如下两行命令 12sh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsacat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 解释： 第一行：ssh -keygen 代表生成密钥，-t代表指定生成的密钥类型，dsa代表dsa密钥认证的意思（密钥类型）；-P用于提供密语，-f 指定生成的密钥文件 第二行：将公钥加入到用于认证的公钥文件中 这时候，我们再试ssh localhost命令，就不会被refused 安装HadoopHomeBrew安装其实很简单，只需一行命令 1brew install hadoop 至于查看安装目录，可以使用以下命令 1brew list hadoop 可以看到我这里安装的是2.7.1版本，并且目录是/usr/local/Cellar/hadoop/2.7.1 配置Hadoop我们需要对4个文件进行修改和配置，具体如下： hadoop-env.sh文件路径：/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/hadoop-env.sh 将代码：1export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true&quot; 替换为： 1export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=&quot; core-site.xml文件路径：/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/core-site.xml 将下面代码添加到文件中： 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 注： fs.default.name 保存了NameNode的位置，HDFS和MapReduce组件都需要用到它，这就是它出现在core-site.xml 文件中而不是 hdfs-site.xml文件中的原因。在该处配置HDFS的地址和端口号。 mapred-site.xml文件路径：/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/mapred-site.xml或者mapred-site.xml.templete 将下面代码添加到文件中： 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9010&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 变量mapred.job.tracker 保存了JobTracker的位置，因为只有MapReduce组件需要知道这个位置，所以它出现在mapred-site.xml文件中。 hdfs-site.xml文件路径：/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/hdfs-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 变量dfs.replication指定了每个HDFS默认备份方式通常为3, 由于我们只有一台主机和一个伪分布式模式的DataNode，将此值修改为1。 运行Hadoop 启动hadoop之前需要格式化hadoop系统的HDFS文件系统跳转到目录/usr/local/Cellar/hadoop/2.7.1/bin下执行如下命令： 1hadoop namenode -format 如果出现command not found :hadoop则需要配置环境变量，具体怎么配置，这是基本技能，就不在这里说明了。 然后进入/usr/local/Cellar/hadoop/2.7.1/sbin 执行如下命令： 1./start-all.sh 或者分开启动： 12./start-dfs.sh./start-yarn.sh 验证hadoop是否启动 Resource Manager: http://localhost:50070JobTracker: http://localhost:8088Specific Node Information: http://localhost:8042","categories":[{"name":"大数据","slug":"大数据","permalink":"https://centmeng.github.io/categories/大数据/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://centmeng.github.io/tags/工具/"}]},{"title":"RxJava实际应用一","date":"2016-11-22T11:50:15.000Z","path":"2016/11/22/RxJava实际应用(一)/","text":"RxJava一直不知庐山真面目，不知道他的强大到底在哪里，针对此，根据实际使用来说明一下，其实初学RxJava只要把握两点： 观察者模式 和 异步。 RxJava的操作符RxJava操作符是在事件传递过程中做的一些鬼斧神工的操作 Map操作应用示例：比如被观察者产生的事件中只有图片文件路径,但是在观察者这里只想要bitmap,那么就需要类型变换 123456789101112131415161718192021222324Observable.create(new Observable.just(getFilePath())) //使用map操作来完成类型转换 .map(new Func1&lt;String, Bitmap&gt;() &#123; @Override public Bitmap call(String s) &#123; return ImageUtils.getImageByFile(s); &#125; &#125;) .subscribe(new Subscriber&lt;Bitmap&gt;() &#123; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Bitmap bitmap) &#123; imageView.setImageBitmap(bitmap); &#125; &#125;); 实际上在使用map操作时，new Func1() 就对应了类型的转你方向，String是原类型，Bitmap是转换后的类型。在call()方法中，输入的是原类型，返回转换后的类型 读取文件，创建bitmap可能是一个耗时操作，那么就应该在子线程中执行，主线程应该仅仅做展示。那么线程切换一般就会是比较复杂的事情了。但是在Rxjava中，是非常方便的。 123456789101112131415161718192021222324252627282930Observable.create(new Observable.just(getFilePath())) //制定了被观察者执行的线程环境 .subscribeOn(Schedulers.newThread()) //将接下来执行的线程环境指定为io线程 .observeOn(Schedulers.io()) //使用map操作来完成类型转换 .map(new Func1&lt;String, Bitmap&gt;() &#123; @Override public Bitmap call(String s) &#123; return ImageUtils.getImageByFile(s); &#125; &#125;) //将后面执行的线程环境切换为主线程 .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Subscriber&lt;Bitmap&gt;() &#123; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Bitmap bitmap) &#123; imageView.setImageBitmap(bitmap); &#125; &#125;); 由上面的代码可以看到，使用操作符将事件处理逐步分解，通过线程调度为每一步设置不同的线程环境，完全解决了你线程切换的烦恼。可以说线程调度+操作符，才真正展现了RxJava无与伦比的魅力。 如上，线程调度只用到subscribeOn（）和observeOn（）两个方法。对于初学者，只需要掌握两点： subscribeOn（）它指示Observable在一个指定的调度器上创建（只作用于被观察者创建阶段）。只能指定一次，如果指定多次则以第一次为准 observeOn（）指定在事件传递（加工变换）和最终被处理（观察者）的发生在哪一个调度器。可指定多次，每次指定完都在下一步生效。 flatmap操作应用场景：查找一个学校每个班级的每个学生，并打印出来。 如果用老办法：先读出所有班级的数据，循环每个班级。再循环中再读取每个班级中每个学生，然后循环打印出来。 这种想法，虽然没毛病，就是嵌套得有点多。 那让我们看看RxJava是怎么做的： 1234567891011121314151617181920212223242526272829303132333435363738private SchoolClass[] mSchoolClasses=new SchoolClass[2]; Observable.from(mSchoolClasses) .flatMap(new Func1&lt;SchoolClass, Observable&lt;Student&gt;&gt;() &#123; @Override public Observable&lt;Student&gt; call(SchoolClass schoolClass) &#123; //将Student列表使用from方法一个一个发出去 //将每个班级的所有学生作为一列表包装成一列Observable&lt;Student&gt; return Observable.from(schoolClass.getStudents()); &#125; &#125;) .subscribe(new Action1&lt;Student&gt;() &#123; @Override public void call(Student student) &#123; mText.append(\"打印单个学生信息：\\n\"); mText.append(\"name:\"+student.name+\" age: \"+student.age+\"\\n\"); &#125; &#125;); class SchoolClass&#123; Student[] stud; public SchoolClass(Student[] s)&#123; this.stud=s; &#125; public Student[] getStudents()&#123; return stud; &#125; &#125; class Student&#123; String name; String age; public Student(String name,String age)&#123; this.name=name; this.age=age; &#125; &#125; RxJava此时对嵌套嘿嘿一笑。其实flatmap操作符将每个Observable产生的事件里的信息再包装成新的Observable传递出来.那么它是怎么破除嵌套难题？ 因为FlatMap可以再次包装新的Observable,而每个Observable都可以使用from(T[])方法来创建自己，这个方法接受一个列表，然后将列表中的数据包装成一系列事件。 异步（线程调度） 调度器类型 效果 Schedulers.computation() 用于计算任务，如事件循环或回调处理，不用用于IO操作，默认线程数等于处理器的数量 Schedulers.from(execulor) 使用指定的Executor作为调度器 Schedulers.immediate() 在当前线程立即开始执行任务 Schedulers.io() 用于IO密集型任务，如异步阻塞IO操作，这个调度器的线程池会更具需要增长；对于普通的计算任务，请使用computation（）；Schedulers.io()默认是一个CachedThreadScheduler，很像一个有线程缓存的新线程调度器 Schedulers.newThread() 为每一个任务创建一个新线程 Schedulers.trampoline() 当其他排队的任务完成后，在当前线程排队开始执行","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"发布项目到jcenter","date":"2016-11-14T10:00:27.000Z","path":"2016/11/14/发布项目到jcenter/","text":"关于怎么发布，大体流程可以参考泓洋大神的就可以了，我只详细的说明下我遇到的坑 坑一 404报404，提前没有创建组织和库，创建库时候名称起名maven，类型选择Maven 坑二 傻傻的分不清，那几个id傻傻的分不清，那几个id 第一个id 12345678publish &#123; userOrg = 'msj'//bintray.com用户名 groupId = 'com.msj.networkcore'//jcenter上的路径 artifactId = 'networkcore'//项目名称 publishVersion = '1.0.0'//版本号 desc = 'Retrofit2+okhttp3+Rxjava封装的网络框架'//描述，不重要 website = 'https://github.com/centmeng'//网站，不重要；尽量模拟github上的地址，例如我这样的；当然你有地址最好了&#125; 其中 userOrg中的msj是组织名称，而且创建Repository Name输入maven，类型是Maven 第二个id，也是在Terminal执行的命令中1./gradlew clean build bintrayUpload -PbintrayUser=centmeng -PbintrayKey=******************* -PdryRun=false PbintrayUser 的填写自己用户名 坑三 lintExecution failed for task ‘:lint’. 在每个build.gradle中添加如下代码,在android括号内 123456android&#123; lintOptions &#123; abortOnError false warning &apos;InvalidPackage&apos; &#125;&#125; 坑四 JavaDoc检查在根build.gradle添加如下代码 123456789101112131415161718allprojects &#123; repositories &#123; jcenter() &#125; tasks.withType(Javadoc) &#123; options&#123; encoding &quot;UTF-8&quot; charSet &apos;UTF-8&apos; links &quot;http://docs.oracle.com/javase/7/docs/api&quot; &#125; &#125;&#125;tasks.withType(Javadoc) &#123; options.addStringOption(&apos;Xdoclint:none&apos;, &apos;-quiet&apos;) options.addStringOption(&apos;encoding&apos;, &apos;UTF-8&apos;)&#125;","categories":[{"name":"其他","slug":"其他","permalink":"https://centmeng.github.io/categories/其他/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://centmeng.github.io/tags/工具/"}]},{"title":"Gephi初体验","date":"2016-11-13T08:35:30.000Z","path":"2016/11/13/Gephi初体验/","text":"话不多说，大家看看图就会操作 导入数据 文件-&gt;打开-&gt;选择文件 设置层级颜色区分 统计-&gt;模块化 这时候我们要转战场了，调整外观，如下图 选择节点-&gt;数值设定-&gt;Modularity Class（如果没有运行模块化则没有此选项） 选择布局ok，现在到了关键时刻，离成功不远了，选择一个展示布局，这里我们选择Yifan Hu，然后运行，就OK了。 最终效果图","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://centmeng.github.io/categories/大数据技术/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://centmeng.github.io/tags/工具/"}]},{"title":"Webview支持https 双向认证(SSL)","date":"2016-10-22T13:11:35.000Z","path":"2016/10/22/Webview支持https 双向认证(SSL)/","text":"HTTPS首先我们在这之前先了解一下https Https相关知识，HTTPS相当于HTTP的安全版本了，它在HTTP的之下加入了SSL (Secure Socket Layer)，这里说他安全就靠这个SSL了。SSL位于TCP/IP和HTTP协议之间，那么SSL有什么作用呢？ 认证用户和服务器，确保数据发送到正确的客户机和服务器；(验证证书) 加密数据以防止数据中途被窃取；（加密） 维护数据的完整性，确保数据在传输过程中不被改变。（摘要算法） Https工作原理HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。握手过程的简单描述如下： 浏览器将自己支持的一套加密算法、HASH算法发送给网站。 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 浏览器获得网站证书之后，开始验证证书的合法性，如果证书信任，则生成一串随机数字作为通讯过程中对称加密的秘钥。然后取出证书中的公钥，将这串数字以及HASH的结果进行加密，然后发给网站。 网站接收浏览器发来的数据之后，通过私钥进行解密，然后HASH校验，如果一致，则使用浏览器发来的数字串使加密一段握手消息发给浏览器。 浏览器解密，并HASH校验，没有问题，则握手结束。接下来的传输过程将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 握手过程中如果有任何错误，都会使加密连接断开，从而阻止了隐私信息的传输。 以上流程协议，参考网上资料，不一定正确，如有错误希望指出。 根据上面的流程，我们可以看到服务器端会有一个证书，在交互过程中客户端需要去验证证书的合法性，对于权威机构颁发的证书当然我们会直接认为合法。对于自己造的证书，那么我们就需要去校验合法性了，也就是说我们只需要假如使用OkhttpClient去信任这个证书就可以畅通的进行通信了。 当然，对于自签名的网站的访问，网上的部分的做法是直接设置信任所有的证书，对于这种做法肯定是有风险的，所以这里我们不去介绍了，有需要自己去查。 WebView支持httpsOK，该说重点了，对于这方面，我们要从3个Android版本来写 Android 4.0以下，即14以下，不包含14，如果最小支持14，则此处可忽略 123456789101112131415161718192021222324252627282930313233343536/** * 设置webview的ssl双向认证 * 注意：该方法只支持android4.0（不包含）以下 * 该方法调用一次即可 * &lt;P&gt;Author : Vincent.M &lt;/P&gt; */ public boolean setWebViewSSLCert() &#123; boolean issuc = false;// true 代表验证和设置成功 if (Build.VERSION.SDK_INT &gt;= 14) &#123; return issuc; &#125; InputStream[] inputStreams = new InputStream[1]; try &#123; inputStreams[0] = this.getAssets().open(\"key.cer\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; HttpsUtils.SSLParams sslParams = HttpsUtils.getSslSocketFactory(inputStreams, null, null); try &#123; Field[] arrayOfField = Class.forName( \"android.net.http.HttpsConnection\").getDeclaredFields(); for (Field localField : arrayOfField) &#123; if (localField.getName().equals(\"mSslSocketFactory\")) &#123;//采用反射的方式修改mSslSocketFactory变量 localField.setAccessible(true); localField.set(null, sslParams.sSLSocketFactory); issuc = true; break; &#125; &#125; &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; return issuc; &#125; HttpsUtils方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206public class HttpsUtils&#123; public static class SSLParams &#123; public SSLSocketFactory sSLSocketFactory; public X509TrustManager trustManager; &#125; public static SSLParams getSslSocketFactory(InputStream[] certificates, InputStream bksFile, String password) &#123; SSLParams sslParams = new SSLParams(); try &#123; TrustManager[] trustManagers = prepareTrustManager(certificates); KeyManager[] keyManagers = prepareKeyManager(bksFile, password); SSLContext sslContext = SSLContext.getInstance(\"TLS\"); X509TrustManager trustManager = null; if (trustManagers != null) &#123; trustManager = new MyTrustManager(chooseTrustManager(trustManagers)); &#125; else &#123; trustManager = new UnSafeTrustManager(); &#125; sslContext.init(keyManagers, new TrustManager[]&#123;trustManager&#125;,null); sslParams.sSLSocketFactory = sslContext.getSocketFactory(); sslParams.trustManager = trustManager; return sslParams; &#125; catch (NoSuchAlgorithmException e) &#123; throw new AssertionError(e); &#125; catch (KeyManagementException e) &#123; throw new AssertionError(e); &#125; catch (KeyStoreException e) &#123; throw new AssertionError(e); &#125; &#125; private class UnSafeHostnameVerifier implements HostnameVerifier &#123; @Override public boolean verify(String hostname, SSLSession session) &#123; return true; &#125; &#125; private static class UnSafeTrustManager implements X509TrustManager &#123; @Override public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; @Override public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; @Override public X509Certificate[] getAcceptedIssuers() &#123; return new X509Certificate[]&#123;&#125;; &#125; &#125; private static TrustManager[] prepareTrustManager(InputStream... certificates) &#123; if (certificates == null || certificates.length &lt;= 0) return null; try &#123; CertificateFactory certificateFactory = CertificateFactory.getInstance(\"X.509\"); KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); keyStore.load(null); int index = 0; for (InputStream certificate : certificates) &#123; String certificateAlias = Integer.toString(index++); keyStore.setCertificateEntry(certificateAlias, certificateFactory.generateCertificate(certificate)); try &#123; if (certificate != null) certificate.close(); &#125; catch (IOException e) &#123; &#125; &#125; TrustManagerFactory trustManagerFactory = null; trustManagerFactory = TrustManagerFactory. getInstance(TrustManagerFactory.getDefaultAlgorithm()); trustManagerFactory.init(keyStore); TrustManager[] trustManagers = trustManagerFactory.getTrustManagers(); return trustManagers; &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (CertificateException e) &#123; e.printStackTrace(); &#125; catch (KeyStoreException e) &#123; e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private static KeyManager[] prepareKeyManager(InputStream bksFile, String password) &#123; try &#123; if (bksFile == null || password == null) return null; KeyStore clientKeyStore = KeyStore.getInstance(\"BKS\"); clientKeyStore.load(bksFile, password.toCharArray()); KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm()); keyManagerFactory.init(clientKeyStore, password.toCharArray()); return keyManagerFactory.getKeyManagers(); &#125; catch (KeyStoreException e) &#123; e.printStackTrace(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (UnrecoverableKeyException e) &#123; e.printStackTrace(); &#125; catch (CertificateException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private static X509TrustManager chooseTrustManager(TrustManager[] trustManagers) &#123; for (TrustManager trustManager : trustManagers) &#123; if (trustManager instanceof X509TrustManager) &#123; return (X509TrustManager) trustManager; &#125; &#125; return null; &#125; private static class MyTrustManager implements X509TrustManager &#123; private X509TrustManager defaultTrustManager; private X509TrustManager localTrustManager; public MyTrustManager(X509TrustManager localTrustManager) throws NoSuchAlgorithmException, KeyStoreException &#123; TrustManagerFactory var4 = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); var4.init((KeyStore) null); defaultTrustManager = chooseTrustManager(var4.getTrustManagers()); this.localTrustManager = localTrustManager; &#125; @Override public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; @Override public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; try &#123; defaultTrustManager.checkServerTrusted(chain, authType); &#125; catch (CertificateException ce) &#123; localTrustManager.checkServerTrusted(chain, authType); &#125; &#125; @Override public X509Certificate[] getAcceptedIssuers() &#123; return new X509Certificate[0]; &#125; &#125;&#125; Android 4.0及以上版本，Android 5.0（不包含）以下,下面这段代码是通用的，在4.0和5.0，不同点在设置WebViewClient中 12345678910111213141516171819202122232425262728293031323334353637private X509Certificate[] mX509Certificates; private PrivateKey mPrivateKey; private void initPrivateKeyAndX509Certificate() throws Exception &#123; // 创建一个证书库，并将证书导入证书库 try &#123; InputStream input = this.getContext().getResources().openRawResource(R.raw.keystore); KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); keyStore.load(input, CERTFILE_PASSWORD.toCharArray()); Enumeration&lt;?&gt; localEnumeration; localEnumeration = keyStore.aliases(); while (localEnumeration.hasMoreElements()) &#123; String str3 = (String) localEnumeration.nextElement(); mPrivateKey = (PrivateKey) keyStore.getKey(str3, CERTFILE_PASSWORD.toCharArray()); if (mPrivateKey == null) &#123; continue; &#125; else &#123; Certificate[] arrayOfCertificate = keyStore .getCertificateChain(str3); mX509Certificates = new X509Certificate[arrayOfCertificate.length]; for (int j = 0; j &lt; mX509Certificates.length; j++) &#123; mX509Certificates[j] = ((X509Certificate) arrayOfCertificate[j]); &#125; &#125; &#125; &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (CertificateException e) &#123; e.printStackTrace(); &#125; catch (KeyStoreException e) &#123; e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 这里在WebViewClient来区分4.0和5.0的不同点 12345678910111213141516171819202122232425262728webview.setWebViewClient(new WebViewClient() &#123; //支持处理https请求，默认是handler.cancel(); @Override public void onReceivedSslError(WebView view, SslErrorHandler handler, SslError error) &#123; handler.proceed(); &#125; //5.0的处理 @TargetApi(Build.VERSION_CODES.LOLLIPOP) @Override public void onReceivedClientCertRequest(WebView view, ClientCertRequest request) &#123; super.onReceivedClientCertRequest(view, request); LogUtils.e(\"msj\", \"onReceivedClientCertRequest\"); request.proceed(mPrivateKey, mX509Certificates); &#125;//4.0.3,4.1.2的处理 4.2.2,4.3.1使用类 WebViewClientClassicExt public void onReceivedClientCertRequest(WebView view, ClientCertRequestHandler handler, String host_and_port) &#123; //注意该方法是调用的隐藏函数接口。这儿是整个验证的技术难点：就是如何调用隐藏类的接口。 //方法：去下载一个android4.2版本全编译后的class.jar 然后导入到工程中 if(((mX509Certificates != null) &amp;&amp; (mX509Certificates.length !=0)))&#123; handler.proceed(mPrivateKey, mX509Certificates); &#125;else&#123; handler.cancel(); &#125; &#125; 再书写4.0的时候会发现，有报错,有两种解决方式 到android 4.2 源码环境下编译 去下载一个全编译的class.jar","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"WebView","slug":"WebView","permalink":"https://centmeng.github.io/tags/WebView/"}]},{"title":"Retrofit2介绍","date":"2016-10-17T05:19:39.000Z","path":"2016/10/17/Retrofit2介绍/","text":"Retrofit2介绍RESTful在开始了解 Retrofit 的使用之前，我们需要理解RESTful概念因为 Retrofit 的初衷就是根据 RESTful风格的API 来进行封装的。关于RESTful 我们可以参考《RESTful API 设计指南》 RetrofitRetrofit与okhttp共同出自于Square公司，retrofit就是对okhttp做了一层封装。把网络请求都交给给了Okhttp，我们只需要通过简单的配置就能使用retrofit来进行网络请求了。官方介绍：http://square.github.io/retrofit/ 引用 Gradle：1compile &apos;com.squareup.retrofit2:retrofit:2.1.0&apos; 使用学习一门新的技术的时候，我们首先要参考的就是官方文档，我们看看官方文档是怎么写的：http://square.github.io/retrofit/ 大家看到官方文档，很是简单粗暴，一言不合就上代码 1234public interface GitHubService &#123; @GET(\"users/&#123;user&#125;/repos\") Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path(\"user\") String user);&#125; 从上面代码我们可知，Retrofit将HTTP API转换为interface接口的方式（Retrofit turns your HTTP API into a Java interface.） 12345Retrofit retrofit = new Retrofit.Builder() .baseUrl(\"https://api.github.com/\") .build();GitHubService service = retrofit.create(GitHubService.class); Retrofit 根据之前定义的接口生成一个具体的实现。通俗的讲就是我们可以将Retrofit类看作是一个“工厂类”的角色，我们在接口中提供了此次的“产品”的生产规格信息，而Retrofit则通过信息负责为我们生产。 1Call&lt;List&lt;Repo&gt;&gt; repos = service.listRepos(\"octocat\"); “Call”：通过之前封装的请求接口对象创建的任一的Call都可以发起一个同步（或异步）的HTTP请求到远程服务器。 以上信息就是简单的Retrofit的操作，通过这个实例感受最多的就是解耦明确；使用简单。通过注解的方式描述request让人眼前一亮。 其他注解 @Path 12345public interface IDemoBiz&#123; @GET(\"modify/&#123;userId&#125;\") Call&lt;User&gt; modify(@Path(\"userId\") String userId);&#125; @Query对于@GET来说，参数信息是可以直接放在url中上传的。那么你马上就反应过来了，这一样也存在严重的耦合！于是，就有了 @Query 12345public interface IDemoBiz&#123; @GET(\"modify/&#123;userId&#125;\") Call&lt;User&gt; modify(@Path(\"userId\") String userId,@Query(\"name\") String name);&#125; @QueryMap假设我要在参数中上传10个参数呢？ 12345public interface IDemoBiz&#123; @GET(\"modify/&#123;userId&#125;\") Call&lt;User&gt; modify(@Path(\"userId\") String userId,@QueryMap Map&lt;String,String&gt; params);&#125; @Post @Body Post请求上传body 12345public interface IDemoBiz&#123; @POST(\"add\") Call&lt;List&lt;User&gt;&gt; get(@Body User user);&#125; @Post @FormUrlEncoded 表单上传 服务器通过request.getParameter的方式直接读取参数信息 12345public interface IDemoBiz&#123; @POST(\"modify/&#123;userId&#125;\") Call&lt;User&gt; modify(@Path(\"userId\") String userId,@Field(\"name\") String name,@Field(\"nickname\") String nickname);&#125; @Headers与@Header 可以设置HTTP的header，拿使用编码来举例 1234567public interface IDemoBiz&#123; @Headers(\"Content-type:application/x-www-form-urlencoded;charset=UTF-8\") @FormUrlEncoded @POST(\"modify/&#123;userId&#125;\") Call&lt;User&gt; modify(@Path(\"userId\") String userId,@Field(\"name\") String name,@Field(\"nickname\") String nickname);&#125; 上面代码说的使用@Headers的用法，那么@Header怎么使用呢？@Header与@Headers不同在于是动态的添加请求头信息。 123@FormUrlEncoded @POST(\"modify/&#123;userId&#125;\")Call&lt;User&gt; modify(@Header(\"Content-type\" String contentType),@Path(\"userId\") String userId,@Field(\"name\") String name,@Field(\"nickname\") String nickname); HTTP的Header也可以在okhttp的拦截器中添加。 其他 当然我们还可以进行文件上传和下载，这里就不过多介绍了，网上有很多示例。 注意事项特别注意如果需要继承rxjava和gson转换，则还需要引入 1compile &apos;com.squareup.retrofit2:adapter-rxjava:2.1.0&apos; 1compile &apos;com.squareup.retrofit2:converter-gson:2.1.0&apos; 其他格式转换引入 1234567Gson: com.squareup.retrofit2:converter-gsonJackson: com.squareup.retrofit2:converter-jacksonMoshi: com.squareup.retrofit2:converter-moshiProtobuf: com.squareup.retrofit2:converter-protobufWire: com.squareup.retrofit2:converter-wireSimple XML: com.squareup.retrofit2:converter-simplexmlScalars (primitives, boxed, and String): com.squareup.retrofit2:converter-scalars 如果不添加转换器会报IllegalArgumentException异常,这也会是新手开发碰到的第一个坑","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"Weex初体验","date":"2016-09-28T09:39:31.000Z","path":"2016/09/28/week初体验/","text":"Weex 初体验在Weex中坑了几天，终于在Android中跑出了第一个demo，此demo会不断的更新。 Git地址：https://github.com/CentMeng/WeexDemo 搭建相关app/build.gradle123compile 'com.taobao.android:weex_sdk:0.8.0+' compile 'com.alibaba:fastjson:1.1.46.android' compile 'com.github.bumptech.glide:glide:3.7.0' ActivityActivity也可以设置 ImageAdaptermInstance.setImgLoaderAdapter(new ImageAdapter(this)); 1234567891011121314151617181920212223242526272829303132333435363738394041424344@EActivity(R.layout.ac_main)public class MainActivity extends AppCompatActivity &#123; @ViewById FrameLayout container; private WXSDKInstance mWeexInstance; @AfterViews void afterView()&#123; // sdk 实例 mWeexInstance = new WXSDKInstance(this); mWeexInstance.registerRenderListener(new IWXRenderListener() &#123; // sdk 将 js 文件渲染成 view 对象回调 @Override public void onViewCreated(WXSDKInstance wxsdkInstance, View view) &#123; if (container != null) &#123; container.addView(view); // 添加到界面 &#125; &#125; @Override public void onRenderSuccess(WXSDKInstance wxsdkInstance, int i, int i1) &#123; &#125; @Override public void onRefreshSuccess(WXSDKInstance wxsdkInstance, int i, int i1) &#123; &#125; @Override public void onException(WXSDKInstance wxsdkInstance, String s, String s1) &#123; &#125; &#125;); // 加载 js 文件 mWeexInstance.render(\"001\", WXFileUtils.loadAsset(\"build.js\", this), null, null, -1, -1, WXRenderStrategy.APPEND_ASYNC); &#125;&#125; Application12345678910111213public class WXApplication extends Application &#123; @Override public void onCreate() &#123; super.onCreate(); //代码中启动Weex RunTime，用于渲染UI WXEnvironment.addCustomOptions(\"appName\",\"TBSample\"); InitConfig config = new InitConfig.Builder() .setImgAdapter(new ImageAdapter()) .build(); WXSDKEngine.initialize(this, config); &#125;&#125; ImageAdapter，用Glide加载图片1234567891011121314151617181920/** * @author Vincent.M * @date 16/9/28 * @copyright ©2016 孟祥程 All Rights Reserved * @desc Weex 加载图片 */public class ImageAdapter implements IWXImgLoaderAdapter &#123; @Override public void setImage(final String url, final ImageView view, WXImageQuality quality, WXImageStrategy strategy) &#123; WXSDKManager.getInstance().postOnUiThread(new Runnable() &#123; @Override public void run() &#123; //.dontAnimate()是为了解决圆形图片第一次加载不出来只显示展位图 Glide.with(WXEnvironment.getApplication()).load(url).placeholder(R.drawable.bg_notus).crossFade().dontAnimate().into(view); &#125; &#125;, 0); &#125;&#125; 版本记录V0.1 环境搭建，运行demo","categories":[{"name":"前段技术","slug":"前段技术","permalink":"https://centmeng.github.io/categories/前段技术/"}],"tags":[{"name":"Weex","slug":"Weex","permalink":"https://centmeng.github.io/tags/Weex/"}]},{"title":"React-Native学习指南","date":"2016-09-27T01:56:46.000Z","path":"2016/09/27/React-Native学习指南/","text":"本指南汇集React-Native各类学习资源，给大家提供便利。指南正在不断的更新，大家有好的资源欢迎Pull Requests！ 同时还有Awesome React Native系列https://github.com/jondot/awesome-react-native 目录 教程 React Native React.js ES6 系列教程 开源APP 图书 组件 工具 资源网站 业界讨论 教程React Native 构建 Facebook F8 2016 App / React Native 开发指南http://f8-app.liaohuqiu.net/ React-Native入门指南https://github.com/vczero/react-native-lesson 30天学习React Native教程https://github.com/fangwei716/30-days-of-react-native React-Native视频教程(部分免费)https://egghead.io/technologies/react React Native 开发培训视频教程（中文|免费）https://www.gitbook.com/book/unbug/react-native-training/details react-native 官方api文档http://facebook.github.io/react-native/docs/getting-started.html react-native中文文档(极客学院)http://wiki.jikexueyuan.com/project/react-native/ react-native中文文档(react native中文网，人工翻译，官网完全同步)http://react-native.cn/docs/getting-started.html react-native第一课http://html-js.com/article/2783 深入浅出 React Native：使用 JavaScript 构建原生应用http://zhuanlan.zhihu.com/FrontendMagazine/19996445 React Native通信机制详解http://blog.cnbang.net/tech/2698/ React Native布局篇https://segmentfault.com/a/1190000002658374 React Native 基础练习指北（一）https://segmentfault.com/a/1190000002645929 React Native 基础练习指北（二）https://segmentfault.com/a/1190000002647733 Diary of Building an iOS App with React Nativehttp://herman.asia/building-a-flashcard-app-with-react-native Use React Native in Existing iOS Apphttp://blog-en.leapoahead.com/post/use-react-native-in-existing-ios-app React Native For Beginners – The Next Big Thing?https://devdactic.com/react-native-for-beginners/ How To Implement A Tab Bar With React Nativehttps://devdactic.com/react-native-tab-bar/ tcomb-form-native使用视频教程(需翻墙)https://react.rocks/example/tcomb-form-native React Native分享记录https://segmentfault.com/a/1190000002678782 React Native构建本地视图组件https://www.dobest.me/article/11 react-native-android-lession(安卓系列教程)https://github.com/yipengmu/react-native-android-lession React Native模块桥接详解https://www.dobest.me/article/14 React Native: 配置和起步http://www.liaohuqiu.net/cn/posts/react-native-1/ React Native: Android 的打包http://www.liaohuqiu.net/cn/posts/react-native-android-package/ ReactNative之原生模块开发并发布——iOS篇http://www.liuchungui.com/blog/2016/05/02/reactnativezhi-yuan-sheng-mo-kuai-kai-fa-bing-fa-bu-iospian/ ReactNative之原生模块开发并发布——android篇http://www.liuchungui.com/blog/2016/05/08/reactnativezhi-yuan-sheng-mo-kuai-kai-fa-bing-fa-bu-androidpian/ react-native的第一课https://github.com/coderyi/blog/blob/master/articles/2016/0122_react-native_first_lesson.md React-Native专题系列文章http://www.lcode.org/react-native/ React.js react.js中文文档http://reactjs.cn/ react.js入门教程(gitbook)https://hulufei.gitbooks.io/react-tutorial/content/introduction.html react.js快速入门教程 - 阮一峰http://www.ruanyifeng.com/blog/2015/03/react.html react.js视频教程http://react-china.org/t/reactjs/584 ES6 深入浅出ES6（一）：ES6是什么http://www.infoq.com/cn/articles/es6-in-depth-an-introduction 深入浅出ES6（二）：迭代器和for-of循环http://www.infoq.com/cn/articles/es6-in-depth-iterators-and-the-for-of-loop 深入浅出ES6（三）：生成器 Generatorshttp://www.infoq.com/cn/articles/es6-in-depth-generators 深入浅出ES6（四）：模板字符串http://www.infoq.com/cn/articles/es6-in-depth-template-string 深入浅出ES6（五）：不定参数和默认参数http://www.infoq.com/cn/articles/es6-in-depth-rest-parameters-and-defaults 系列教程 深入浅出React（一）：React的设计哲学 - 简单之美http://www.infoq.com/cn/articles/react-art-of-simplity 深入浅出React（二）：React开发神器Webpackhttp://www.infoq.com/cn/articles/react-and-webpack 深入浅出React（三）：理解JSX和组件http://www.infoq.com/cn/articles/react-jsx-and-component 深入浅出React（四）：虚拟DOM Diff算法解析http://www.infoq.com/cn/articles/react-dom-diff 深入浅出React（五）：使用Flux搭建React应用程序架构http://www.infoq.com/cn/articles/react-flux react-webpack-cookbook中文版http://fakefish.github.io/react-webpack-cookbook/ Flex 布局语法教程http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html React 初探http://www.alloyteam.com/2015/04/react-explore/ React虚拟DOM浅析http://www.alloyteam.com/2015/10/react-virtual-analysis-of-the-dom/ react组件间通信http://www.alloyteam.com/2015/07/react-zu-jian-jian-tong-xin/ React 数据流管理架构之 Redux 介绍http://www.alloyteam.com/2015/09/react-redux/ React服务器端渲染实践小结http://www.alloyteam.com/2015/10/8783/ React Native Android 踩坑之旅http://www.alloyteam.com/2015/10/react-native-android-steps-on-tour/ React Native 之 JSBridgehttp://www.alloyteam.com/2015/05/react-native-zhi-jsbridge/ React Native探索系列教程 React Native探索（一）：背景、规划和风险http://www.infoq.com/cn/articles/react-native-overview React Native探索（二）：布局篇http://www.infoq.com/cn/articles/react-native-layout React Native探索（三）：与 react-web 的融合http://www.infoq.com/cn/articles/react-native-web 开源APP 研究源码也是一个很好的学习方式 官方演示Apphttps://github.com/facebook/react-native/tree/master/Examples Facebook F8 Apphttps://github.com/fbsamples/f8app 奇舞周刊 iOS 版（上架应用）https://github.com/fakefish/Weekly75 react-native-dribbble-apphttps://github.com/catalinmiron/react-native-dribbble-app Gank.io客户端https://github.com/Bob1993/React-Native-Gank Leanote for iOS(云笔记)https://github.com/leanote/leanote-ios-rn ReactNativeRubyChinahttps://github.com/henter/ReactNativeRubyChina HackerNews-React-Nativehttps://github.com/iSimar/HackerNews-React-Native React-Native新闻客户端https://github.com/tabalt/ReactNativeNews newswatch(新闻客户端)https://github.com/bradoyler/newswatch-react-native buyscreen(购买页面)https://github.com/appintheair/react-native-buyscreen V2EX客户端https://github.com/samuel1112/v2er react-native-todohttps://github.com/joemaddalone/react-native-todo react-native-beerhttps://github.com/muratsu/react-native-beer react-native-starshttps://github.com/86/react-native-stars 模仿天猫首页的apphttps://github.com/hugohua/react-native-demo ReactNativeChesshttps://github.com/csarsam/ReactNativeChess react native 编写的音乐软件https://github.com/Johnqing/miumiu react-native-pokedexhttps://github.com/ababol/react-native-pokedex CNode-React-Nativehttps://github.com/SFantasy/CNode-React-Native 8tracks电台客户端https://github.com/voronianski/EightTracksReactNative React-Native实现的计算器https://github.com/yoxisem544/Calculator-using-React-Native 房产搜索apphttps://github.com/jawee/react-native-PropertyFinder 知乎专栏apphttps://github.com/LeezQ/react-native-zhihu-app ForeignExchangeApphttps://github.com/peralmq/ForeignExchangeApp Segmentfault 客户端https://github.com/fakefish/sf-react-native 糗事百科apphttps://github.com/stormhouse/QiuShiReactNative 孢子社区apphttps://github.com/Hi-Rube/baoz-ReactNative 深JS apphttps://github.com/fraserxu/shenjs Den - 房屋销售app*https://github.com/asamiller/den Noder-cnodejs客户端https://github.com/soliury/noder-react-native 知乎日报Android版https://github.com/race604/ZhiHuDaily-React-Native ziliun-react-nativehttps://github.com/sonnylazuardi/ziliun-react-native react-native-weather-apphttps://github.com/shevawen/react-native-weather-app React Native Sample App(Navigation,Flux)https://github.com/taskrabbit/ReactNativeSampleApp TesterHome社区apphttps://github.com/qddegtya/A-ReactNative-TesterHome Finance - 股票报价apphttps://github.com/7kfpun/FinanceReactNative shopping - 购物apphttps://github.com/bigsui/shopping-react-native zhuiyuan - 追源cms apphttps://github.com/kazaff/ZhuiYuanDemo uestc-bbs-react-native - UESTC清水河畔RN客户端(with Redux)https://github.com/just4fun/uestc-bbs-react-native react-native-nw-react-calculator(iOS/Android、Web、桌面多端)https://github.com/benoitvallon/react-native-nw-react-calculator react-native-nba-apphttps://github.com/wwayne/react-native-nba-app 开源中国的Git@OSC客户端http://git.oschina.net/rplees/react-native-gitosc rn_bycloud 帮瀛律师端apphttps://github.com/liuchungui/rn_bycloud ReactNativeRollingExamples - react-native的一些example https://github.com/joggerplus/ReactNativeRollingExamples Reading App Write In React-Native（Studying and Programinghttps://github.com/attentiveness/reading 数独 - 重拾纯粹数独的乐趣https://github.com/nihgwu/react-native-sudoku Shop-React-Nativehttps://github.com/EleTeam/Shop-React-Native 图书 《React Native入门与实战》http://item.jd.com/11844102.html 《React Native开发指南》http://www.ituring.com.cn/book/1846 《React Native跨平台移动应用开发》http://item.jd.com/10372998311.html 《React Native：用JavaScript开发移动应用》http://item.jd.com/11785195.html 组件 由于已经有较好的组件库网站，这里就不做总结。可以直接查看如下网站，过后可能精选一部分优质组件出来 :P React-native组件库（比较全的组件库）https://js.coach/ React Native Moduleshttp://reactnativemodules.com/ 最佳轮播类组件https://github.com/leecade/react-native-swiper react-native-simple-routerhttps://github.com/react-native-simple-router-community/react-native-simple-router react-native-router-fluxhttps://github.com/aksonov/react-native-router-flux 下拉刷新组件https://github.com/jsdf/react-native-refreshable-listview 模态框https://github.com/brentvatne/react-native-modal react-native-navbarhttps://github.com/react-native-fellowship/react-native-navbar 滚动轮播组件https://github.com/appintheair/react-native-looped-carousel HTML显示组件https://github.com/jsdf/react-native-htmlview Material React Native (MRN) - Material Design组件库https://github.com/binggg/mrn react-native-gitfeed - GitHub客户端(iOS/Android)https://github.com/xiekw2010/react-native-gitfeed React-Native-Elements - React Native样式组件库https://github.com/react-native-community/React-Native-Elements Shoutem UI - React Native样式组件库https://github.com/shoutem/ui 工具 react-native-snippets(代码提示)https://github.com/Shrugs/react-native-snippets react-native-babel(使用ES6+)https://github.com/roman01la/react-native-babel sqlite for react-nativehttps://github.com/almost/react-native-sqlite gulp-react-native-css(就像写css一样写React Style)https://github.com/soliury/gulp-react-native-css rnpm(React Native Package Manager)https://github.com/rnpm/rnpm Pepperoni - React Native项目初始化套件https://github.com/futurice/pepperoni-app-kit Deco IDE - React Native IDEhttps://www.decosoftware.com/ ignite - React Native CLI项目生成器https://github.com/infinitered/ignite 资源网站 React-native官网http://facebook.github.io/react-native/ React-China社区http://react-china.org/ React Native中文社区http://bbs.react-native.cn/ React-native组件库（比较全的组件库）http://react.parts/ React Native Moduleshttp://reactnativemodules.com/ Use React Native 资讯站(使用技巧及新闻)http://www.reactnative.com/ 11款React Native开源移动 UI 组件http://www.oschina.net/news/61214/11-react-native-ui-components 稀土掘金的 React 标签http://gold.xitu.io/#/tag/React.js http://gold.xitu.io/#/tag/React%20Native 业界讨论 跨平台开发时代的 (再次) 到来？（ Xamarin，NativeScript 和 React Native 对比）http://onevcat.com/2015/03/cross-platform/ 谈谈 React Native - 唐巧http://blog.devtang.com/blog/2015/02/01/talk-about-react-native/ 如何评价React-Native?https://www.zhihu.com/question/27852694/answer/43990708 React Native概述：背景、规划和风险http://div.io/topic/938 Native与Web的融合 - Qcon中React-Native演讲http://www.infoq.com/cn/presentations/the-fusion-of-native-and-web 使用React Native一年后的感受http://www.dobest.me/blog/2016/06/12/%E4%BD%BF%E7%94%A8React%20Native%E4%B8%80%E5%B9%B4%E5%90%8E%E7%9A%84%E6%84%9F%E5%8F%97/ Weex &amp; ReactNative &amp; JSPatch大对比http://awhisper.github.io/2016/07/22/Weex-ReactNative-JSPatch/ weex&amp;ReactNative对比https://zhuanlan.zhihu.com/p/21677103","categories":[{"name":"前端技术","slug":"前端技术","permalink":"https://centmeng.github.io/categories/前端技术/"}],"tags":[{"name":"Rect-Native","slug":"Rect-Native","permalink":"https://centmeng.github.io/tags/Rect-Native/"}]},{"title":"weChat小程序开发工具和破解","date":"2016-09-23T00:45:23.000Z","path":"2016/09/23/weChat小程序开发工具和破解/","text":"距离张小龙的那场首次公开演讲已经有九个月了，而在那场演讲中备受关注的「应用号」在千呼万唤中终于以「小程序」的名字正式对外小范围公测，不少创业者表示机会来了跃跃欲试。下面我也发个大招，给大家带波福利， 开发工具 开发工具V0.9包含下面需要用到的替换文件包 百度云盘：链接: https://pan.baidu.com/s/1boEtSJ1 密码: fa3f 破解步骤 下载开发工具，并安装（注意：一定要安装0.9版本） 打开『微信Web开发者工具』的程序目录 Windows：使用资源管理器查看 Mac：右键点击图标，选择『显示包内容』 进入程序目录后，替换以下文件（只需要替换0.9版本里的，0.7版本用来登陆）： Windows： \\package.nw\\app\\dist\\components\\create\\createstep.js \\package.nw\\app\\dist\\stroes\\projectStores.js Mac： /Resources/app.nw/app/dist/components/create/createstep.js /Resources/app.nw/app/dist/stroes/projectStores.js 使用教程 运行『微信Web开发者工具』 通过微信扫描二维码 创建项目 AppID：随便填 项目名称：随便填 本地开发目录：选择一个目录 点击「添加项目」 此时如果出错，先退出再重进 此时，能够看到项目列表了 打开项目 开始开发 常见问题 找不到所要替换的文件 问题原因：开发工具版本不正确，老版本不支持 解决方案：确保下载的程序版本在0.9.092100以上 Failed to load resource: net::ERR_NAME_NOT_RESOLVED http://1709827360.appservice.open.weixin.qq.com/appservice 问题原因：通常是由于系统设置了代理如Shadowsocks等。 解决方案：关闭代理，或者依次点击工具栏“动作”-“设置”，选择“不使用任何代理，勾选后直连网络”。 修复asdebug.js报错 问题原因：TypeError: Cannot read property ‘MaxRequestConcurrent’ of undefined 解决方案：替换 /Resources/app.nw/app/dist/weapp/appservice/asdebug.js 扫码登录失败 问题原因：please bind your wechat account to the appid first 解决方案：先使用0.7版本的进行扫码登陆，登陆成功后，再用0.9的版本打开就直接进入了。 教程网址http://wxopen.notedown.cn/?","categories":[{"name":"前端技术","slug":"前端技术","permalink":"https://centmeng.github.io/categories/前端技术/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://centmeng.github.io/tags/工具/"}]},{"title":"MVVM框架简介和使用","date":"2016-09-22T08:09:18.000Z","path":"2016/09/22/MVVM框架简介和使用/","text":"MVVM简介MVVM是由MVC–&gt;MVP–&gt;MVVM一步步进化来的，那么先让我们了解下：MVC和MVP MVCMVC 即模型——视图——控制器。这样设计使得程序的各个部分分离降低耦合性，我们对代码的结构进行了划分。 视图（View）：用户界面。 控制器（Controller）：业务逻辑。 模型（Model）：数据保存。 大概流程是，View传送指令到Controller，Controller完成业务逻辑后，要求Model改变状态，Model将新的数据发送到View，用户得到反馈。 MVP Presenter 替换掉了Controller，不仅仅处理逻辑部分。而且还控制着View的刷新，监听Model层的数据变化。这样隔离掉View和Model的关系后使得View层变的非常的薄，没有任何的逻辑部分又不用主动监听数据，被称之为“被动视图”。 MVVM 至于MVVM基本上和MVP一模一样，感觉只是名字替换了一下。他的关键技术就是今天的主题(Data Binding)。View的变化可以自动的反应在ViewModel，ViewModel的数据变化也会自动反应到View上。这样开发者就不用处理接收事件和View更新的工作，框架已经帮你做好了。 Data Binding Library去年的Google IO 大会上，Android 团队发布了一个数据绑定框架（Data Binding Library）。以后可以直接在 layout 布局 xml 文件中绑定数据了，无需再 findViewById 然后手工设置数据了。其语法和使用方式和 JSP 中的 EL 表达式非常类似。 下面就来介绍怎么使用Data Binding Library。 基本使用目前，最新版的Android Studio已经内置了该框架的支持，配置起来也很简单，只需要编辑app目录下的build.gradle文件，添加下面的内容就好了 123456android &#123; .... dataBinding &#123; enabled = true &#125;&#125; 要使用数据绑定，我们得首先创建一个实体类，比如User实体类，如下： 1234567891011121314151617181920212223242526272829303132333435363738public class UserEntity &#123; private String username; private String nickname; private int age; public UserEntity() &#123; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public UserEntity(int age, String nickname, String username) &#123; this.age = age; this.nickname = nickname; this.username = username; &#125;&#125; 下面我们来看看layout文件是需要怎么书写 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;layout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; &gt; &lt;data&gt; &lt;variable name=&quot;user&quot; type=&quot;org.lenve.databinding1.UserEntity&quot;/&gt; &lt;/data&gt; &lt;LinearLayout xmlns:tools=&quot;http://schemas.android.com/tools&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:orientation=&quot;vertical&quot; tools:context=&quot;org.lenve.databinding1.MainActivity&quot;&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;user.username&#125;&quot;/&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;user.nickname&#125;&quot;/&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;String.valueOf(user.age)&#125;&quot;/&gt; &lt;/LinearLayout&gt;&lt;/layout&gt; 你会发现布局文件不再是以传统的某一个容器作为根节点，而是使用作为根节点，在节点中我们可以通过节点来引入我们要使用的数据源。 在data中定义的variable节点，name属性表示变量的名称，type表示这个变量的类型，实例就是我们实体类的位置，当然，这里你也可以换一种写法，如下： 1234567&lt;data&gt; &lt;import type=&quot;org.lenve.databinding1.UserEntity&quot;/&gt; &lt;variable name=&quot;user&quot; type=&quot;UserEntity&quot;/&gt; &lt;/data&gt; 先使用import节点将UserEntity导入，然后直接使用即可。但是如果这样的话又会有另外一个问题，假如我有两个类都是UserEntity，这两个UserEntity分属于不同的包中，又该如何？看下面： 1234567&lt;data&gt; &lt;import type=&quot;org.lenve.databinding1.UserEntity&quot; alias=&quot;CentMeng&quot;/&gt; &lt;variable name=&quot;user&quot; type=&quot;CentMeng&quot;/&gt; &lt;/data&gt; 在import节点中还有一个属性叫做alias，这个属性表示我可以给该类取一个别名，我给UserEntity这个实体类取一个别名叫做Lenve，这样我就可以在variable节点中直接写CentMeng了。 看完data节点我们再来看看布局文件，TextView的text属性被我直接设置为了@{user.username},这样，该TextView一会直接将UserEntity实体类的username属性的值显示出来，对于显示age的TextView，我用了String.valueOf来显示，因为大家知道TextView并不能直接显示int型数据，所以需要一个简单的转换，事实上，我们还可以在{}里边进行一些简单的运算，这些我一会再说。 最后，我们来看看Activity中该怎么写，setContentView方法不能够再像以前那样来写了，换成下面的方式： 1DataBindingUtil.setContentView(this, R.layout.activity_main) 该方法有一个返回值，这个返回值就是系统根据我们的activity_main.xml布局生成的一个ViewModel类，所以完整写法如下： 12ActivityMainBinding activityMainBinding = DataBindingUtil.setContentView(this, R.layout.activity_main); 有了ViewModel，再把数据绑定上去就可以了，如下： 12345678910@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); ActivityMainBinding activityMainBinding = DataBindingUtil.setContentView(this, R.layout.activity_main); UserEntity user = new UserEntity(); user.setAge(34); user.setUsername(&quot;zhangsan&quot;); user.setNickname(&quot;张三&quot;); activityMainBinding.setUser(user);&#125; 基本的运算基本三目运算1234&lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;`username is :`+user.username&#125;&quot;/&gt; 两个??表示如果username属性为null则显示nickname属性，否则显示username属性。 字符拼接1234&lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;`username is :`+user.username&#125;&quot;/&gt; 这里的字符拼接不是用单引号哦，用的是ESC按键下面那个按键按出来的。目前DataBinding中的字符拼接还不支持中文。 根据数据来决定显示样式12345&lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:background=&quot;@&#123;user.age &amp;lt; 24 ? 0xFF0000FF:0xFFFF0000&#125;&quot; android:text=&quot;@&#123;String.valueOf(user.age)&#125;&quot;/&gt; 我在这里给TextView设置背景的时候，做了一个简单的判断，如果用户的年龄小于24，背景就显示为蓝色，否则背景就显示为红色，DataBinding里支持小于号但是不支持大于号，索性，大于小于号我都用转义字符来表示。 其他运算基本四则运算，逻辑与、逻辑或、取反位移等 数学表达式 + – / * % 字符串链接 + 逻辑操作符 &amp;&amp; || 二元操作符 &amp; | ^ 一元操作符 + – ! ~ Shift &gt;&gt; &gt;&gt;&gt; &lt;&lt; 比较 == &gt; &lt; &gt;= &lt;=&lt; p=””&gt; instanceof Grouping () Literals – character, String, numeric, null 值域引用（Field access） 通过[]访问数组里面的对象 自定义绑定（ImageView绑定示例）这里我们还得介绍DataBinding的另一项新功能，就是关于DataBinding自定义属性的问题，事实上，在我们使用DataBinding的时候，可以给一个控件自定义一个属性，比如我们下面即将说的这个绑定ImageView的案例。假设我现在想要通过Picasso显示一张网络图片，正常情况下这个显示很简单，可是如果我要通过DataBinding来实现，该怎么做呢？我们可以使用 1@BindingAdapter 注解来创建一个自定义属性，同时还要有一个配套的注解的方法。当我们在布局文件中使用这个自定义属性的时候，会触发这个被我们注解的方法，这样说大家可能还有一点模糊，我们来看看新的实体类： 123456789101112131415161718192021222324252627282930313233public class User &#123; private String username; private String userface; public User() &#123; &#125; public User(String userface, String username) &#123; this.userface = userface; this.username = username; &#125; @BindingAdapter(&quot;bind:userface&quot;) public static void getInternetImage(ImageView iv, String userface) &#123; Picasso.with(iv.getContext()).load(userface).into(iv); &#125; public String getUserface() &#123; return userface; &#125; public void setUserface(String userface) &#123; this.userface = userface; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125;&#125; 新类里边只有两个属性，分别是用户名和用户图像，用户图像中存储的实际上是一个网络图片地址，这里除了基本的get/set方法之外还多了一个叫做getInternetImage的网络方法，这个方法有一个注解@BindAdapter(“bind:userface”)，该注解表示当用户在ImageView中使用自定义属性userface的时候，会触发这个方法，我在这个方法中来为这个ImageView加载一张图片，这里有一点需要注意，就是该方法必须为静态方法。OK，我们再来看看这次的布局文件： 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;layout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; &gt; &lt;data&gt; &lt;variable name=&quot;user&quot; type=&quot;org.lenve.databinding2.User&quot;/&gt; &lt;/data&gt; &lt;LinearLayout xmlns:tools=&quot;http://schemas.android.com/tools&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:orientation=&quot;vertical&quot; tools:context=&quot;org.lenve.databinding2.MainActivity&quot;&gt; &lt;ImageView android:id=&quot;@+id/iv&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; app:userface=&quot;@&#123;user.userface&#125;&quot;&gt;&lt;/ImageView&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@&#123;user.username&#125;&quot;/&gt; &lt;/LinearLayout&gt;&lt;/layout&gt; 在ImageView控件中使用userface属性的时候，使用的前缀不是android而是app。再来看看Activity中的代码： 123456@Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); ActivityMainBinding dataBinding = DataBindingUtil.setContentView(this, R.layout.activity_main); dataBinding.setUser(new User(&quot;http://img2.cache.netease.com/auto/2016/7/28/201607282215432cd8a.jpg&quot;, &quot;张三&quot;)); &#125; 绑定ListView现在google退出了RecyclerView，其实他和ListView的方式是一样的，通用的。 下面是主体布局和item布局 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;RelativeLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:tools=&quot;http://schemas.android.com/tools&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; tools:context=&quot;org.lenve.databinding3.MainActivity&quot;&gt; &lt;ListView android:id=&quot;@+id/lv&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot;&gt;&lt;/ListView&gt;&lt;/RelativeLayout&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;layout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; &gt; &lt;data&gt; &lt;variable name=&quot;food&quot; type=&quot;org.lenve.databinding3.Food&quot;/&gt; &lt;/data&gt; &lt;RelativeLayout android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;96dp&quot; android:orientation=&quot;vertical&quot;&gt; &lt;ImageView android:id=&quot;@+id/iv&quot; android:layout_width=&quot;96dp&quot; android:layout_height=&quot;96dp&quot; android:padding=&quot;6dp&quot; app:img=&quot;@&#123;food.img&#125;&quot;/&gt; &lt;TextView android:id=&quot;@+id/description&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginLeft=&quot;8dp&quot; android:layout_toRightOf=&quot;@id/iv&quot; android:ellipsize=&quot;end&quot; android:maxLines=&quot;3&quot; android:text=&quot;@&#123;food.description&#125;&quot;/&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginLeft=&quot;8dp&quot; android:layout_toRightOf=&quot;@id/iv&quot; android:layout_alignParentBottom=&quot;true&quot; android:layout_marginBottom=&quot;2dp&quot; android:text=&quot;@&#123;food.keywords&#125;&quot; android:textStyle=&quot;bold&quot;/&gt; &lt;/RelativeLayout&gt;&lt;/layout&gt; 其他的和上面介绍一样，这里就不粘贴代码了，我们主要看看adapter吧 12345678910111213141516171819202122232425262728293031323334353637383940414243public class MyBaseAdapter&lt;T&gt; extends BaseAdapter &#123; private Context context; private LayoutInflater inflater; private int layoutId; private int variableId; private List&lt;T&gt; list; public MyBaseAdapter(Context context, int layoutId, List&lt;T&gt; list, int resId) &#123; this.context = context; this.layoutId = layoutId; this.list = list; this.variableId = resId; inflater = LayoutInflater.from(context); &#125; @Override public int getCount() &#123; return list.size(); &#125; @Override public Object getItem(int position) &#123; return list.get(position); &#125; @Override public long getItemId(int position) &#123; return position; &#125; @Override public View getView(int position, View convertView, ViewGroup parent) &#123; ViewDataBinding dataBinding; if (convertView == null) &#123; dataBinding = DataBindingUtil.inflate(inflater, layoutId, parent, false); &#125;else&#123; dataBinding = DataBindingUtil.getBinding(convertView); &#125; dataBinding.setVariable(variableId, list.get(position)); return dataBinding.getRoot(); &#125;&#125; 这个大概算是Adapter的终极写法了，如果你按这种方式来写Adapter，那么如果没有非常奇葩的需求，你这个App中可能就只有这一个给ListView使用的Adapter了，为什么这么说呢？因为这个Adapter中没有一个变量和我们的ListView沾边，解释一下几个变量吧：layoutId这个表示item布局的资源id，variableId是系统自动生成的，根据我们的实体类，直接从外部传入即可。另外注意布局加载方式为DataBindingUtil类中的inflate方法。OK，最后再来看看Activity: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class MainActivity extends AppCompatActivity &#123; private Handler mHandler = new Handler()&#123; @Override public void handleMessage(Message msg) &#123; MyBaseAdapter&lt;Food&gt; adapter = new MyBaseAdapter&lt;&gt;(MainActivity.this, R.layout.listview_item, foods, org.lenve.databinding3.BR.food); lv.setAdapter(adapter); &#125; &#125;; private List&lt;Food&gt; foods; private ListView lv; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); lv = ((ListView) findViewById(R.id.lv)); initData(); &#125; private void initData() &#123; OkHttpClient client = new OkHttpClient.Builder().build(); Request request = new Request.Builder().url(&quot;http://www.tngou.net/api/food/list?id=1&quot;).build(); client.newCall(request).enqueue(new Callback() &#123; @Override public void onFailure(Call call, IOException e) &#123; &#125; @Override public void onResponse(Call call, Response response) throws IOException &#123; if (response.isSuccessful()) &#123; parseJson(response.body().string()); &#125; &#125; &#125;); &#125; private void parseJson(String jsonStr) &#123; foods = new ArrayList&lt;&gt;(); try &#123; JSONObject jo = new JSONObject(jsonStr); JSONArray tngou = jo.getJSONArray(&quot;tngou&quot;); for (int i = 0; i &lt; tngou.length(); i++) &#123; JSONObject item = tngou.getJSONObject(i); String description = item.getString(&quot;description&quot;); String img = &quot;http://tnfs.tngou.net/image&quot;+item.getString(&quot;img&quot;); String keywords = &quot;【关键词】 &quot;+item.getString(&quot;keywords&quot;); String summary = item.getString(&quot;summary&quot;); foods.add(new Food(description, img, keywords, summary)); &#125; mHandler.sendEmptyMessage(0); &#125; catch (JSONException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 点击事件处理如果你使用DataBinding，我们的点击事件也会有新的处理方式，首先以ListView为例来说说如何绑定点击事件，在listview_item布局文件中每一个item的根节点添加如下代码： 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;layout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; &gt; .... .... &lt;RelativeLayout android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;96dp&quot; android:onClick=&quot;@&#123;food.onItemClick&#125;&quot; android:orientation=&quot;vertical&quot;&gt; &lt;ImageView android:id=&quot;@+id/iv&quot; android:layout_width=&quot;96dp&quot; android:layout_height=&quot;96dp&quot; android:padding=&quot;6dp&quot; app:img=&quot;@&#123;food.img&#125;&quot;/&gt; .... .... .... &lt;/RelativeLayout&gt;&lt;/layout&gt; OK，我给RelativeLayout容器添了onClick属性，属性的值为food.onItemClick，那么这个onItemClick到底是什么呢？其实就是在实体类Food中定义的一个方法，如下： 123public void onItemClick(View view) &#123; Toast.makeText(view.getContext(), getDescription(), Toast.LENGTH_SHORT).show(); &#125; 点击item获取当前position的数据，获取方式也是非常简单，直接get方法获取即可，比传统的ListView的点击事件通过position来获取数据方便多了。如果我想为关键字这个TextView添加点击事件也很简单，和上面一样，这里我就不再贴代码了. 数据更新处理单纯的更新Food对象并不能改变ListView的UI显示效果，那该怎么做呢？Google给我们提供了三种解决方案，分别如下： 让实体类继承自BaseObservable (最常用)让实体类继承自BaseObservable，然后给需要改变的字段的get方法添加上@Bindable注解，然后给需要改变的字段的set方法加上notifyPropertyChanged(org.lenve.databinding3.BR.description);一句即可，比如我想点击item的时候把description字段的数据全部改为111，我可以修改Food类变为下面的样子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Food extends BaseObservable &#123; private String description; private String img; private String keywords; private String summary; public Food() &#123; &#125; public Food(String description, String img, String keywords, String summary) &#123; this.description = description; this.img = img; this.keywords = keywords; this.summary = summary; &#125; @BindingAdapter(&quot;bind:img&quot;) public static void loadInternetImage(ImageView iv, String img) &#123; Picasso.with(iv.getContext()).load(img).into(iv); &#125; public void onItemClick(View view) &#123;// Toast.makeText(view.getContext(), getDescription(), Toast.LENGTH_SHORT).show(); setDescription(&quot;111&quot;); &#125; public void clickKeywords(View view) &#123; Toast.makeText(view.getContext(), getKeywords(), Toast.LENGTH_SHORT).show(); &#125; @Bindable public String getDescription() &#123; return description; &#125; public void setDescription(String description) &#123; this.description = description; notifyPropertyChanged(org.lenve.databinding3.BR.description); &#125; public String getImg() &#123; return img; &#125; public void setImg(String img) &#123; this.img = img; &#125; public String getKeywords() &#123; return keywords; &#125; public void setKeywords(String keywords) &#123; this.keywords = keywords; &#125; public String getSummary() &#123; return summary; &#125; public void setSummary(String summary) &#123; this.summary = summary; &#125;&#125; 使用DataBinding提供的ObservableFields来创建实体类这种方式使用起来略微麻烦，除了继承BaseObservable之外，创建属性的方式也变成下面这种： 1private final ObservableField&lt;String&gt; description = new ObservableField&lt;&gt;(); 属性的读写方式也变了，读取方式如下： 1description.get() 写入方式如下： 1this.description.set(description); OK，依据上面几个规则，我新定义的实体类如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Food extends BaseObservable &#123; private final ObservableField&lt;String&gt; description = new ObservableField&lt;&gt;(); private final ObservableField&lt;String&gt; img = new ObservableField&lt;&gt;(); private final ObservableField&lt;String&gt; keywords = new ObservableField&lt;&gt;(); private final ObservableField&lt;String&gt; summary = new ObservableField&lt;&gt;(); public Food() &#123; &#125; public Food(String description, String img, String keywords, String summary) &#123; this.description.set(description); this.keywords.set(keywords); this.img.set(img); this.summary.set(summary); &#125; @BindingAdapter(&quot;bind:img&quot;) public static void loadInternetImage(ImageView iv, String img) &#123; Picasso.with(iv.getContext()).load(img).into(iv); &#125; public void onItemClick(View view) &#123;// Toast.makeText(view.getContext(), getDescription(), Toast.LENGTH_SHORT).show(); setDescription(&quot;111&quot;); &#125; public void clickKeywords(View view) &#123; Toast.makeText(view.getContext(), getKeywords(), Toast.LENGTH_SHORT).show(); &#125; @Bindable public String getDescription() &#123; return description.get(); &#125; public void setDescription(String description) &#123; this.description.set(description); notifyPropertyChanged(org.lenve.databinding3.BR.description); &#125; public String getImg() &#123; return img.get(); &#125; public void setImg(String img) &#123; this.img.set(img); &#125; public String getKeywords() &#123; return keywords.get(); &#125; public void setKeywords(String keywords) &#123; this.keywords.set(keywords); &#125; public String getSummary() &#123; return summary.get(); &#125; public void setSummary(String summary) &#123; this.summary.set(summary); &#125;&#125; 使用DataBinding中提供的集合来存储数据即可DataBinding中给我们提供了一些现成的集合，用来存储数据，比如ObservableArrayList，ObservableArrayMap，因为这些用的少，我这里就不做介绍了。","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"解决HTTPS的SSL认证","date":"2016-09-21T15:14:27.000Z","path":"2016/09/21/解决HTTPS的SSL认证/","text":"相信很多人，在开发时候会遇到https检验证书问题，证书不对，无法调取接口。其实解决这个方法很简单，只需要写如下类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import java.security.KeyManagementException;import java.security.NoSuchAlgorithmException;import java.security.SecureRandom;import java.security.cert.X509Certificate;import javax.net.ssl.HostnameVerifier;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSession;import javax.net.ssl.TrustManager;import javax.net.ssl.X509TrustManager;/** * @author mengxiangcheng * @date 16/9/19 * @copyright ©2016 孟少杰 All Rights Reserved * @desc SSL认证 */public class FakeX509TrustManager implements X509TrustManager &#123; private static TrustManager[] trustManagers; private static final X509Certificate[] _AcceptedIssuers = new X509Certificate[] &#123;&#125;; @Override public void checkClientTrusted(X509Certificate[] x509Certificates, String s) throws java.security.cert.CertificateException &#123; //To change body of implemented methods use File | Settings | File Templates. &#125; @Override public void checkServerTrusted(X509Certificate[] x509Certificates, String s) throws java.security.cert.CertificateException &#123; //To change body of implemented methods use File | Settings | File Templates. &#125; public boolean isClientTrusted(X509Certificate[] chain) &#123; return true; &#125; public boolean isServerTrusted(X509Certificate[] chain) &#123; return true; &#125; @Override public X509Certificate[] getAcceptedIssuers() &#123; return _AcceptedIssuers; &#125; public static void allowAllSSL() &#123; HttpsURLConnection.setDefaultHostnameVerifier(new HostnameVerifier() &#123; @Override public boolean verify(String arg0, SSLSession arg1) &#123; // TODO Auto-generated method stub return true; &#125; &#125;); SSLContext context = null; if (trustManagers == null) &#123; trustManagers = new TrustManager[] &#123; new FakeX509TrustManager() &#125;; &#125; try &#123; context = SSLContext.getInstance(\"TLS\"); context.init(null, trustManagers, new SecureRandom()); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (KeyManagementException e) &#123; e.printStackTrace(); &#125; HttpsURLConnection.setDefaultSSLSocketFactory(context.getSocketFactory()); &#125;&#125; 然后在请求接口前加allowAllSSL()方法 1FakeX509TrustManager.allowAllSSL();","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://centmeng.github.io/tags/HTTPS/"}]},{"title":"android界面性能调优","date":"2016-09-21T02:52:06.000Z","path":"2016/09/21/android界面性能调优/","text":"Android渲染知识绘制原理Android系统要求每一帧都要在 16ms 内绘制完成，平滑的完成一帧意味着任何特殊的帧需要执行所有的渲染代码（包括 framework 发送给 GPU 和 CPU 绘制到缓冲区的命令）都要在 16ms 内完成，保持流畅的体验。这个速度允许系统在动画和输入事件的过程中以约 60 帧每秒（ 1秒 / 0.016帧每秒 = 62.5帧/秒 ）的平滑帧率来渲染。 如果你的应用没有在 16ms 内完成这一帧的绘制，假设你花了 24ms 来绘制这一帧，那么就会出现掉帧的情况。 系统准备将新的一帧绘制到屏幕上，但是这一帧并没有准备好，所有就不会有绘制操作，画面也就不会刷新。反馈到用户身上，就是用户盯着同一张图看了 32ms 而不是 16ms ，也就是说掉帧发生了。 掉帧掉帧是用户体验中一个非常核心的问题。丢弃了当前帧，并且之后不能够延续之前的帧率，这种不连续的间隔会容易会引起用户的注意，也就是我们常说的卡顿、不流畅。 引起掉帧的原因非常多，比如： 花了非常多时间重新绘制界面中的大部分东西，这样非常浪费CPU周期； 过度绘制严重，在绘制用户看不到的对象上花费了太多的时间； 有一大堆动画重复了一遍又一遍，消耗 CPU 、 GPU 资源； 频繁的触发垃圾回收； 为什么是60FpsAndroid系统要求每一帧都要在 16ms 内绘制完成，那么1秒的帧率就是约 60 帧每秒（ 1秒 / 0.016帧每秒 = 62.5帧/秒 ），那为什么要以 60 Fps来作为 App 性能的衡量标准呢？这是因为人眼和大脑之间的协作无法感知到超过 60 Fps的画面更新。 市面上绝大多数Android设备的屏幕刷新频率是 60 HZ。当然，超过 60 Fps 是没有意义的，人眼感知不到区别。24 Fps 是人眼能感知的连续线性的运动，所以是电影胶圈的常用帧率，因为这个帧率已经足够支撑大部分电影画面所要表达的内容，同时能最大限度地减少费用支出。但是，低于 30 Fps 是无法顺畅表现绚丽的画面内容的，此时就需要用到 60 Fps 来达到想要表达的效果。 应用的界面性能目标就是保持 60 Fps，这意味着每一帧你只有 16 ms（1秒 / 60帧率）的时间来处理所有的任务。 垃圾回收垃圾回收器是一个在应用运行期间自动释放那些不再引用的内存的机制，常称 GC 。频繁的 GC 也是导致严重性能问题的罪魁祸首之一。 前面提到，平滑的完成一帧意味着所有渲染代码都必须在 16ms 内完成。频繁的 GC 会严重限制一帧时间内的剩余时间，如果 GC 所做的工作超过了那些必须的工作，那么留给应用平滑的帧率的时间就越少。越接近 16ms ，在垃圾回收事件触发的时候，就越容易导致卡顿。 注意，Android4.4 引进了新的 ART 虚拟机来取代 Dalvik 虚拟机。它们的机制大有不同，简单而言： Dalvik 虚拟机的 GC 是非常耗资源的，并且在正常的情况下一个硬件性能不错的Android设备也会很容易耗费掉 10 - 20 ms 的时间； ART 虚拟机的GC会动态提升垃圾回收的效率，在 ART 中的中断，通常在 2 - 3 ms 间。 比 Dalvik 虚拟机有很大的性能提升； ART 虚拟机相对于 Dalvik 虚拟机来说的垃圾回收来说有一个很大的性能提升，但 2 - 3 ms 的回收时间对于超过16ms帧率的界限也是足够的。因此，尽管垃圾回收在 Android 5.0 之后不再是耗资源的行为，但也是始终需要尽可能避免的，特别是在执行动画的情况下，可能会导致一些让用户明显感觉的丢帧。 想了解更多详细的 ART 和 Dalvik 虚拟机垃圾回收机制，可「 戳我 」和「 我 」进行深入了解。 UI 线程UI 线程是应用的主线程，很多的性能和卡顿问题是由于我们在主线程中做了大量的工作。 所以，所有耗资源的操作，比如 IO 操作、网络操作、SQL 操作、列表刷新等，都应该用后台进程去实现，不能占用主线程，主线程是 UI 线程，是保持程序流畅的关键； 在 Android 5.0 版本里，Android 框架层引入了 “ Render Thread ” ，用于向 GPU 发送实际渲染的操作。这个线程减轻了一些 UI 线程减少的操作。但是输入、滚动和动画仍然在 UI thread，因为 Thread 必须能够响应操作。 垂直同步垂直同步是 Android4.1 通过 Project Butter 在 UI 架构中引入的新技术，同期引入的还有 Triple Buffer 和 HWComposer 等技术，都是为提高 UI 的流畅性而生。 举个例子，你拍了一张照片，然后旋转5度再拍另外一张照片，将两照片的中间剪开并拼接在一起，得到下图： 中间这部分有明显区别的部分，等价于设备刷新率和帧速率不一致的结果。 一般而言， GPU 的帧速率应高于刷新率，才不会卡顿或掉帧。如果屏幕刷新率比帧速率还快，屏幕会在两帧中显示同一个画面，这种断断续续情况持续发生时，用户将会很明显地感觉到动画的卡顿或者掉帧，然后又恢复正常，我们常称之为闪屏、跳帧、延迟。 应用应避免这些帧率下降的情况，以确保 GPU 能在屏幕刷新之前完成数据的获取及写入，保证动画流畅。 UI 绘制机制与栅格化绝大多数渲染操作都依赖两个硬件： CPU 、 GPU 。 CPU 负责 Measure 、 layout 、 Record 、 Execute 的计算操作， GPU 负责栅格化（ Rasterization ）操作。 非必需的视图组件会带来多余的 CPU 计算操作，还会占用多余的 GPU 资源。 栅格化（ Rasterization ）能将 Button 、 Shape 、 Path 、 Bitmap 等资源组件拆分到不同的像素上进行显示。这个操作很费时，所以引入了 GPU 来加快栅格化的操作。 CPU 负责把 UI 组件计算成多边形（ Polygons ），纹理（ Texture ），然后交给 GPU 进行栅格化渲染，再将处理结果传到屏幕上显示。 在 Android 里的那些资源组件的显示（比如 Bitmaps 、 Drawable ），都是一起打包到统一的纹理（ Texture ）当中，然后再传递到 GPU 里面。 图片的显示，则是先经过 CPU 的计算加载到内存中，再传给 GPU 进行渲染。 文字的显示，则是先经过 CPU 换算成纹理（ Texture ），再传给 GPU 进行渲染，返回到 CPU 绘制单个字符的时候，再重新引用经过 GPU 渲染的内容。 动画的显示更加复杂，我们需要在 16 ms 内处理完所有 CPU 和 GPU 的计算、绘制、渲染等操作，才能获得应用的流畅体验。 To检测和解决检测维度根据业务的不同与所需要的测试粒度的不同，就会有不同的检测维度。目前我所在业务所需的界面性能检测维度如下： 界面过度绘制；（检测过度绘制）渲染性能；（检测严格模式下的UI渲染性能呈现）布局边界合理性；（检测元素显示的合理性）还有专项测试中某些用户场景可能还包含着另外一些隐形的检测维度，比如： OpenGL 跟踪分析；GPU 视图更新合理性；Flash 硬件层更新合理性；动画加 / 减速状态问题点检测；…… 调试工具检测和解决界面性能问题很大程度上依赖于你的应用程序架构，幸运的是，Andorid 提供了很多调试工具，知道并学会使用这些工具很重要，它们可以帮助我们调试和分析界面性能问题，以让应用拥有更好的性能体验。下面列举Android常见的界面性能调试工具： Hierarchy View Hierarchy View 在Android SDK里自带，常用来查看界面的视图结构是否过于复杂，用于了解哪些视图过度绘制，又该如何进行改进。详见官方使用教程（需要翻墙）:「 戳我 」，官方介绍「 戳我 」。 Lint Lint 是 ADT 自带的静态代码扫描工具，可以给 XML 布局文件和 项目代码中不合理的或存在风险的模块提出改善性建议。官方关于 Lint 的实际使用的提示，列举几点如下： 包含无用的分支，建议去除； 包含无用的父控件，建议去除； 警告该布局深度过深； 建议使用 compound drawables ； 建议使用 merge 标签； …… 更多 Lint 的官方介绍「 戳我 」。 Systrace Systrace 在Android DDMS 里自带，可以用来跟踪 graphics 、view 和 window 的信息，发现一些深层次的问题。很麻烦，限制大，实际调试中我基本用不到。官方介绍 「戳我」。 Track Track 在 Android DDMS里自带，是个很棒的用来跟踪构造视图的时候哪些方法费时，精确到每一个函数，无论是应用函数还是系统函数，我们可以很容易地看到掉帧的地方以及那一帧所有函数的调用情况，找出问题点进行优化。官方介绍 「戳我」。 OverDraw 通过在 Android 设备的设置 APP 的开发者选项里打开 “ 调试 GPU 过度绘制 ” ，来查看应用所有界面及分支界面下的过度绘制情况，方便进行优化。官方介绍 「戳我」。 GPU 呈现模式分析 通过在 Android 设备的设置 APP 的开发者选项里启动 “ GPU 呈现模式分析 ” ，可以得到最近 128 帧 每一帧渲染的时间，分析性能渲染的性能及性能瓶颈。官方介绍 「戳我」。 StrictMode 通过在 Android 设备的设置 APP 的开发者选项里启动 “ 严格模式 ” ，来查看应用哪些操作在主线程上执行时间过长。当一些操作违背了严格模式时屏幕的四周边界会闪烁红色，同时输出 StrictMode 的相关信息到 LOGCAT 日志中。 Animator duration scale 通过在 Android 设备的设置 APP 的开发者选项里打开 “ 窗口动画缩放 ” / “ 过渡动画缩放 ” / “ 动画程序时长缩放 ”，来加速或减慢动画的时间，以查看加速或减慢状态下的动画是否会有问题。 Show hardware layer updates 通过在 Android 设备的设置 APP 的开发者选项里启动 “ 显示硬件层更新 ”，当 Flash 硬件层在进行更新时会显示为绿色。使用这个工具可以让你查看在动画期间哪些不期望更新的布局有更新，方便你进行优化，以获得应用更好的性能。实例《 Optimizing Android Hardware Layers 》（需要翻墙）:「戳我 」 如何解决前面提到过我司的目前所需的测试维度如下： 界面过度绘制；（检测过度绘制）渲染性能；（检测严格模式下的UI渲染性能呈现）布局边界合理性；（检测元素显示的合理性）故接下来将围绕这三两点，分别从概念、追踪、挖掘根源以及排查的工具来具体讲述如何解决，以及给开发的优化建议。 界面过度绘制（OverDraw）界面过度绘制过度绘制是一个术语，表示某些组件在屏幕上的一个像素点的绘制次数超过 1 次。 通俗来讲，绘制界面可以类比成一个涂鸦客涂鸦墙壁，涂鸦是一件工作量很大的事情，墙面的每个点在涂鸦过程中可能被涂了各种各样的颜色，但最终呈现的颜色却只可能是 1 种。这意味着我们花大力气涂鸦过程中那些非最终呈现的颜色对路人是不可见的，是一种对时间、精力和资源的浪费，存在很大的改善空间。绘制界面同理，花了太多的时间去绘制那些堆叠在下面的、用户看不到的东西，这样是在浪费CPU周期和渲染时间！ 追踪过度绘制通过在 Android 设备的设置 APP 的开发者选项里打开 “ 调试 GPU 过度绘制 ” ，来查看应用所有界面及分支界面下的过度绘制情况，方便进行优化。 Android 会在屏幕上显示不同深浅的颜色来表示过度绘制： 没颜色：没有过度绘制，即一个像素点绘制了 1 次，显示应用本来的颜色； 蓝色：1倍过度绘制，即一个像素点绘制了 2 次； 绿色：2倍过度绘制，即一个像素点绘制了 3 次； 浅红色：3倍过度绘制，即一个像素点绘制了 4 次； 深红色：4倍过度绘制及以上，即一个像素点绘制了 5 次及以上； 设备的硬件性能是有限的，当过度绘制导致应用需要消耗更多资源（超过了可用资源）的时候性能就会降低，表现为卡顿、不流畅、ANR 等。为了最大限度地提高应用的性能和体验，就需要尽可能地减少过度绘制，即更多的蓝色色块而不是红色色块。 实际测试，常用以下两点来作为过度绘制的测试指标，将过度绘制控制在一个约定好的合理范围内： 应用所有界面以及分支界面均不存在超过4X过度绘制（深红色区域）； 应用所有界面以及分支界面下，3X过度绘制总面积（浅红色区域）不超过屏幕可视区域的1/4； 过度绘制的根源过度绘制很大程度上来自于视图相互重叠的问题，其次还有不必要的背景重叠。 官方例子，比如一个应用所有的View都有背景的话，就会看起来像第一张图中那样，而在去除这些不必要的背景之后（指的是Window的默认背景、Layout的背景、文字以及图片的可能存在的背景），效果就像第二张图那样，基本没有过度绘制的情况。 不合理的xml布局对绘制的影响当布局文件的节点树的深度越深，XML 中的标签和属性设置越多，对界面的显示有灾难性影响。 一个界面要显示出来，第一步会进行解析布局，在 requestLayout 之后还要进行一系列的 measure 、 layout 、 draw 操作，若布局文件嵌套过深、拥有的标签属性过于臃肿，每一步的执行时间都会受到影响，而界面的显示是进行完这些操作后才会显示的，所以每一步操作的时间增长，最终显示的时间就会越长。 源码相关有能力且有兴趣看源码的童鞋，过度绘制的源码位置在: /frameworks/base/libs/hwui/OpenGLRenderer.cpp ，有兴趣的可以去研究查看。 123456789101112131415161718192021222324252627 if (Properties::debugOverdraw &amp;&amp; getTargetFbo() == 0) &#123; const Rect* clip = &amp;mTilingClip; mRenderState.scissor().setEnabled(true); mRenderState.scissor().set(clip-&gt;left, mState.firstSnapshot()-&gt;getViewportHeight() - clip-&gt;bottom, clip-&gt;right - clip-&gt;left, clip-&gt;bottom - clip-&gt;top); // 1x overdraw mRenderState.stencil().enableDebugTest(2); drawColor(mCaches.getOverdrawColor(1), SkXfermode::kSrcOver_Mode); // 2x overdraw mRenderState.stencil().enableDebugTest(3); drawColor(mCaches.getOverdrawColor(2), SkXfermode::kSrcOver_Mode); // 3x overdraw mRenderState.stencil().enableDebugTest(4); drawColor(mCaches.getOverdrawColor(3), SkXfermode::kSrcOver_Mode); // 4x overdraw and higher mRenderState.stencil().enableDebugTest(4, true); drawColor(mCaches.getOverdrawColor(4), SkXfermode::kSrcOver_Mode); mRenderState.stencil().disable(); &#125;&#125; 渲染性能（Rendering）渲染性能概念渲染性能往往是掉帧的罪魁祸首，这种问题很常见，让人头疼。好在 Android 给我们提供了一个强大的工具，帮助我们非常容易追踪性能渲染问题，看到究竟是什么导致你的应用出现卡顿、掉帧。 追踪渲染性能通过在 Android 设备的设置 APP 的开发者选项里打开 “ GPU 呈现模式分析 ” 选项，选择 ” 在屏幕上显示为条形图 “ 。 这个工具会在Android 设备的屏幕上实时显示当前界面的最近 128 帧 的 GPU 绘制图形数据，包括 StatusBar 、 NavBar 、 当前界面的 GPU 绘制图形柱状图数据。我们一般只需关心当前界面的 GPU 绘制图形数据即可。 界面上一共有 128 个小柱状图，代表的是当前界面最近的 128 帧 GPU 绘制图形数据。一个小柱状图代表的这一帧画面渲染的耗时，柱状图越高代表耗时越长。随着界面的刷新，柱状图信息也会实时滚动刷新。 中间有一条绿线，代表 16 ms ，保持动画流畅的关键就在于让这些垂直的柱状条尽可能地保持在绿线下面,任何时候超过绿线,你就有可能丢失一帧的内容。 每一个柱状图都是由三种颜色构成：蓝、红、黄。 蓝色代表的是这一帧绘制 Display List 的时间。通俗来说，就是记录了需要花费多长时间在屏幕上更新视图。用代码语言来说，就是执行视图的 onDraw 方法，创建或更新每一个视图的 Display List 的时间。 红色代表的是这一帧 OpenGL 渲染 Display List 所需要的时间。通俗来说，就是记录了执行视图绘制的耗时。用代码语言来说，就是 Android 用 OpenGL ES 的 API 接口进行 2D 渲染 Display List 的时间。 黄色代表的是这一帧 CPU 等待 GPU 处理的时间。通俗来说，就是 CPU 等待 GPU 发出接到命令的回复的等待时间。用代码语言来说，就是这是一个阻塞调用。 实际测试，常用以下两点来作为渲染性能的测试指标，将渲染性能控制在一个约定好的合理范围内： 执行应用的所有功能及分支功能，操作过程中涉及的柱状条区域应至少 90 % 保持到绿线下面； 从用户体检的角度主观判断应用在 512 M 内存的 Android 设备下所有操作过程中的卡顿感是否能接受，不会感觉突兀怪异； 渲染性能差的根源当你看到蓝色的线较高的时候，可能是由于你的视图突然无效了需要重新绘制，或者是自定义的视图过于复杂耗时过长。 当你看到红色的线较高的时候，可能是由于你的视图重新提交了需要重新绘制导致的（比如屏幕从竖屏旋转成横屏后当前界面重新创建），或者是自定义的视图很复杂，绘制起来很麻烦，导致耗时过长。比如下面这种视图： 当你看到黄色的线较高的时候，那就意味着你给 GPU 太多的工作，太多的负责视图需要 OpenGL 命令去绘制和处理，导致 CPU 迟迟没等到 GPU 发出接到命令的回复。 检测说明这个工具能够很好地帮助你找到渲染相关的问题，帮助你找到卡顿的性能瓶颈，追踪究竟是什么导致被测应用出现卡顿、变慢的情况，以便在代码层面进行优化。甚至让负责产品设计的人去改善他的设计，以获得良好的用户体验。 检测渲染性能时，常伴随着开启“ 严格模式 ” 查看应用哪些情景在 UI 线程（主线程）上执行时间过长。 另外有些强大但可能少用的工具在测试性能渲染时辅助分析，比如： HierarchyViewer：这个工具常用来查看界面的视图结构是否过于复杂，用于了解哪些视图过度绘制，又该如何进行改进； Tracer for OpenGL：这个工具收集了所有UI界面发给GPU的绘制命令。常用于辅助开发人员 DEBUG 、定位一些 HierarchyViewer 工具定位不了的疑难渲染细节问题。 UI绘制机制的补充说明如上面所说，布局和 UI 组件等都会先经过 CPU 计算成 GPU 能够识别并绘制的多边形（ Polygons ），纹理（ Texture ），然后交给 GPU 进行栅格化渲染，再将处理结果传到屏幕上显示。 “ CPU 计算成 GPU 能够识别并绘制的对象 ” 这个操作是在 DisplayList 的帮助下完成的。DisplayList 拥有要交给 GPU 栅格化渲染到屏幕上的数据信息。 DisplayList 会在某个视图第一次需要渲染时创建。当该视图有类似位置被移动等变化而需要重新渲染这个视图的时候，则只需 GPU 额外执行一次渲染指令冰更新到屏幕上就够了。但如果视图中的绘制内容发生变化时（比如不可见了），那之间的 DisplayList 就无法继续使用了，这时系统就会重新执行一次重新创建 DisplayList 、渲染DisplayList 并更新到屏幕上。这个流程的表现性能取决于该视图的复杂程度。 给开发的界面优化 Advice优化布局的结构布局结构太复杂，会减慢渲染的速度，造成性能瓶颈。我们可以通过以下这些惯用、有效的布局原则来优化： 避免复杂的View层级。布局越复杂就越臃肿，就越容易出现性能问题，寻找最节省资源的方式去展示嵌套的内容； 尽量避免在视图层级的顶层使用相对布局 RelativeLayout 。相对布局 RelativeLayout 比较耗资源，因为一个相对布局 RelativeLayout 需要两次度量来确保自己处理了所有的布局关系，而且这个问题会伴随着视图层级中的相对布局 RelativeLayout 的增多，而变得更严重； 布局层级一样的情况建议使用线性布局 LinearLayout 代替相对布局 RelativeLayout，因为线性布局 LinearLayout 性能要更高一些；确实需要对分支进行相对布局 RelativeLayout 的时候，可以考虑更优化的网格布局 GridLayout ，它已经预处理了分支视图的关系，可以避免两次度量的问题； 相对复杂的布局建议采用相对布局 RelativeLayout ，相对布局 RelativeLayout 可以简单实现线性布局 LinearLayout 嵌套才能实现的布局； 不要使用绝对布局 AbsoluteLayout ； 将可重复使用的组件抽取出来并用 标签进行重用。如果应用多个地方的 UI 用到某个布局，就将其写成一个布局部件，便于各个 UI 重用。官方详解 「 戳我 」 使用 merge 标签减少布局的嵌套层次，官方详解 「 戳我 」； 去掉多余的不可见背景。有多层背景颜色的布局，只留最上层的对用户可见的颜色即可，其他用户不可见的底层颜色可以去掉，减少无效的绘制操作； 尽量避免使用 layoutweight 属性。使用包含 layoutweight 属性的线性布局 LinearLayout 每一个子组件都需要被测量两次，会消耗过多的系统资源。在使用 ListView 标签与 GridView 标签的时候，这个问题显的尤其重要，因为子组件会重复被创建。平分布局可以使用相对布局 RelativeLayout 里一个 0dp 的 view 做分割线来搞定，如果不行，那就……； 合理的界面的布局结构应是宽而浅，而不是窄而深； 优化处理逻辑 按需载入视图。某些不怎么重用的耗资源视图，可以等到需要的时候再加载，提高UI渲染速度； 使用 ViewStub 标签来加载一些不常用的布局； 动态地 inflation view 性能要比用 ViewStub 标签的 setVisiblity 性能要好，当然某些功能的实现采用 ViewStub 标签更合适； 尽量避免不必要的耗资源操作，节省宝贵的运算时间； 避免在 UI 线程进行繁重的操作。耗资源的操作（比如 IO 操作、网络操作、SQL 操作、列表刷新等）耗资源的操作应用后台进程去实现，不能占用 UI 线程，UI 线程是主线程，主线程是保持程序流畅的关键，应该只操作那些核心的 UI 操作，比如处理视图的属性和绘制； 最小化唤醒机制。我们常用广播来接收那些期望响应的消息和事件，但过多的响应超过本身需求的话，会消耗多余的 Android 设备性能和资源。所以应该最小化唤醒机制，当应用不关心这些消失和事件时，就关闭广播，并慎重选择那些要响应的 Intent 。 为低端设备考虑，比如 512M 内存、双核 CPU 、低分辨率，确保你的应用可以满足不同水平的设备。 优化应用的启动速度。当应用启动一个应用时，界面的尽快反馈显示可以给用户一个良好的体验。为了启动更快，可以延迟加载一些 UI 以及避免在应用 Application 层级初始化代码。 本文摘选自 androidtest.org 《Android界面性能调优手册》","categories":[{"name":"进阶","slug":"进阶","permalink":"https://centmeng.github.io/categories/进阶/"}],"tags":[{"name":"Android性能调优","slug":"Android性能调优","permalink":"https://centmeng.github.io/tags/Android性能调优/"}]},{"title":"Vincent.M开发规范","date":"2016-09-20T06:25:40.000Z","path":"2016/09/20/Vincent-M开发规范/","text":"android 命名规范资源文件图标： ic_ 背景： bg_ 图片: img_ 资源背景命名 selector：选择前颜色选择后颜色有无置灰（true,false无置灰则不用谢）_圆角（corner无圆角不用谢）_linecorlor（边框颜色，与背景颜色一样不用写）_dashline（虚线则写） drawable形状等：背景颜色（red）圆角（corner）线颜色（red）_虚线（无圆角则表示直角，无虚线则表示实线） 资源背景前置参数： 背景：bg_ RadioButton：rb_ CheckBox：cb_ ps：RadioButton，CheckBox 图片的话命名 rb_主题色_形状 其他：通用style用通用方法命名，非通用activity主体名控件名标记属性 例如首页，下方radiobutton 命名方式：main_rb_bottom 颜色：color_未选择颜色变换色置灰色(没有则不写) layout:Activity: ac_fragment: fg_Dialog: dialog_Recyclerview： rv_GridView: grid_ android尺寸规范触摸目标大小最小触摸目标大小48dp，图标间距24dp（详细请看下图），头像40dp 网格式底部卡片间距 （我的标准是将下图24dp换成16dp,16dp换成12dp） 字体大小1234567&lt;dimen name=&quot;fourSize&quot;&gt;8sp&lt;/dimen&gt;&lt;dimen name=&quot;fiveSize&quot;&gt;10sp&lt;/dimen&gt;&lt;dimen name=&quot;sixSize&quot;&gt;12sp&lt;/dimen&gt;&lt;dimen name=&quot;sevenSize&quot;&gt;14sp&lt;/dimen&gt;&lt;dimen name=&quot;eightSize&quot;&gt;16sp&lt;/dimen&gt;&lt;dimen name=&quot;nineSize&quot;&gt;18sp&lt;/dimen&gt;&lt;dimen name=&quot;elevenSize&quot;&gt;22sp&lt;/dimen&gt; 边距相关12345678910111213&lt;dimen name=&quot;padding_half&quot;&gt;4dp&lt;/dimen&gt;&lt;dimen name=&quot;padding&quot;&gt;8dp&lt;/dimen&gt;&lt;dimen name=&quot;padding_doublehalf&quot;&gt;12dp&lt;/dimen&gt;&lt;dimen name=&quot;padding_double&quot;&gt;16dp&lt;/dimen&gt;&lt;dimen name=&quot;paddingX3&quot;&gt;24dp&lt;/dimen&gt;&lt;dimen name=&quot;paddingX4&quot;&gt;32dp&lt;/dimen&gt;&lt;dimen name=&quot;margin_half&quot;&gt;6dp&lt;/dimen&gt;&lt;dimen name=&quot;margin&quot;&gt;12dp&lt;/dimen&gt;&lt;dimen name=&quot;margin_double&quot;&gt;24dp&lt;/dimen&gt;&lt;dimen name=&quot;marginX3&quot;&gt;36dp&lt;/dimen&gt;&lt;dimen name=&quot;margin_normal&quot;&gt;16dp&lt;/dimen&gt;&lt;dimen name=&quot;margin_normal_half&quot;&gt;8dp&lt;/dimen&gt;&lt;dimen name=&quot;margin_normal_double&quot;&gt;32dp&lt;/dimen&gt; 标题栏：竖屏 48dp（有图标就要56dp，图标24dp，上下间距16dp） 横屏56dp 平板64dp 如下图： 常用字体颜色1234567&lt;color name=&quot;gray&quot;&gt;#ccc&lt;/color&gt; &lt;color name=&quot;lightgray&quot;&gt;#eee&lt;/color&gt; &lt;color name=&quot;darkgray&quot;&gt;#A9A9A9&lt;/color&gt; &lt;color name=&quot;black&quot;&gt;#000&lt;/color&gt; &lt;color name=&quot;deepgray&quot;&gt;#858689&lt;/color&gt; &lt;color name=&quot;lightblack&quot;&gt;#505153&lt;/color&gt; &lt;color name=&quot;transblack&quot;&gt;#333333&lt;/color&gt; 字体透明度白色背景中，标准的文本透明度是87%。 次级文本/图标， 不透明度应该是48%。 提示 文本，处于还要更低的视觉层级，那么不透明度是24% 字数好的阅读体验，每行大约60个字符。恰当字符数量是提高可读性的关键 基本色设置 其他关于UI性能优化可以参考：android界面性能调优","categories":[{"name":"进阶","slug":"进阶","permalink":"https://centmeng.github.io/categories/进阶/"}],"tags":[{"name":"规范","slug":"规范","permalink":"https://centmeng.github.io/tags/规范/"}]},{"title":"Android安全进阶攻略","date":"2016-09-20T03:02:18.000Z","path":"2016/09/20/Android安全进阶攻略/","text":"研究什么从攻击角度举例，可以是：对某个模块进行漏洞挖掘的方法，对某个漏洞进行利用的技术，通过逆向工程破解程序、解密数据，对系统或应用进行感染、劫持等破坏安全性的攻击技术等。 而防御上则是：查杀恶意应用的方法，检测和防范漏洞利用，为增强系统和第三方应用的安全性提供解决方案等。 学习什么理论知识主要是操作系统原理。这是非常重要的知识，是认识某一个具体系统的前提。比起单纯阅读源码和分析文章，自己动手编译系统内核，用调试器一步步调试内核更有帮助。最后还可以尝试自己编写内核驱动模块或分析已有的内核Rootkit来深入理解操作系统。对于操作系统，我们需要分析WRK，了解包括系统引导、内存管理、进程管理、线程调度、文件系统、网络驱动等内容。 掌握的语言掌握C/C++，能理解该语言被编译器处理后汇编层面的实现原理。了解Java，需要理解Dalvik/ART虚拟机内部的实现过程。对于x86/ARM汇编，能读懂即可，遇到不认识的指令能从指令集手册中找到答案。 另外，还需要掌握一门脚本语言，主要用来快速编写小工具或者POC，我推荐Python，因为开源社区中大部分Android安全分析类工具都是用Python编写的，例如知名的Androguard和Drozer。 逆向工程逆向工程绝对是一项必备技能。无论是分析恶意软件行为还是分析闭源软件漏洞，都需要逆向工程。但更重要的是，逆向工程能让我们从闭源程序中汲取营养，加快理解系统的速度。在对这类程序进行反汇编、调试的过程中，也会加深对操作系统、程序语言内部实现的理解，将上述知识串联起来。 神奇小子Geohot不久前利用CVE–2014–3153开发出了Android 4.4 Root通杀工具Towelroot，大多数人都不明白这个漏洞复杂的利用方法，但我通过对Towelroot逆向工程，第一时间理解了该漏洞利用的几项关键技术（Towelroot加入了大量混淆指令来反逆向工程，因而难度颇高）。也许我们不是天才，但逆向工程能让我们时不时地跟上天才的步伐。 理解Android系统Android源码非常庞大，即便只看系统组件，恐怕也要好几年。更何况其源码并不是Android手机的全部，还有Linux内核、基带、bootloader、TrustZone等底层模块等待我们探索。我们只需了解支撑Android系统运转的核心服务，以及Android系统的安全机制设计即可，其余内容则可在需要用到时再去分析。 就组件来说，下面是应该优先理解的。 Zygote：Android应用的孵化器，一切Android程序由此进程fork而来。 Binder：Android的进程间通信机制，它是Android平台最核心的功能组件。 Package Manager Service：应用安装包管理服务，不仅负责包的安装和卸载，更重要的是负责Android应用信息的查询和控制，例如Android权限管理。 Activity Manager Service：管理Android框架层的进程，也包含了Android应用四大组件的逻辑实现。 Dalvik虚拟机：虽然即将被ART取代，但Dalvik依然是帮助我们理解虚拟机和Android可执行程序文件格式的好教材。 就安全机制来说，则需要了解下面几点。 沙箱隔离：沙箱是基于不同应用之间User ID的不同而实现的，其本质是Linux对于不同用户间访问权限的隔离。 应用权限控制：Android应用需要申请相应的权限才能访问系统的资源和信息，大多数权限由Android框架层的API进行控制，另一部分权限映射到应用所在的Group ID上，由Linux内核做出控制。 SE Linux：Linux内核层的安全增强，是一套独立于传统Linux权限访问控制的强制性权限控制机制。Google已将这套机制移植到Android内核，这给内核漏洞利用带来了一些挑战。 Android安全研究的热点方向与现状手机Root与内核漏洞挖掘利用在Android 2.x时代，往往利用一些用户层程序的漏洞即可将手机root，现在则主要依赖内核漏洞。Android为Linux内核引入了新的内核模块，以及不同厂商的驱动方案。这就为系统内核引入了新的安全隐患，无论是高通、MTK还是三星猎户座，或者华为海思的芯片，多少都出现过一些内核漏洞，这是Android平台内核的一个主要攻击点。随着Google将SE Linux引入Android，攻击面有所减小，但不能完全解决内核漏洞利用的问题。从防御角度来说，同样面临着挑战：一些APT攻击如果利用内核漏洞，将能拿到系统的完全控制权。Android平台内核漏洞长期以来一直都在持续曝光，漏洞利用与防范依然是持续的热点。 从这个方向入手，首先需要了解Linux内核，然后不断对目前已公开的CVE漏洞进行分析，理解漏洞的成因和各个类型。在漏洞利用方面，有开源项目run_root_shell可作为参考，该项目包含了多个经典漏洞的利用实现，是入门的好材料。除此之外，还可以关注国外的POC程序或对一键root类产品做分析。 Android应用与系统框架层漏洞挖掘Android应用本身的问题主要集中在4大组件上，通常是一些逻辑处理问题导致信息泄露、身份认证绕过等。得益于Android沙箱机制，应用本身的攻击面是相对较小的，但一些开发人员似乎因此有恃无恐，在编码过程中表现出了较差的安全意识。此外围绕WebView或者SSL漏洞所引发的安全问题也比较常见。 框架层漏洞也是逻辑漏洞居多，但危害往往要比应用更大。比较著名的高危漏洞有Master Key签名绕过、WebView远程代码执行等。 目前已存在一些开源漏洞挖掘工具，如Drozer和Intent Fuzzer。我们可以在此基础上改进，如果有独特的挖掘思路，也可以自己尝试开发挖掘工具。 恶意软件攻防从数量上看，隐私窃取和钓鱼软件是目前Android平台主要的恶意软件类型。 如果用户对于应用申请的权限毫不知情，一款应用便能轻松获取用户的短信、通讯录、地理位置、录音等私密信息。Android平台需要有主动防御程序控制应用获取隐私的行为，目前有两种方法实现，一种是集成到厂商的ROM代码中，另一种则是利用API Hook实现。无论使用哪种方式，目前面临的问题都是如何更智能地为用户管理权限，以减少防御软件频繁弹窗带来的打扰。 市面上还充斥着大量的仿冒支付类应用，他们看起来可能与正版应用没有区别，因为这些仿冒应用是由正版应用篡改而来的。这些软件通常会有用户名和密码窃取的恶意代码。安全软件需要通过签名、代码特征等方法对此进行识别。 从趋势上看，恶意软件也不再局限于Android安装包（APK）的形式进行分发，而往往会带有Linux可执行文件（ELF），对系统进行更深层次的攻击。 目前市面上的安全产品对APK文件的查杀已较成熟，但对系统原生层的恶意软件查杀还没有特别完善的实现，对一些APT级别的新型威胁防御也仍在探索阶段。 知名的恶意软件Oldboot就是恶意程序使用底层技术对抗查杀的典型案例，该程序的完整分析细节已被公开，读者可从网络上搜索文章参考，以更好地理解如何分析恶意软件行为。 支付安全长期以来，手机支付使用短信验证码和独立支付密码解决支付者身份认证的问题。但仍存在短信遭人窃听或密码被窃取的风险，因此一些厂商效仿PC上的U盾方案，推出音频盾或蓝牙盾解决认证问题。而利用ARM架构下的TrustZone将支付认证过程独立于操作系统之外，也是一个方向。手机支付是很强的需求，依然有很多方案值得探索。 应用加固（加壳）与逆向工程游戏、支付类应用都有很强的反逆向工程、防破解、防篡改的需求，目前已有几家比较成熟的方案出现。但目前对于Android ELF格式程序的保护还不够，终极防护当然是使用类似PC上的VMProtect虚拟机。逆向工程与加固保护是一个不断攻防的过程，加固方案需要不断提升自己的保护强度，修补方案上的漏洞。而对于逆向工程师来说，不能逆向不意味着不能分析程序行为。一个好的软件跟踪方法往往让你事半功倍。 目前国内比较知名的加固方案有梆梆加固、360加固保、爱加密等，大家可以在这些产品官网上看到相应信息。 企业安全BYOD仅就终端设备本身来说，BYOD通常的方案是将手机系统隔离出两个环境：一个公用，一个私用，两者互不影响。三星的KNOX安全套件就提供了这样一个功能，使用Container，将需要隔离的公用应用包裹起来；Google也在开发类似应用，但传闻进展较慢。这类方案通常会和系统本身紧密结合，实现这样一套方案，或者发现这类方案中的安全漏洞，也是一个新的方向。 实例：Android 4.4.2系统vold漏洞如何在第一时间得知漏洞并非所有漏洞都会被纳入漏洞数据库（CVE），很多漏洞是被秘密修补的。一种方法是看版本升级时Android源码中的Change Log，运气好的话，你会从AOSP的Git Commit信息中注意到下面这句： 12Project： platform/system/void0de7c61: Validate asec names 洞的信息。如果你对这条提交记录背后的问题足够敏感，就能发现问题。 事实上，注意到这条信息的人是少数。大多数人得知这个问题前，已有人掌握了技术细节并开发出了一款针对Moto的root工具放到了XDA论坛和Twitter上。 如何掌握漏洞细节可能你会想到对这款名为“[Root 4.4.x] Pie for Motorola devices”工具进行逆向工程，但通过JEB，可以发现它经过了复杂的混淆。 这种混淆叫做dexGuard，比Google使用的ProGuard更复杂。花精力脱壳，还不如自己开发一个能做软件行为跟踪（trace）的ROM对其进行分析，但这是比较高级的话题。 先把工具放到一边，其实我们也可以通过现有的信息对该漏洞的利用方法进行分析。首先我们已获得了漏洞修补信息（其diff信息参见https://android.googlesource.com/platform/system/vold/+/0de7c61），这个问题出现在系统vold进程中，再结合源码和AIRBUS发布的分析报告，我们就可以得知以下信息。 问题出现在系统进程vold（卷管理进程），这是一个以root权限运行的分区管理进程。具体出现问题的功能模块是ASEC（Android Secure External Caches），其大致功能是对应用在SD卡上存储的文件进行权限管理。因为SD卡的文件系统格式是FAT，它本身是不支持文件权限管理的。 使用“vdc asec create YOURNAME ext4 none 2000 false”命令，vold进程接收到消息，在/data/app-sec目录下创建一个文件夹/data/app-sec/YOURNAME，并将这个目录mount成/mnt/asec/YOURNAME。 如代码所示，vold在将/data/app-sec/和YOURNAME拼凑在一起时，使用了sprintf，未对YOURNAME这个字符串做任何校验。这意味着我们可以将YOURNAME构造成“../../PATH”的形式。这样vold将为我们mount任何目录，如果这个目录已存在（例如/sbin），将被新mount的目录覆盖。 如何利用这个漏洞获取root既然vold可以为我们重复mount任意目录，就意味着我们可以使用自己指定的目录覆盖系统目录，也就等价于可以替换系统文件来获得以root身份执行的机会。将/sbin目录重新mount，替换/sbin/adbd文件，并且当系统进程adbd重新被init进程启动时，我们将有机会以root权限执行任意代码。这个漏洞利用代码非常简单。 这段命令首先创建了一个指向/sbin的符号链接/data/local/tmp/test1。然后使用vdc向vold发送触发漏洞的消息，vold将会把/data/app-sec/../../data/local/tmp/test1 mount起来。因为/data/local/tmp/test1是/sbin的符号链接，所以/sbin目录被覆盖成一个空分区。这个空分区是不可写入的，但我们能在该分区内建立符号链接，因此我为/data/local/tmp/adbd建立了一个符号链接是/sbin/adbd。这样一来，/sbin/adbd就指向了一个我们可控的文件：/data/local/tmp/adbd。当adbd进程被杀死，init进程将重新启动adbd，/data/local/tmp/adbd以root权限运行。后面要做的就是为手机安装su程序了，至此，手机root的过程完成。 摘抄自《程序员杂志》","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"android安全","slug":"android安全","permalink":"https://centmeng.github.io/tags/android安全/"}]},{"title":"Android修改字体大小效果不变","date":"2016-09-14T08:32:22.000Z","path":"2016/09/14/Android修改字体大小效果不变/","text":"很多开发者在开发的时候，会遇到有的用户修改字体大小，从而导致适配问题，在这里，可以通过如下代码，让自己App字体大小不变。具体代码如下: 12345678private void initFontScale() &#123; Configuration configuration = getResources().getConfiguration(); configuration.fontScale = (float) 1; //0.85 small size, 1 normal size, 1,15 big etc DisplayMetrics metrics = new DisplayMetrics(); getWindowManager().getDefaultDisplay().getMetrics(metrics); metrics.scaledDensity = configuration.fontScale * metrics.density; getBaseContext().getResources().updateConfiguration(configuration, metrics); 以上代码需要每个Activity中调用，所以最好写在BaseActivity中，不喜勿喷，博主小白一个。","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"适配","slug":"适配","permalink":"https://centmeng.github.io/tags/适配/"}]},{"title":"RxJava 介绍和使用","date":"2016-09-13T08:11:15.000Z","path":"2016/09/13/rxjava介绍/","text":"RxJava介绍 Git地址https://github.com/ReactiveX/RxJava https://github.com/ReactiveX/RxAndroid 介绍Rxjava在Github主页上给的介绍是”a library for composing asynchronous and event-based programs using observable sequences for the Java VM”（一个在 Java VM 上使用可观测的序列来组成异步的、基于事件的程序的库）。看到这样的解释，对于小白的我还是很高深的，其实，用一个词就可以代替，【异步】。那么他和Android其他异步Handler，AsyncTask有什么不同呢？这是因为RxJava有一个很好的优点就是简洁。当然这不是代码量的简洁，而是逻辑的简洁，让我们看一下下面例子，看下代码逻辑。详细介绍，会在使用中做详细解释。 需求是这样的： 界面上有一个自定义的视图 imageCollectorView ，它的作用是显示多张图片，并能使用 addImage(Bitmap) 方法来任意增加显示的图片。现在需要程序将一个给出的目录数组 File[] folders 中每个目录下的 png 图片都加载出来并显示在 imageCollectorView 中。需要注意的是，由于读取图片的这一过程较为耗时，需要放在后台执行，而图片的显示则必须在 UI 线程执行。常用的实现方式有多种，我这里贴出其中一种： 123456789101112131415161718192021222324252627Observable.from(folders) .flatMap(new Func1&lt;File, Observable&lt;File&gt;&gt;() &#123; @Override public Observable&lt;File&gt; call(File file) &#123; return Observable.from(file.listFiles()); &#125; &#125;) .filter(new Func1&lt;File, Boolean&gt;() &#123; @Override public Boolean call(File file) &#123; return file.getName().endsWith(&quot;.png&quot;); &#125; &#125;) .map(new Func1&lt;File, Bitmap&gt;() &#123; @Override public Bitmap call(File file) &#123; return getBitmapFromFile(file); &#125; &#125;) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Action1&lt;Bitmap&gt;() &#123; @Override public void call(Bitmap bitmap) &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); 下面再贴出一种平常使用的方式 1234567891011121314151617181920new Thread() &#123; @Override public void run() &#123; super.run(); for (File folder : folders) &#123; File[] files = folder.listFiles(); for (File file : files) &#123; if (file.getName().endsWith(&quot;.png&quot;)) &#123; final Bitmap bitmap = getBitmapFromFile(file); getActivity().runOnUiThread(new Runnable() &#123; @Override public void run() &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); &#125; &#125; &#125; &#125;&#125;.start(); 虽然使用RxJava代码量增多，但整体逻辑还是变得简单了，观察一下你会发现， RxJava 的这个实现，是一条从上到下的链式调用，没有任何嵌套，这在逻辑的简洁性上是具有优势的。当需求变得复杂时，这种优势将更加明显（试想如果还要求只选取前 10 张图片，常规方式要怎么办？如果有更多这样那样的要求呢？再试想，在这一大堆需求实现完两个月之后需要改功能，当你翻回这里看到自己当初写下的那一片迷之缩进，你能保证自己将迅速看懂，而不是对着代码重新捋一遍思路？）。 RxJava观察者模式 RxJava 的异步实现，是通过一种扩展的观察者模式来实现的。 RxJava 有四个基本概念：Observable (可观察者，即被观察者)、 Observer (观察者)、 subscribe (订阅)、事件。Observable 和 Observer 通过 subscribe() 方法实现订阅关系，从而 Observable 可以在需要的时候发出事件来通知 Observer。 与传统观察者模式不同， RxJava 的事件回调方法除了普通事件 onNext() （相当于 onClick() / onEvent()）之外，还定义了两个特殊的事件：onCompleted() 和 onError()。 onCompleted(): 事件队列完结。RxJava 不仅把每个事件单独处理，还会把它们看做一个队列。RxJava 规定，当不会再有新的 onNext() 发出时，需要触发 onCompleted() 方法作为标志。 onError(): 事件队列异常。在事件处理过程中出异常时，onError() 会被触发，同时队列自动终止，不允许再有事件发出。 在一个正确运行的事件序列中, onCompleted() 和 onError() 有且只有一个，并且是事件序列中的最后一个。需要注意的是，onCompleted() 和 onError() 二者也是互斥的，即在队列中调用了其中一个，就不应该再调用另一个。 RxJava基本实现基于以上的概念， RxJava 的基本实现主要有三点： 创建 ObserverObserver 即观察者，它决定事件触发的时候将有怎样的行为。 RxJava 中的 Observer 接口的实现方式： 12345678910111213141516Observer&lt;String&gt; observer = new Observer&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, &quot;Item: &quot; + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, &quot;Completed!&quot;); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, &quot;Error!&quot;); &#125;&#125;; 除了 Observer 接口之外，RxJava 还内置了一个实现了 Observer 的抽象类：Subscriber。 Subscriber 对 Observer 接口进行了一些扩展，但他们的基本使用方式是完全一样的： 12345678910111213141516Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, &quot;Item: &quot; + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, &quot;Completed!&quot;); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, &quot;Error!&quot;); &#125;&#125;; 不仅基本使用方式一样，实质上，在 RxJava 的 subscribe 过程中，Observer 也总是会先被转换成一个 Subscriber 再使用。所以如果你只想使用基本功能，选择 Observer 和 Subscriber 是完全一样的。它们的区别对于使用者来说主要有两点： onStart(): 这是 Subscriber 增加的方法。它会在 subscribe 刚开始，而事件还未发送之前被调用，可以用于做一些准备工作，例如数据的清零或重置。这是一个可选方法，默认情况下它的实现为空。需要注意的是，如果对准备工作的线程有要求（例如弹出一个显示进度的对话框，这必须在主线程执行）， onStart() 就不适用了，因为它总是在 subscribe 所发生的线程被调用，而不能指定线程。要在指定的线程来做准备工作，可以使用 doOnSubscribe() 方法. unsubscribe(): 这是 Subscriber 所实现的另一个接口 Subscription 的方法，用于取消订阅。在这个方法被调用后，Subscriber 将不再接收事件。一般在这个方法调用前，可以使用 isUnsubscribed() 先判断一下状态。 unsubscribe() 这个方法很重要，因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用，这个引用如果不能及时被释放，将有内存泄露的风险。所以最好保持一个原则：要在不再使用的时候尽快在合适的地方（例如 onPause() onStop() 等方法中）调用 unsubscribe() 来解除引用关系，以避免内存泄露的发生。 创建 ObservableObservable 即被观察者，它决定什么时候触发事件以及触发怎样的事件。 RxJava 使用 create() 方法来创建一个 Observable ，并为它定义事件触发规则： 123456789Observable observable = Observable.create(new Observable.OnSubscribe&lt;String&gt;() &#123; @Override public void call(Subscriber&lt;? super String&gt; subscriber) &#123; subscriber.onNext(&quot;Hello&quot;); subscriber.onNext(&quot;Hi&quot;); subscriber.onNext(&quot;Aloha&quot;); subscriber.onCompleted(); &#125;&#125;); 可以看到，这里传入了一个 OnSubscribe 对象作为参数。OnSubscribe 会被存储在返回的 Observable 对象中，它的作用相当于一个计划表，当 Observable 被订阅的时候，OnSubscribe 的 call() 方法会自动被调用，事件序列就会依照设定依次触发（对于上面的代码，就是观察者Subscriber 将会被调用三次 onNext() 和一次 onCompleted()）。这样，由被观察者调用了观察者的回调方法，就实现了由被观察者向观察者的事件传递，即观察者模式。 create() 方法是 RxJava 最基本的创造事件序列的方法。基于这个方法， RxJava 还提供了一些方法用来快捷创建事件队列，例如： just(T…): 将传入的参数依次发送出来。 123456Observable observable = Observable.just(&quot;Hello&quot;, &quot;Hi&quot;, &quot;Aloha&quot;);// 将会依次调用：// onNext(&quot;Hello&quot;);// onNext(&quot;Hi&quot;);// onNext(&quot;Aloha&quot;);// onCompleted(); from(T[]) / from(Iterable&lt;? extends T&gt;) : 将传入的数组或 Iterable 拆分成具体对象后，依次发送出来。 1234567String[] words = &#123;&quot;Hello&quot;, &quot;Hi&quot;, &quot;Aloha&quot;&#125;;Observable observable = Observable.from(words);// 将会依次调用：// onNext(&quot;Hello&quot;);// onNext(&quot;Hi&quot;);// onNext(&quot;Aloha&quot;);// onCompleted(); 上面 just(T…) 的例子和 from(T[]) 的例子，都和之前的 create(OnSubscribe) 的例子是等价的。 Subscribe (订阅)创建了 Observable 和 Observer 之后，再用 subscribe() 方法将它们联结起来，整条链子就可以工作了。代码形式很简单： 123observable.subscribe(observer);// 或者：observable.subscribe(subscriber); ps:有人可能会注意到， subscribe() 这个方法有点怪：它看起来是『observalbe 订阅了 observer / subscriber』而不是『observer / subscriber 订阅了 observalbe』，这看起来就像『杂志订阅了读者』一样颠倒了对象关系。这让人读起来有点别扭，不过如果把 API 设计成 observer.subscribe(observable) / subscriber.subscribe(observable) ，虽然更加符合思维逻辑，但对流式 API 的设计就造成影响了，比较起来明显是得不偿失的。 Observable.subscribe(Subscriber) 的内部实现是这样的（仅核心代码）： 1234567// 注意：这不是 subscribe() 的源码，而是将源码中与性能、兼容性、扩展性有关的代码剔除后的核心代码。// 如果需要看源码，可以去 RxJava 的 GitHub 仓库下载。public Subscription subscribe(Subscriber subscriber) &#123; subscriber.onStart(); onSubscribe.call(subscriber); return subscriber;&#125; 可以看到，subscriber() 做了3件事： 调用 Subscriber.onStart() 。这个方法在前面已经介绍过，是一个可选的准备方法。 调用 Observable 中的 OnSubscribe.call(Subscriber) 。在这里，事件发送的逻辑开始运行。从这也可以看出，在 RxJava 中， Observable 并不是在创建的时候就立即开始发送事件，而是在它被订阅的时候，即当 subscribe() 方法执行的时候。 将传入的 Subscriber 作为 Subscription 返回。这是为了方便 unsubscribe(). 整个过程中对象间的关系如下图： 除了 subscribe(Observer) 和 subscribe(Subscriber) ，subscribe() 还支持不完整定义的回调，RxJava 会自动根据定义创建出 Subscriber 。形式如下： 12345678910111213141516171819202122232425262728Action1&lt;String&gt; onNextAction = new Action1&lt;String&gt;() &#123; // onNext() @Override public void call(String s) &#123; Log.d(tag, s); &#125;&#125;;Action1&lt;Throwable&gt; onErrorAction = new Action1&lt;Throwable&gt;() &#123; // onError() @Override public void call(Throwable throwable) &#123; // Error handling &#125;&#125;;Action0 onCompletedAction = new Action0() &#123; // onCompleted() @Override public void call() &#123; Log.d(tag, &quot;completed&quot;); &#125;&#125;;// 自动创建 Subscriber ，并使用 onNextAction 来定义 onNext()observable.subscribe(onNextAction);// 自动创建 Subscriber ，并使用 onNextAction 和 onErrorAction 来定义 onNext() 和 onError()observable.subscribe(onNextAction, onErrorAction);// 自动创建 Subscriber ，并使用 onNextAction、 onErrorAction 和 onCompletedAction 来定义 onNext()、 onError() 和 onCompleted()observable.subscribe(onNextAction, onErrorAction, onCompletedAction); 简单解释一下这段代码中出现的 Action1 和 Action0。 Action0 是 RxJava 的一个接口，它只有一个方法 call()，这个方法是无参无返回值的；由于 onCompleted() 方法也是无参无返回值的，因此 Action0 可以被当成一个包装对象，将 onCompleted() 的内容打包起来将自己作为一个参数传入 subscribe() 以实现不完整定义的回调。这样其实也可以看做将 onCompleted() 方法作为参数传进了 subscribe()，相当于其他某些语言中的『闭包』。 Action1 也是一个接口，它同样只有一个方法 call(T param)，这个方法也无返回值，但有一个参数；与 Action0 同理，由于 onNext(T obj) 和 onError(Throwable error) 也是单参数无返回值的，因此 Action1 可以将 onNext(obj) 和 onError(error) 打包起来传入 subscribe() 以实现不完整定义的回调。事实上，虽然 Action0 和 Action1 在 API 中使用最广泛，但 RxJava 是提供了多个 ActionX 形式的接口 (例如 Action2, Action3) 的，它们可以被用以包装不同的无返回值的方法。","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"Fresco初始化一些配置","date":"2016-08-11T15:27:15.000Z","path":"2016/08/11/Fresco初始化一些配置/","text":"废话不多说，只是为了方便日后查找，以及让大家参考，所以直接上代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262/** * @author CentMeng csdn@vip.163.com on 16/3/11. * Fresco缓存配置 */public class ConfigConstants &#123; private static final int MAX_HEAP_SIZE = (int) Runtime.getRuntime().freeMemory();//分配的可用内存 public static final int MAX_MEMORY_CACHE_SIZE = MAX_HEAP_SIZE / 4;//使用的缓存数量 public static final int MAX_SMALL_DISK_VERYLOW_CACHE_SIZE = 30 * ByteConstants.MB;//小图极低磁盘空间缓存的最大值（特性：可将大量的小图放到额外放在另一个磁盘空间防止大图占用磁盘空间而删除了大量的小图） public static final int MAX_SMALL_DISK_LOW_CACHE_SIZE = 30 * ByteConstants.MB;//小图低磁盘空间缓存的最大值（特性：可将大量的小图放到额外放在另一个磁盘空间防止大图占用磁盘空间而删除了大量的小图） public static final int MAX_SMALL_DISK_CACHE_SIZE = 20 * ByteConstants.MB;//小图磁盘缓存的最大值（特性：可将大量的小图放到额外放在另一个磁盘空间防止大图占用磁盘空间而删除了大量的小图） public static final int MAX_DISK_CACHE_VERYLOW_SIZE = 30 * ByteConstants.MB;//默认图极低磁盘空间缓存的最大值 public static final int MAX_DISK_CACHE_LOW_SIZE = 50 * ByteConstants.MB;//默认图低磁盘空间缓存的最大值 public static final int MAX_DISK_CACHE_SIZE = 150 * ByteConstants.MB;//默认图磁盘缓存的最大值 private static final String IMAGE_PIPELINE_SMALL_CACHE_DIR = \"smallpic\";//小图所放路径的文件夹名 private static final String IMAGE_PIPELINE_CACHE_DIR = \"pic\";//默认图所放路径的文件夹名 private static ImagePipelineConfig sImagePipelineConfig; private ConfigConstants()&#123; &#125; /** * 初始化配置，单例 */ public static ImagePipelineConfig getImagePipelineConfig(Context context) &#123; if (sImagePipelineConfig == null) &#123; synchronized (ImagePipelineConfig.class) &#123; if (sImagePipelineConfig == null) &#123; sImagePipelineConfig = configureCaches(context); &#125; &#125; &#125; return sImagePipelineConfig; &#125; /** * 初始化配置 */ private static ImagePipelineConfig configureCaches(Context context) &#123; //得到当前外部存储设备的目录 File filePath = FileUtils.getDiskCacheDir(context,\"\"); //内存配置// final MemoryCacheParams bitmapCacheParams = new MemoryCacheParams(// ConfigConstants.MAX_MEMORY_CACHE_SIZE, // 内存缓存中总图片的最大大小,以字节为单位。// Integer.MAX_VALUE, // 内存缓存中图片的最大数量。// ConfigConstants.MAX_MEMORY_CACHE_SIZE, // 内存缓存中准备清除但尚未被删除的总图片的最大大小,以字节为单位。// Integer.MAX_VALUE, // 内存缓存中准备清除的总图片的最大数量。// ConfigConstants.MAX_MEMORY_CACHE_SIZE); // 内存缓存中单个图片的最大大小。 //修改内存图片缓存数量，空间策略（这个方式有点恶心） Supplier&lt;MemoryCacheParams&gt; mSupplierMemoryCacheParams= new Supplier&lt;MemoryCacheParams&gt;() &#123; @Override public MemoryCacheParams get() &#123; MemoryCacheParams bitmapCacheParams = new MemoryCacheParams( (int)Runtime.getRuntime().freeMemory(), // 内存缓存中总图片的最大大小,以字节为单位。 Integer.MAX_VALUE, // 内存缓存中图片的最大数量。 (int)Runtime.getRuntime().freeMemory(), // 内存缓存中准备清除但尚未被删除的总图片的最大大小,以字节为单位。 Integer.MAX_VALUE, // 内存缓存中准备清除的总图片的最大数量。 (int)Runtime.getRuntime().freeMemory()); LogUtils.e(LogConstant.DATA_OUTPUT,\"******图片内存\"+bitmapCacheParams.maxCacheSize+\"---\"+Runtime.getRuntime().freeMemory()); return bitmapCacheParams; &#125; &#125;; //小图片的磁盘配置 DiskCacheConfig diskSmallCacheConfig = DiskCacheConfig.newBuilder(context) .setBaseDirectoryPath(filePath)//缓存图片基路径 .setBaseDirectoryName(IMAGE_PIPELINE_SMALL_CACHE_DIR)//文件夹名// .setCacheErrorLogger(cacheErrorLogger)//日志记录器用于日志错误的缓存。// .setCacheEventListener(cacheEventListener)//缓存事件侦听器。// .setDiskTrimmableRegistry(diskTrimmableRegistry)//类将包含一个注册表的缓存减少磁盘空间的环境。 .setMaxCacheSize(ConfigConstants.MAX_DISK_CACHE_SIZE)//默认缓存的最大大小。 .setMaxCacheSizeOnLowDiskSpace(MAX_SMALL_DISK_LOW_CACHE_SIZE)//缓存的最大大小,使用设备时低磁盘空间。 .setMaxCacheSizeOnVeryLowDiskSpace(MAX_SMALL_DISK_VERYLOW_CACHE_SIZE)//缓存的最大大小,当设备极低磁盘空间// .setVersion(version) .build(); //默认图片的磁盘配置 DiskCacheConfig diskCacheConfig = DiskCacheConfig.newBuilder(context) .setBaseDirectoryPath(filePath)//缓存图片基路径 .setBaseDirectoryName(IMAGE_PIPELINE_CACHE_DIR)//文件夹名 .setCacheErrorLogger(new CacheErrorLogger() &#123; @Override public void logError(CacheErrorCategory category, Class&lt;?&gt; clazz, String message, Throwable throwable) &#123; LogUtils.e(LogConstant.DATA_OUTPUT,\"*******图片错误\"+message); &#125; &#125;)//日志记录器用于日志错误的缓存。 //缓存事件侦听器。// .setDiskTrimmableRegistry(diskTrimmableRegistry)//类将包含一个注册表的缓存减少磁盘空间的环境。 .setMaxCacheSize(ConfigConstants.MAX_DISK_CACHE_SIZE)//默认缓存的最大大小。 .setMaxCacheSizeOnLowDiskSpace(MAX_DISK_CACHE_LOW_SIZE)//缓存的最大大小,使用设备时低磁盘空间。 .setMaxCacheSizeOnVeryLowDiskSpace(MAX_DISK_CACHE_VERYLOW_SIZE)//缓存的最大大小,当设备极低磁盘空间// .setVersion(version) .build(); //渐变配置 ProgressiveJpegConfig progressiveJpegConfig = new ProgressiveJpegConfig() &#123; @Override public int getNextScanNumberToDecode(int scanNumber) &#123; return scanNumber + 2; &#125; public QualityInfo getQualityInfo(int scanNumber) &#123; boolean isGoodEnough = (scanNumber &gt;= 5); return ImmutableQualityInfo.of(scanNumber, isGoodEnough, false); &#125; &#125;; //缓存图片配置 ImagePipelineConfig.Builder configBuilder = ImagePipelineConfig.newBuilder(context)// .setAnimatedImageFactory(AnimatedImageFactory animatedImageFactory)//图片加载动画 .setBitmapMemoryCacheParamsSupplier(mSupplierMemoryCacheParams)//内存缓存配置（一级缓存，已解码的图片）// .setCacheKeyFactory(cacheKeyFactory)//缓存Key工厂// .setEncodedMemoryCacheParamsSupplier(mSupplierMemoryCacheParams)//内存缓存和未解码的内存缓存的配置（二级缓存）// .setExecutorSupplier(executorSupplier)//线程池配置// .setImageCacheStatsTracker(imageCacheStatsTracker)//统计缓存的命中率// .setImageDecoder(ImageDecoder imageDecoder) //图片解码器配置// .setIsPrefetchEnabledSupplier(Supplier&lt;Boolean&gt; isPrefetchEnabledSupplier)//图片预览（缩略图，预加载图等）预加载到文件缓存 .setMainDiskCacheConfig(diskCacheConfig)//磁盘缓存配置（总，三级缓存）// .setMemoryTrimmableRegistry(memoryTrimmableRegistry) //内存用量的缩减,有时我们可能会想缩小内存用量。比如应用中有其他数据需要占用内存，不得不把图片缓存清除或者减小 或者我们想检查看看手机是否已经内存不够了。// .setNetworkFetchProducer(networkFetchProducer)//自定的网络层配置：如OkHttp，Volley// .setPoolFactory(poolFactory)//线程池工厂配置 .setProgressiveJpegConfig(progressiveJpegConfig)//渐进式JPEG图// .setRequestListeners(requestListeners)//图片请求监听// .setResizeAndRotateEnabledForNetwork(boolean resizeAndRotateEnabledForNetwork)//调整和旋转是否支持网络图片 .setSmallImageDiskCacheConfig(diskSmallCacheConfig)//磁盘缓存配置（小图片，可选～三级缓存的小图优化缓存） ; return configBuilder.build(); &#125; //圆形，圆角切图，对动图无效// public static RoundingParams getRoundingParams()&#123;// RoundingParams roundingParams = RoundingParams.fromCornersRadius(7f);//// roundingParams.asCircle();//圆形//// roundingParams.setBorder(color, width);//fresco:roundingBorderWidth=\"2dp\"边框 fresco:roundingBorderColor=\"@color/border_color\"//// roundingParams.setCornersRadii(radii);//半径//// roundingParams.setCornersRadii(topLeft, topRight, bottomRight, bottomLeft)//fresco:roundTopLeft=\"true\" fresco:roundTopRight=\"false\" fresco:roundBottomLeft=\"false\" fresco:roundBottomRight=\"true\"//// roundingParams. setCornersRadius(radius);//fresco:roundedCornerRadius=\"1dp\"圆角//// roundingParams.setOverlayColor(overlayColor);//fresco:roundWithOverlayColor=\"@color/corner_color\"//// roundingParams.setRoundAsCircle(roundAsCircle);//圆//// roundingParams.setRoundingMethod(roundingMethod);//// fresco:progressBarAutoRotateInterval=\"1000\"自动旋转间隔// // 或用 fromCornersRadii 以及 asCircle 方法// return roundingParams;// &#125;//// //Drawees DraweeHierarchy 组织// public static GenericDraweeHierarchy getGenericDraweeHierarchy(Context context)&#123;// GenericDraweeHierarchy gdh = new GenericDraweeHierarchyBuilder(context.getResources())//// .reset()//重置//// .setActualImageColorFilter(colorFilter)//颜色过滤//// .setActualImageFocusPoint(focusPoint)//focusCrop, 需要指定一个居中点//// .setActualImageMatrix(actualImageMatrix)//// .setActualImageScaleType(actualImageScaleType)//fresco:actualImageScaleType=\"focusCrop\"缩放类型//// .setBackground(background)//fresco:backgroundImage=\"@color/blue\"背景图片//// .setBackgrounds(backgrounds)//// .setFadeDuration(fadeDuration)//fresco:fadeDuration=\"300\"加载图片动画时间// .setFailureImage(ConfigConstants.sErrorDrawable)//fresco:failureImage=\"@drawable/error\"失败图//// .setFailureImage(failureDrawable, failureImageScaleType)//fresco:failureImageScaleType=\"centerInside\"失败图缩放类型//// .setOverlay(overlay)//fresco:overlayImage=\"@drawable/watermark\"叠加图//// .setOverlays(overlays)// .setPlaceholderImage(ConfigConstants.sPlaceholderDrawable)//fresco:placeholderImage=\"@color/wait_color\"占位图//// .setPlaceholderImage(placeholderDrawable, placeholderImageScaleType)//fresco:placeholderImageScaleType=\"fitCenter\"占位图缩放类型//// .setPressedStateOverlay(drawable)//fresco:pressedStateOverlayImage=\"@color/red\"按压状态下的叠加图// .setProgressBarImage(new ProgressBarDrawable())//进度条fresco:progressBarImage=\"@drawable/progress_bar\"进度条//// .setProgressBarImage(progressBarImage, progressBarImageScaleType)//fresco:progressBarImageScaleType=\"centerInside\"进度条类型//// .setRetryImage(retryDrawable)//fresco:retryImage=\"@drawable/retrying\"点击重新加载//// .setRetryImage(retryDrawable, retryImageScaleType)//fresco:retryImageScaleType=\"centerCrop\"点击重新加载缩放类型// .setRoundingParams(RoundingParams.asCircle())//圆形/圆角fresco:roundAsCircle=\"true\"圆形// .build();// return gdh;// &#125;////////DraweeView～～～SimpleDraweeView——UI组件//// public static SimpleDraweeView getSimpleDraweeView(Context context,Uri uri)&#123;//// SimpleDraweeView simpleDraweeView=new SimpleDraweeView(context);//// simpleDraweeView.setImageURI(uri);//// simpleDraweeView.setAspectRatio(1.33f);//宽高缩放比//// return simpleDraweeView;//// &#125;//// //SimpleDraweeControllerBuilder// public static SimpleDraweeControllerBuilder getSimpleDraweeControllerBuilder(SimpleDraweeControllerBuilder sdcb,Uri uri, Object callerContext,DraweeController draweeController)&#123;// SimpleDraweeControllerBuilder controllerBuilder = sdcb// .setUri(uri)// .setCallerContext(callerContext)//// .setAspectRatio(1.33f);//宽高缩放比// .setOldController(draweeController);// return controllerBuilder;// &#125;//// //图片解码// public static ImageDecodeOptions getImageDecodeOptions()&#123;// ImageDecodeOptions decodeOptions = ImageDecodeOptions.newBuilder()//// .setBackgroundColor(Color.TRANSPARENT)//图片的背景颜色//// .setDecodeAllFrames(decodeAllFrames)//解码所有帧//// .setDecodePreviewFrame(decodePreviewFrame)//解码预览框//// .setForceOldAnimationCode(forceOldAnimationCode)//使用以前动画//// .setFrom(options)//使用已经存在的图像解码//// .setMinDecodeIntervalMs(intervalMs)//最小解码间隔（分位单位）// .setUseLastFrameForPreview(true)//使用最后一帧进行预览// .build();// return decodeOptions;// &#125;//// //图片显示// public static ImageRequest getImageRequest(InstrumentedDraweeView view,String uri)&#123;// ImageRequest imageRequest = ImageRequestBuilder.newBuilderWithSource(Uri.parse(uri))//// .setAutoRotateEnabled(true)//自动旋转图片方向//// .setImageDecodeOptions(getImageDecodeOptions())// 图片解码库//// .setImageType(ImageType.SMALL)//图片类型，设置后可调整图片放入小图磁盘空间还是默认图片磁盘空间//// .setLocalThumbnailPreviewsEnabled(true)//缩略图预览，影响图片显示速度（轻微）// .setLowestPermittedRequestLevel(RequestLevel.FULL_FETCH)//请求经过缓存级别 BITMAP_MEMORY_CACHE，ENCODED_MEMORY_CACHE，DISK_CACHE，FULL_FETCH//// .setPostprocessor(postprocessor)//修改图片//// .setProgressiveRenderingEnabled(true)//渐进加载，主要用于渐进式的JPEG图，影响图片显示速度（普通）// .setResizeOptions(new ResizeOptions(view.getLayoutParams().width, view.getLayoutParams().height))//调整大小//// .setSource(Uri uri)//设置图片地址// .build();// return imageRequest;// &#125;//// //DraweeController 控制 DraweeControllerBuilder// public static DraweeController getDraweeController(ImageRequest imageRequest,InstrumentedDraweeView view)&#123;// DraweeController draweeController = Fresco.newDraweeControllerBuilder()//// .reset()//重置// .setAutoPlayAnimations(true)//自动播放图片动画//// .setCallerContext(callerContext)//回调// .setControllerListener(view.getListener())//监听图片下载完毕等//// .setDataSourceSupplier(dataSourceSupplier)//数据源//// .setFirstAvailableImageRequests(firstAvailableImageRequests)//本地图片复用，可加入ImageRequest数组// .setImageRequest(imageRequest)//设置单个图片请求～～～不可与setFirstAvailableImageRequests共用，配合setLowResImageRequest为高分辨率的图//// .setLowResImageRequest(ImageRequest.fromUri(lowResUri))//先下载显示低分辨率的图// .setOldController(view.getController())//DraweeController复用// .setTapToRetryEnabled(true)//点击重新加载图// .build();// return draweeController;// &#125;//// //默认加载图片和失败图片// public static Drawable sPlaceholderDrawable;// public static Drawable sErrorDrawable;//// @SuppressWarnings(\"deprecation\")// public static void init(final Resources resources) &#123;// if (sPlaceholderDrawable == null) &#123;// sPlaceholderDrawable = resources.getDrawable(R.color.placeholder);// &#125;// if (sErrorDrawable == null) &#123;// sErrorDrawable = resources.getDrawable(R.color.error);// &#125;// &#125;&#125;","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"volley框架介绍","date":"2016-08-11T13:44:07.000Z","path":"2016/08/11/volley框架介绍/","text":"volley介绍开发android应用很多时候都要涉及网络操作，Android SDK中提供了HttpClient 和 HttpUrlConnection两种方式用来处理网络操作，但当应用比较复杂的时候需要我们编写大量的代码处理很多东西：图像缓存，请求的调度等等； 而Volley框架就是为解决这些而生的，它与2013年Google I/O大会上被提出：使得Android应用网络操作更方便更快捷；抽象了底层Http Client等实现的细节，让开发者更专注与产生RESTful Request。另外，Volley在不同的线程上异步执行所有请求而避免了阻塞主线程。 目前的HTTP通信框架，AsyncHttpClient，网络图片加载框架，Universal-Image-Loader，而Volley是将以上两个框架集于一身。 volley下载1git clone https://android.googlesource.com/platform/frameworks/volley 或者使用我的地址，很久没有更新了，请见谅,解决了SSL证书问题以及做了简单的缓存 volley特点 自动调度网络请求 多个并发的网络连接 通过使用标准的HTTP缓存机制保持磁盘和内存响应的一致 支持请求优先级 支持取消请求的强大API，可以取消单个请求或多个 易于定制 健壮性：便于正确的更新UI和获取数据 包含调试和追踪工具 volley使用我一般都是使用封装好的方法 创建volleyHttpClient对象封装了返回Gson和String的get,post请求以及相应需要增加oauth验证的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499public class VolleyHttpClient &#123; public static final int GET = 1; public static final int GET_AOUTH = 2; public static final int POST = 3; public static final int POST_AOUTH = 4; public static final int GETSTRING = 5; public static final int GETSTRING_AOUTH = 6; public static final int POSTSTRING_AOUTH = 7; private static final String TAG = &quot;VolleyHttpClient&quot;; private static HttpService httpService; private final static Gson gson = new Gson(); private static BaseActivity activity; public VolleyHttpClient(HttpService httpService) &#123; this.httpService = httpService; &#125; /** * 传入初始化好的httpService 实例 * * @param httpService * @return */ public static VolleyHttpClient newInstance(HttpService httpService, Context context) &#123; activity = (BaseActivity) context; if (httpService != null) &#123; return new VolleyHttpClient(httpService); &#125; return null; &#125; public void post(ApiRequest apiRequest) &#123; doNetTask(POST, apiRequest, DataCacheType.NO_CACHE); &#125; public void postWithOAuth(ApiRequest apiRequest) &#123; doNetTask(POST_AOUTH, apiRequest, DataCacheType.NO_CACHE); &#125; public void get(ApiRequest apiRequest) &#123; doNetTask(GET, apiRequest, DataCacheType.NO_CACHE); &#125; public void getWithOAuth(ApiRequest apiRequest) &#123; doNetTask(GET_AOUTH, apiRequest, DataCacheType.NO_CACHE); &#125; public void doNetTask(int method, ApiRequest apiRequest) &#123; doNetTask(method, apiRequest, DataCacheType.NO_CACHE); &#125; public void doNetTask(int method, ApiRequest apiRequest, DataCacheType cacheType) &#123; doNetTask(method, apiRequest, cacheType, false, null); &#125; public void doNetTask(int method, ApiRequest apiRequest, DataCacheType cacheType, boolean needLogin, BaseActivity activity) &#123; doNetTask(method, apiRequest, cacheType, needLogin, activity, false); &#125; public void doNetTask(int method, ApiRequest apiRequest, DataCacheType cacheType, boolean needLogin, BaseActivity activity, boolean needFinish) &#123; if (needLogin &amp;&amp; activity.app.getUserParam() == null) &#123; try &#123; activity.cancelLoadingDialog(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Intent intent = new Intent(activity, LoginActivity_.class); activity.startActivity(intent); if (needFinish) &#123; activity.finish(); &#125; return; &#125; switch (method) &#123; case GET: //USER_OLD_CACHE有缓存先加载缓存数据，然后网络请求只是保存数据 //TEMP_CACHE有缓存先加载缓存数据，不进行网络请求 get(apiRequest, false, cacheType); break; case GET_AOUTH: get(apiRequest, true, cacheType); break; case POST: post(apiRequest, false, cacheType); break; case POST_AOUTH: post(apiRequest, true, cacheType); break; case GETSTRING: getByStringRequest(apiRequest, false, cacheType); break; case GETSTRING_AOUTH: getByStringRequest(apiRequest, true, cacheType); break; case POSTSTRING_AOUTH: postByStringRequest(apiRequest, true, cacheType); break; &#125; &#125; /** * 不用传header以及accesstoken的GET请求 * * @param apiRequest */ public void get(ApiRequest apiRequest, boolean needOauth, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); if (needOauth) &#123; String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; if (!TextUtils.isEmpty(accessToken)) &#123; LogUtils.e(&quot;access_token&quot;, accessToken); &#125;// header.put(&quot;Authorization&quot;, &quot;Bearer&quot; + &quot; &quot; + accessToken); header.put(&quot;token&quot;, accessToken); &#125; String url = apiRequest.getUrl(Method.GET); Listener listener = apiRequest.getListener(); LogUtils.e(&quot;------cacheType---------&quot;, cacheType.name()); switch (cacheType) &#123; case USE_OLD_CACHE: case TEMP_CACHE: String cacheStr =&quot;&quot;; if(cacheType == DataCacheType.TEMP_CACHE)&#123; cacheStr = DataCache.getDataCache().queryTempCache(url); &#125;else &#123; cacheStr = DataCache.getDataCache().queryCache(url); &#125; if (!TextUtils.isEmpty(cacheStr)) &#123; try &#123; if (apiRequest.getResponseType() != null) &#123; //有缓存先加载缓存数据 listener.onResponse(gson.fromJson(cacheStr, apiRequest.getResponseType())); //有缓存先加载缓存数据，不进行网络请求 if (cacheType == DataCacheType.TEMP_CACHE) &#123; return; &#125; &#125; else &#123; listener.onResponse(cacheStr); if (cacheType == DataCacheType.TEMP_CACHE) &#123; return; &#125; &#125; &#125; catch (JsonSyntaxException e) &#123; e.printStackTrace(); &#125; &#125; break; default: break; &#125; GsonRequest request = new GsonRequest(Method.GET, url, apiRequest.getResponseType(), header, null, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); //网络错误并且使用TEMP_CACHE和use old cache还有待考察 if (!useCache(apiRequest.getResponseType(), url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; public void post(ApiRequest apiRequest, boolean needOauth, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); if (needOauth) &#123; String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; if (!TextUtils.isEmpty(accessToken)) &#123; LogUtils.e(&quot;access_token&quot;, accessToken); &#125;// header.put(&quot;Authorization&quot;, &quot;Bearer&quot; + &quot; &quot; + accessToken); header.put(&quot;token&quot;, accessToken); &#125; LogUtils.e(&quot;------cacheType---------&quot;, cacheType.name()); String url = apiRequest.getUrl(Request.Method.POST); Listener listener = apiRequest.getListener(); if (apiRequest.getParams() != null &amp;&amp; apiRequest.getParams().size() &gt; 0) &#123; //post有参数时候请求不建议使用use_old_cache方式，因为根据路径存储，post参数不在路径中 if (cacheType == DataCacheType.USE_OLD_CACHE) &#123; cacheType = DataCacheType.CACHE; &#125; &#125; switch (cacheType) &#123; case USE_OLD_CACHE: case TEMP_CACHE: String cacheStr = DataCache.getDataCache().queryCache(url); if (!TextUtils.isEmpty(cacheStr)) &#123; try &#123; if (apiRequest.getResponseType() != null) &#123; //有缓存先加载缓存数据 listener.onResponse(gson.fromJson(cacheStr, apiRequest.getResponseType())); //有缓存先加载缓存数据，不进行网络请求 if (cacheType == DataCacheType.TEMP_CACHE) &#123; return; &#125; &#125; else &#123; listener.onResponse(cacheStr); if (cacheType == DataCacheType.TEMP_CACHE) &#123; return; &#125; &#125; &#125; catch (JsonSyntaxException e) &#123; e.printStackTrace(); &#125; &#125; break; default: break; &#125; GsonRequest request = new GsonRequest(Request.Method.POST, url, apiRequest.getResponseType(), header, apiRequest.getParams(), listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); //网络错误并且使用TEMP_CACHE和use old cache还有待考察 if (!useCache(apiRequest.getResponseType(), url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; /** * 图片请求 */ public ImageLoader.ImageContainer loadingImage(ImageView imageView, String url, int loadingResid, int errorResid, BitmapCache mCache, ImageLoader.ImageListener listener) &#123; if (listener == null) &#123; listener = ImageLoader.getImageListener(imageView, loadingResid, errorResid); &#125; if (httpService.httpQueue != null) &#123; ImageLoader imageLoader = new ImageLoader(httpService.httpQueue, mCache); return imageLoader.get(url, listener); &#125; return null; &#125; public void loadingImage(ImageView imageView, String url, int loadingResid, int errorResid, BitmapCache mCache) &#123; loadingImage(imageView, url, loadingResid, errorResid, mCache, null); &#125; /** * StringRequest */ public void getByStringRequest(ApiRequest apiRequest, boolean needOauth, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); if (needOauth) &#123; String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; if (!TextUtils.isEmpty(accessToken)) &#123; LogUtils.e(&quot;access_token&quot;, accessToken); &#125;// header.put(&quot;Authorization&quot;, &quot;Bearer&quot; + &quot; &quot; + accessToken); header.put(&quot;token&quot;, accessToken); &#125; String url = apiRequest.getUrl(Request.Method.GET); Listener listener = apiRequest.getListener(); StringRequest request = new StringRequest(Request.Method.GET, url, header, null, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); if (!useCache(null, url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; /** * StringRequest */ public void postByStringRequest(ApiRequest apiRequest, boolean needOauth, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); String url = apiRequest.getUrl(Request.Method.POST); Listener listener = apiRequest.getListener(); if (needOauth) &#123; String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; if (!TextUtils.isEmpty(accessToken)) &#123; LogUtils.e(&quot;access_token&quot;, accessToken); &#125;// header.put(&quot;Authorization&quot;, &quot;Bearer&quot; + &quot; &quot; + accessToken); header.put(&quot;token&quot;, accessToken); &#125; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(); for (String key : apiRequest.getParams().keySet()) &#123; params.put(key, (String) apiRequest.getParams().get(key)); &#125; StringRequest request = new StringRequest(Request.Method.POST, url, header, params, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); if (!useCache(null, url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; /** * 断网情况使用缓存处理 * * @param clazz * @param url * @param listener * @return */ private boolean useCache(Class clazz, String url, Listener listener) &#123; HttpService.httpQueue.getCache().invalidate(url, true); if (!NetWorkUtils.detect(httpService.getContext())) &#123; String cacheStr = DataCache.getDataCache().queryCache(url); if (cacheStr != null) &#123; try &#123; if (clazz != null) &#123; listener.onResponse(gson.fromJson(cacheStr, clazz)); &#125; else &#123; listener.onResponse(cacheStr); &#125; return true; &#125; catch (JsonSyntaxException e) &#123; e.printStackTrace(); return false; &#125; &#125; return false; &#125; else &#123; return false; &#125; &#125; public void getExtWithOAuth(com.core.api.event.request.Request apiRequest) &#123; getExtWithOAuth(apiRequest, DataCacheType.NO_CACHE); &#125; public void getExtWithOAuth(com.core.api.event.request.Request apiRequest, DataCacheType cacheType) &#123; String url = apiRequest.getUrl(Request.Method.GET) + &quot;?&quot; + apiRequest.httpParam.encodeParametersToString(&quot;UTF-8&quot;); Listener listener = apiRequest.getListener(); Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; header.put(&quot;token&quot;, accessToken); GsonRequestExt request = new GsonRequestExt(Request.Method.GET, url, apiRequest.getResponseType(), header, apiRequest.httpParam, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); if (!useCache(apiRequest.getResponseType(), url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; public void getExt(com.core.api.event.request.Request apiRequest, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); String url = apiRequest.getUrl(Request.Method.GET) + &quot;?&quot; + apiRequest.httpParam.encodeParametersToString(&quot;UTF-8&quot;); Listener listener = apiRequest.getListener(); GsonRequestExt request = new GsonRequestExt(Request.Method.GET, url, apiRequest.getResponseType(), header, apiRequest.httpParam, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); if (!useCache(apiRequest.getResponseType(), url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; public void postExt(com.core.api.event.request.Request apiRequest, DataCacheType cacheType) &#123; Map&lt;String, String&gt; header = new HashMap&lt;String, String&gt;(); if (apiRequest.getHeaders() != null) &#123; header.putAll(apiRequest.getHeaders()); &#125; header.put(&quot;code&quot;, ApiSettings.VERSION_CODE); header.put(&quot;osType&quot;, ApiSettings.OSTYPE); String accessToken = GlobalPhone.token; if(TextUtils.isEmpty(accessToken))&#123; accessToken = DataCache.getDataCache() .queryCache(&quot;access_token&quot;); &#125; if (!TextUtils.isEmpty(accessToken)) &#123; header.put(&quot;token&quot;, accessToken); &#125; String url = apiRequest.getUrl(Request.Method.POST); Listener listener = apiRequest.getListener(); GsonRequestExt request = new GsonRequestExt(Request.Method.POST, url, apiRequest.getResponseType(), header, apiRequest.httpParam, listener, apiRequest.getErrorlistener(), cacheType); request.setShouldCache(false); if (!useCache(apiRequest.getResponseType(), url, listener)) &#123; httpService.addToRequestQueue(request); &#125; &#125; // volley框架缓存 // if (HttpService.httpQueue.getCache().get(url) != null) &#123; // String cacheStr = new String(HttpService.httpQueue.getCache() // .get(url).data); // // if (cacheStr != null) &#123; // // try &#123; // listener.onResponse(cacheStr); // // &#125; catch (JsonSyntaxException e) &#123; // e.printStackTrace(); // &#125; // // return; // &#125; // // &#125;&#125; 使用 先创建基础Request，所有Request的继承他 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120public class ApiRequest &#123; public String url = &quot;&quot;; protected Map&lt;String, Object&gt; params = null; private Class&lt;?&gt; clazz; private Response.Listener&lt;?&gt; listener; private Response.ErrorListener errorlistener; protected Map&lt;String, String&gt; headers; public ApiRequest(String values, Class&lt;?&gt; clazz) &#123; this(values, clazz, false); &#125; public ApiRequest(String values, Class&lt;?&gt; clazz, boolean isChonggou) &#123; if (isChonggou) &#123; this.url = values; &#125; else &#123; this.url = String.format(&quot;%1$s%2$s&quot;, ApiSettings.URL_BASE, values); &#125; this.clazz = clazz; this.params = new HashMap&lt;String, Object&gt;();// params.put(&quot;versionCode&quot;,ApiSettings.VERSION_CODE); this.headers = new HashMap&lt;String, String&gt;(); &#125; public String getUrl(int method) &#123; switch (method) &#123; case Method.GET: return urlWithParameters(url, params); case Method.POST: return url; &#125; return url; &#125; public Map&lt;String, Object&gt; getParams() &#123; if (params.isEmpty()) &#123; Log.e(&quot;REQUEST_PARAMS&quot;, &quot;null&quot;); return null; &#125; return params; &#125; public void setParams(Map&lt;String, Object&gt; params) &#123; this.params = params; &#125; public Class getResponseType() &#123; return clazz; &#125; public Response.Listener&lt;?&gt; getListener() &#123; return listener; &#125; public void setListener(Response.Listener&lt;?&gt; listener) &#123; this.listener = listener; &#125; public Response.ErrorListener getErrorlistener() &#123; return errorlistener; &#125; public void setErrorlistener(Response.ErrorListener errorlistener) &#123; this.errorlistener = errorlistener; &#125; public Map&lt;String, String&gt; getHeaders() &#123; if (headers.isEmpty()) &#123; Log.e(&quot;REQUEST_Header&quot;, &quot;null&quot;); return null; &#125; return headers; &#125; public void setHeaders(Map&lt;String, String&gt; headers) &#123; this.headers = headers; &#125; public void addParams(Map&lt;String, Object&gt; params) &#123; if (this.params != null) &#123; this.params.putAll(params); &#125; else &#123; this.params = new HashMap&lt;String, Object&gt;(); this.params.putAll(params); &#125; &#125; public static String urlWithParameters(String url, Map&lt;String, Object&gt; params) &#123; StringBuilder builder = new StringBuilder(); if (params != null) &#123; for (HashMap.Entry&lt;String, Object&gt; entry : params.entrySet()) &#123; if (builder.length() == 0) &#123; if (url.contains(&quot;?&quot;)) &#123; builder.append(&quot;&amp;&quot;); &#125; else &#123; builder.append(&quot;?&quot;); &#125; &#125; else &#123; builder.append(&quot;&amp;&quot;); &#125; builder.append(entry.getKey()).append(&quot;=&quot;) .append(entry.getValue()); &#125; &#125; return url + builder.toString(); &#125;&#125; 创建相应的request,ApiConstans中存放所有请求的路径 12345678public class AnswerListRequest extends ApiRequest implements ApiConstants &#123; public AnswerListRequest(int page,int pageSize) &#123; super(API_ANSWERLIST, AnswerListResponse.class); params.put(&quot;page&quot;,page); params.put(&quot;pageSize&quot;,pageSize); &#125;&#125; 当然，所有请求可以放到一个library包，做抽离","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"移动端主流框架","date":"2016-08-10T06:53:36.000Z","path":"2016/08/10/移动端主流框架/","text":"开发主流框架 touchweb（手机网站） web-app（phoneGap appcan 打包成安卓apk 和 苹果ios格式） hybrid-app（主流） native-app 主流的css框架 bootstrap css动画 其他框架 icon字体 fontawesome icon字体 iconfont css 和 SASS 和 Less框架 主流的js框架 zeptiojs Jquery中方法基本都有，特点是非常的小，加载快缺点是不支持IE浏览器 jGestures (手势识别) 事件简介 orientationchange 代表设备顺时针或者逆时针旋转.此事件可以被设备触发,可能使用的是重力传感器. pinch 缩放手势(两个手指在屏幕上的相对运动) rotate 旋转手势(两个手指顺时针或者逆时针旋转) swipemove 在正在滑动时触发(在设备屏幕上移动手指,比如:拖动) swipeone 单点滑动手势,滑动完成后触发(一个手指在屏幕上移动) swipetwo 两点滑动(两个手指在屏幕上方向一致的滑动) swipethree 三点滑动(三个手指在屏幕上方向一致的滑动) swipefour 四点滑动(四个手指在屏幕上方向一致的滑动) swipeup 向上滑动,在严格的向上滑动手势完成后触发 swiperightup 向右上角滑动,在向右且向上的滑动手势完成后触发 swiperight 向右滑动,在严格的向右滑动手势完成后触发 swiperightdown 向右下角滑动,在向右且向下的滑动手势完成后触发 swipedown 向下滑动,在严格的向下滑动手势完成后触发 swipeleftdown 向左下角滑动,在向左且向下的滑动手势完成后触发 swipeleft 向左滑动,在严格的向左滑动手势完成后触发 swipeleftup 向左上角滑动,在向左且向上的滑动手势完成后触发 tapone 在单个手指轻点的手势后触发 taptwo 在两个手指一起轻点的手势后触发 tapthree 在三个手指一起轻点的手势后触发 pinchopen 撑开手势,当两个手指撑大并离开设备时触发. pinchclose 捏紧手势,当两个手指捏紧并离开设备时触发. rotatecw 两个手指顺时针旋转并且离开屏幕时触发(two fingers rotating clockwise) rotateccw 两个手指逆时针旋转并且离开屏幕时触发 (two fingers rotating counterclockwise) shake 当检测到设备正在摇晃时触发 shakefrontback 当检测到摇晃动作，且可以被解读为前后移动之时触发. shakeleftright 当检测到摇晃动作，且可以被解读为左右移动之时触发. shakeupdown 当检测到摇晃动作，且可以被解读为上下移动之时触发. 关于swipe，我上一篇文章已经介绍过了，http://www.haorooms.com/post/jquery_scroll_upanddown 当页面有滚动条的时候，swipe的up,down，left,right可能会不触发！事件会被滚动事件覆盖掉！ 事件用法： 1234567 &lt;script&gt;jQuery(document).ready(function () &#123; jQuery(window).bind(&apos;shakeupdown&apos;,function(event_,data_)&#123; alert(&apos;shake: &apos;+ data_.description) &#125;) &#125;)&lt;/script&gt; swiper (滚动效果，就类似于现在H5宣传滑动跳转页面一样) iSroll.js 移动开发流行框架 jqueryMobile (缺点下拉框反应比较慢) app framework senchtouch（桌面程序） mobileangularui phonegap appcan 妹子UI 百度GMU","categories":[{"name":"前端技术","slug":"前端技术","permalink":"https://centmeng.github.io/categories/前端技术/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://centmeng.github.io/tags/框架/"}]},{"title":"spring-boot 分页查询（关联表）","date":"2016-08-08T14:27:42.000Z","path":"2016/08/08/spring-boot-分页查询（关联表）/","text":"引言：由于公司转型，使我原本android开发工程师，转变为后台开发工程师，对于后台，除了大学利用servlet写过些项目，其他就一无所知。公司使用spring-boot框架.那么spring-boot框架究竟是什么呢？Spring-boot是微框架，是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。好了废话不说了，下面讲讲分页实例吧。 首先我们创建两个实例（表）TestPage 和TestPageRef，其中TestPageRef关联TestPage的Id,其中这两个表都继承TimeScopeEntity（增加了id和创建时间字段） 12345678910111213141516171819/** * 分页测试表 * @author CentMeng &lt;mengshaojie@188.com&gt; * @date Aug 8, 2016 3:30:45 PM * @copyright ©2016 孟少杰 All Rights Reserved * @desc */@Data@NoArgsConstructor@AllArgsConstructor@Entity@Table(name = &quot;T_TESTPAGE&quot;)public class TestPage extends TimeScopeEntity&#123; private String name; private String content; &#125; 12345678910111213141516171819/** * 分页测试表关联表 * @author CentMeng &lt;mengshaojie@188.com&gt; * @date Aug 8, 2016 3:30:45 PM * @copyright ©2016 孟少杰 All Rights Reserved * @desc */@Data@NoArgsConstructor@AllArgsConstructor@Entity@Table(name = &quot;T_TESTPAGEREF&quot;)public class TestPageRef extends TimeScopeEntity&#123; private String testId; private boolean enabled;&#125; 写Dao层接口，主要是继承PagingAndSortingRepository这里我们写一个获取list的方法接口,返回的是Page对象 也可以返回某些字段，将t，替换成t.id,t.content等等 123456789101112131415161718192021import javax.transaction.Transactional;import net.luoteng.muser.entity.TestPage;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.jpa.repository.Query;import org.springframework.data.repository.PagingAndSortingRepository;import org.springframework.data.repository.query.Param;/** * 分页测试 * @author CentMeng &lt;mengshaojie@188.com&gt; * @date Aug 8, 2016 3:39:55 PM * @copyright ©2016 孟少杰 All Rights Reserved * @desc */@Transactionalpublic interface TestRepository extends PagingAndSortingRepository&lt;TestPage,String&gt;&#123; @Query(&quot;select t from TestPage t,TestPageRef r where t.id = r.testId and r.enabled = :enabled&quot;) public Page&lt;TestPage&gt; findList( @Param(&quot;enabled&quot;) boolean enabled,Pageable pageable);&#125; 写Service层Service层要分接口层和实现层，springboot的注入为接口注入 接口123456789101112131415161718package net.luoteng.muser.service;import net.luoteng.muser.common.PageResult;import net.luoteng.muser.entity.TestPage;import org.springframework.data.domain.Pageable;/** * * 分页测试 * @author CentMeng &lt;mengshaojie@188.com&gt; * @date Aug 8, 2016 3:37:51 PM * @copyright ©2016 孟少杰 All Rights Reserved * @desc */public interface TestService &#123; public PageResult&lt;TestPage&gt; list(boolean enabled,Pageable pageable);&#125; 实现1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.List;import javax.transaction.Transactional;import net.luoteng.muser.common.PageResult;import net.luoteng.muser.dao.TestRepository;import net.luoteng.muser.entity.TestPage;import net.luoteng.muser.service.TestService;import org.apache.commons.collections.CollectionUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.stereotype.Component;/** * * @author CentMeng &lt;mengshaojie@188.com&gt; * @date Aug 8, 2016 4:21:25 PM * @copyright ©2016 孟少杰 All Rights Reserved * @desc */@Component@Transactionalpublic class TestImpl implements TestService&#123; @Autowired TestRepository testRepository; @Override public PageResult&lt;TestPage&gt; list(boolean enabled, Pageable pageable) &#123; Page&lt;TestPage&gt; testPages = testRepository.findList(enabled,pageable); List&lt;TestPage&gt; tests = testPages.getContent(); if (!CollectionUtils.isEmpty(tests)) &#123; PageResult pageResult = new PageResult(tests, testPages.getTotalElements()); return pageResult; &#125; else &#123; return null; &#125; &#125;&#125; Page返回参数说明： 12345678910111213141516171819202122232425262728&#123; &quot;content&quot;:[ &#123;&quot;id&quot;:123,&quot;title&quot;:&quot;blog122&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:122,&quot;title&quot;:&quot;blog121&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:121,&quot;title&quot;:&quot;blog120&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:120,&quot;title&quot;:&quot;blog119&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:119,&quot;title&quot;:&quot;blog118&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:118,&quot;title&quot;:&quot;blog117&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:117,&quot;title&quot;:&quot;blog116&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:116,&quot;title&quot;:&quot;blog115&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:115,&quot;title&quot;:&quot;blog114&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:114,&quot;title&quot;:&quot;blog113&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:113,&quot;title&quot;:&quot;blog112&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:112,&quot;title&quot;:&quot;blog111&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:111,&quot;title&quot;:&quot;blog110&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:110,&quot;title&quot;:&quot;blog109&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;, &#123;&quot;id&quot;:109,&quot;title&quot;:&quot;blog108&quot;,&quot;content&quot;:&quot;this is blog content&quot;&#125;], &quot;last&quot;:false, &quot;totalPages&quot;:9, &quot;totalElements&quot;:123, &quot;size&quot;:15, &quot;number&quot;:0, &quot;first&quot;:true, &quot;sort&quot;:[&#123; &quot;timeCreated&quot;:&quot;DESC&quot;, &#125;], &quot;numberOfElements&quot;:15&#125; 以id倒序排列的10条数据 当前页不是最后一页，后面还有数据 总共有9页 每页大小为15 当前页为第0页 当前页是第一页 当前页是以id倒序排列的 当前页一共有15条数据 Controller层关键代码 12345678910111213141516171819202122@Autowired TestService testService; /** * * @param page * @param pageSize * @return */ @RequestMapping(value = &quot;/test/page&quot;, method = RequestMethod.GET) public RestResponse testPage( @RequestParam(value = &quot;page&quot;, defaultValue = &quot;0&quot;) Integer page, @RequestParam(value = &quot;pageSize&quot;, defaultValue = &quot;10&quot;) Integer pageSize) &#123; RestResponse result = new RestResponse(); //排序对象 Sort sort = new Sort(Sort.Direction.DESC, &quot;timeCreated&quot;); Pageable pageable = new PageRequest(page, pageSize, sort); PageResult&lt;TestPage&gt; pageResult = testService.list(true, pageable); return result.success(pageResult); &#125; OK这样，分页关联表查询效果就实现了 注解解释只是个人查看记忆用，非本次讲解内容 @Data 自动创建getter和setter@NoArgsConstructor@AllArgsConstructor 这两个是声明构造函数@Entity 申明是实体，需要创建表的都会用到@Table(name = “T_TESTPAGE”) 创建表，可以设置表名，以及唯一键@Component 在service实现层使用@Transactional 事务 在service实现层和dao层都需要使用@Autowired 自动引入，自己构造的则不用使用此注解@RequestMapping(value = “/test/page”, method = RequestMethod.GET) 配置请求路径和请求方式","categories":[{"name":"后端技术","slug":"后端技术","permalink":"https://centmeng.github.io/categories/后端技术/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://centmeng.github.io/tags/spring-boot/"}]},{"title":"android实现中间卡位下方viewpager效果展示","date":"2016-07-25T11:11:35.000Z","path":"2016/07/25/android实现中间卡位下方viewpager效果展示/","text":"###设置卡位效果### 实现如图效果，中间tab滑动上方时候，卡在顶部，下方继续上滑 其实很简单，只需要借助android的Design Support Library ####1.引用library1compile 'com.android.support:design:23.3.0' ####2.写布局 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;android.support.design.widget.CoordinatorLayout android:id=\"@+id/coordinator\" android:layout_marginTop=\"@dimen/view_height\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt; &lt;android.support.design.widget.AppBarLayout android:id=\"@+id/barlayout\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:layout_above=\"@+id/layout_zhidian\" android:background=\"@color/background\" android:theme=\"@style/ThemeOverlay.AppCompat.Dark\"&gt; &lt;FrameLayout android:id=\"@+id/layout_topexpert\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:background=\"@color/white\" app:layout_scrollFlags=\"scroll|exitUntilCollapsed\" android:visibility=\"visible\"&gt; &lt;....&gt; &lt;..../&gt; &lt;/FrameLayout&gt; &lt;android.support.design.widget.TabLayout android:id=\"@+id/tl_expert\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" app:tabGravity=\"center\" app:tabIndicatorColor=\"@color/basecolor\" android:background=\"@color/white\" app:tabMode=\"fixed\" android:layout_gravity=\"center\" app:tabSelectedTextColor=\"@color/basecolor\" app:tabTextColor=\"@color/darkgray\" /&gt; &lt;/android.support.design.widget.AppBarLayout&gt; &lt;android.support.v4.view.ViewPager android:id=\"@+id/viewpager\" app:layout_behavior=\"@string/appbar_scrolling_view_behavior\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" /&gt; &lt;/android.support.design.widget.CoordinatorLayout&gt; 其中关键的是CoordinatorLayout #####设置滑动布局##### 在CoordinatorLayout中包含AppBarLayout,其中AppBarLayout中的子布局，如果设置app:layout_scrollFlags属性里面必须至少启用scroll这个flag，这样这个view才会滚动出屏幕，否则它将一直固定在顶部。可以使用的其他flag有： enterAlways: 一旦向上滚动这个view就可见。 enterAlwaysCollapsed: 顾名思义，这个flag定义的是何时进入（已经消失之后何时再次显示）。假设你定义了一个最小高度（minHeight）同时enterAlways也定义了，那么view将在到达这个最小高度的时候开始显示，并且从这个时候开始慢慢展开，当滚动到顶部的时候展开完。 exitUntilCollapsed: 同样顾名思义，这个flag时定义何时退出，当你定义了一个minHeight，这个view将在滚动到达这个最小高度的时候消失。 记住，要把带有scroll flag的view放在前面，这样收回的view才能让正常退出，而固定的view继续留在顶部。 本例中layout_topexpert是使用滑动消失的设置了 app:layout_scrollFlags=”scroll|exitUntilCollapsed”，而tl_expert是卡在上方的，所以没有做任何设置 #####定义AppBarLayout与滚动视图之间的联系#####在viewpager或者任意支持嵌套滚动的view比如NestedScrollView上添加app:layout_behavior。support library包含了一个特殊的字符串资源@string/appbar_scrolling_view_behavior，它和AppBarLayout.ScrollingViewBehavior相匹配，用来通知AppBarLayout 这个特殊的view何时发生了滚动事件，这个behavior需要设置在触发事件（滚动）的view之上 *另外需要注意的是* 如果相关滚动的是viewpager，在viewpager可以使用recyclerview和scrollview，但ScrollView要使用NestedScrollView 滑动卡位的效果实现了，下面是实现Tabfenye和viewpager下方的效果了，其实也很简单，使用库中的android.support.design.widget.TabLayout并做些设置就ok了 ###设置Tablayout### ####1.设置ViewPager的adpter 代码很简单，直接看代码 1234567891011121314151617181920212223242526272829303132333435363738394041public class ExpertDetailPagerAdapter extends FragmentPagerAdapter &#123; private String userId = \"\"; private String[] tabTitles = new String[]&#123;\"点师介绍\",\"话题\",\"益答\",\"动态\"&#125;; @Override public CharSequence getPageTitle(int position) &#123; return tabTitles[position]; &#125; public ExpertDetailPagerAdapter(FragmentManager fm, String userId) &#123; super(fm); this.userId = userId; &#125; @Override public int getCount() &#123; return 4; &#125; @Override public Fragment getItem(int position) &#123; switch (position)&#123; case 0: return ExpertInfoFragment.newInstance(userId); case 1: return ExpertTopicFragment.newInstance(userId); case 2: RankEntity entity = new RankEntity(); entity.setId(userId); return ExpertYiDaFragment.newInstance(entity); case 3: return ExpertDynamicFragment.newInstance(userId); &#125; return null; &#125; &#125; getPageTitle是返回Tab的标题 ####2.设置Tablayout 12345fragmentAdapter = new ExpertDetailPagerAdapter(getSupportFragmentManager(),expertId); viewpager.setAdapter(fragmentAdapter); viewpager.setOffscreenPageLimit(3); tl_expert.setupWithViewPager(viewpager); 本例中Tablayout是居中显示，是通过在布局中设置这两个属性实现的 123app:tabGravity=\"center\"app:tabMode=\"fixed\" 这样就实现了，我一开始使用ScrollView嵌套ViewPager，ViewPager中嵌套ScrollView，RecyclerView出现一大堆问题，最后发现用design库如此的简单解决了问题 ###自定义Behavior### CoordinatorLayout的工作原理是搜索定义了CoordinatorLayout Behavior 的子view，不管是通过在xml中使用app:layout_behavior标签还是通过在代码中对view类使用@DefaultBehavior修饰符来添加注解。当滚动发生的时候，CoordinatorLayout会尝试触发那些声明了依赖的子view。 要自己定义CoordinatorLayout Behavior，你需要实现layoutDependsOn() 和onDependentViewChanged()两个方法。比如AppBarLayout.Behavior 就定义了这两个关键方法。这个behavior用于当滚动发生的时候让AppBarLayout发生改变。 123456789101112public boolean layoutDependsOn(CoordinatorLayout parent, View child, View dependency) &#123; return dependency instanceof AppBarLayout;&#125;public boolean onDependentViewChanged(CoordinatorLayout parent, View child, View dependency) &#123; // check the behavior triggered android.support.design.widget.CoordinatorLayout.Behavior behavior = ((android.support.design.widget.CoordinatorLayout.LayoutParams) dependency.getLayoutParams()).getBehavior(); if (behavior instanceof AppBarLayout.Behavior) &#123; // do stuff here &#125;&#125;","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"布局样式","slug":"布局样式","permalink":"https://centmeng.github.io/tags/布局样式/"}]},{"title":"studio配置AndroidAnnotations","date":"2016-07-23T03:32:15.000Z","path":"2016/07/23/studio配置AndroidAnnotations/","text":"修改全局gradle文件 1234567891011121314151617181920212223buildscript &#123; repositories &#123; jcenter() &#125; dependencies &#123; classpath &apos;com.android.tools.build:gradle:2.1.2&apos; // NOTE: Do not place your application dependencies here; they belong // in the individual module build.gradle files classpath &apos;com.neenbedankt.gradle.plugins:android-apt:1.4&apos; &#125;&#125;allprojects &#123; repositories &#123; jcenter() &#125;&#125;task clean(type: Delete) &#123; delete rootProject.buildDir&#125; 修改app级gradle文件 1234567891011121314151617181920apply plugin: &apos;com.android.application&apos;apply plugin: &apos;android-apt&apos;def AAVersion = &apos;3.3.2&apos;dependencies &#123; compile fileTree(dir: &apos;libs&apos;, include: [&apos;*.jar&apos;]) testCompile &apos;junit:junit:4.12&apos; compile &apos;com.android.support:appcompat-v7:23.4.0&apos; apt &quot;org.androidannotations:androidannotations:$AAVersion&quot; compile &quot;org.androidannotations:androidannotations-api:$AAVersion&quot;&#125;apt &#123; arguments &#123; androidManifestFile variant.outputs[0].processResources.manifestFile // resourcePackageName &quot;your.package.name&quot; resourcePackageName &apos;com.luoteng.voicerecord&apos; &#125;&#125; 通过如下配置我们就可以使用android annotations了","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"Android Studio","slug":"Android-Studio","permalink":"https://centmeng.github.io/tags/Android-Studio/"}]},{"title":"python使用决策树算法","date":"2016-07-19T15:16:52.000Z","path":"2016/07/19/python使用决策树算法/","text":"步骤： 导入数据 利用csv导入数据 分离数据 将输入数据，和结果数据分离出来 转化数据 ***将输入数据和结果数据转化成0，1格式的数据 输入数据转化如下 12345678910111213141516dummyX[[ 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.] [ 0. 0. 1. 1. 0. 1. 0. 0. 1. 0.] [ 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.] [ 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.] [ 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.] [ 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.] [ 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.] [ 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.] [ 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.] [ 0. 1. 0. 0. 1. 0. 0. 1. 0. 1.] [ 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.] [ 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.] [ 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.] [ 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]] 其中每一列对应的数据是: ['age=middle_aged', 'age=senior', 'age=youth', 'credit_rating=excellent', 'credit_rating=fair', 'income =high', 'income =low', 'income =medium', 'student=no', 'student=yes'] 输出数据转化如下 123456789101112131415dummY[[0] [0] [1] [1] [1] [0] [1] [0] [1] [1] [1] [1] [1] [0]]其中每一行都是最终结果，此例是是否购买的结果 建模 12 clf = tree.DecisionTreeClassifier(criterion='entropy') #声明使用决策树ID3算法clf = clf.fit(dummyX,dummyY); 生成dot文件 12with open(\"allEletronicInformationGainOri.dot\", 'w') as f: f = tree.export_graphviz(clf,feature_names=vec.get_feature_names(),out_file=f) 利用graphviz工具将dot文件导入把决策树画出来（其中分支节点的上下关系根据信息熵的大小来评估的） 测试和使用 123#newRowX是0，1输入数据predictedY = clf.predict(newRowX)print(\"新数据结果\" + str(predictedY)) ###信息熵的算法：(变量的不确定性越大，熵越大) =负的 每一个发生的概率 乘以 以2为低概率的对数### 代码地址","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://centmeng.github.io/categories/大数据技术/"}],"tags":[{"name":"python","slug":"python","permalink":"https://centmeng.github.io/tags/python/"}]},{"title":"TextView显示Gif图片实现图文混排","date":"2016-07-19T11:36:25.000Z","path":"2016/07/19/TextView图文混排/","text":"首先我们使用的html，解析成Spanned，然后设置Span来实现图文混排的，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public static Drawable getUrlDrawable(String source, TextView mTextView) &#123; GlideImageGetter imageGetter = new GlideImageGetter(mTextView.getContext(),mTextView); return imageGetter.getDrawable(source);&#125; public static void setImageText(TextView tv)&#123; String html =\"&lt;p dir=\\\"ltr\\\"&gt;&lt;img src=\\\"http://p1.duyao001.com/image/article/a838e283f2b5d7cc45487c5fd79f84cb.gif\\\"&gt;&lt;img src=\\\"http://statics.zhid58.com/Fqr9YXHd20fDOqil4nLAbBhNBw0A\\\"&gt;&lt;br&gt;&lt;br&gt;&lt;img src=\\\"http://statics.zhid58.com/FufBg05KGCLypIvrYgjaXnTWySUS\\\"&gt;&lt;br&gt;&lt;br&gt;OK咯木木木立刻哦lol额JOJO图谋女女look女女诺克各地测了测理论啃了了乐克乐克人咯咯JOJO图谋木木木木木木女女哦咯口头摸头LED可口女女LED咳咳JOJO咯JOJO咳咳咯科技JOJO扣女哦lol欧诺扣女&lt;a href=\\\"http://www.taobao.com\\\"&gt;http://www.taobao.com&lt;/a&gt; jvjvjvjv jgjvvjjvjce&lt;br&gt;&lt;br&gt;&lt;img src=\\\"http://statics.zhid58.com/FkBcKMiLfzGfUpSb0bge4x-gIqWw\\\"&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;\"; Spanned htmlStr = Html.fromHtml(html); if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.HONEYCOMB) &#123; tv.setLayerType(View.LAYER_TYPE_SOFTWARE, null); tv.setTextIsSelectable(true); &#125; tv.setText(htmlStr); tv.setMovementMethod(LinkMovementMethod.getInstance()); CharSequence text = tv.getText(); if(text instanceof Spannable)&#123; int end = text.length(); Spannable sp = (Spannable)tv.getText(); URLSpan[] urls=sp.getSpans(0, end, URLSpan.class); ImageSpan[] imgs = sp.getSpans(0,end,ImageSpan.class); StyleSpan[] styleSpens = sp.getSpans(0,end,StyleSpan.class); ForegroundColorSpan[] colorSpans = sp.getSpans(0,end,ForegroundColorSpan.class); SpannableStringBuilder style=new SpannableStringBuilder(text); style.clearSpans(); for(URLSpan url : urls)&#123; style.setSpan(url,sp.getSpanStart(url),sp.getSpanEnd(url),Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); ForegroundColorSpan colorSpan = new ForegroundColorSpan(Color.parseColor(\"#FF12ADFA\")); style.setSpan(colorSpan,sp.getSpanStart(url),sp.getSpanEnd(url),Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); &#125; for(ImageSpan url : imgs)&#123; ImageSpan span = new ImageSpan(getUrlDrawable(url.getSource(),tv),url.getSource()); style.setSpan(span,sp.getSpanStart(url),sp.getSpanEnd(url),Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); &#125; for(StyleSpan styleSpan : styleSpens)&#123; style.setSpan(styleSpan,sp.getSpanStart(styleSpan),sp.getSpanEnd(styleSpan),Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); &#125; for(ForegroundColorSpan colorSpan : colorSpans)&#123; style.setSpan(colorSpan,sp.getSpanStart(colorSpan),sp.getSpanEnd(colorSpan),Spannable.SPAN_EXCLUSIVE_EXCLUSIVE); &#125; tv.setText(style); &#125;&#125; 上面代码图片展示是通过ImageSpan来实现的，但默认的图片展示的gif图片是静态取第一帧图片，我们可以在获取图片时候使用Glide，来实现播放gif,glide是图片加载库，这个库被广泛的运用在google的开源项目中，包括2014年google I/O大会上发布的官方app。Glide和Picasso有90%的相似度，准确的说，就是Picasso的克隆版本。但是在细节上还是有不少区别的。而且性能上更加优化。 把Glide引入到我们项目中，然后在创建UrlDrawable 和 GlideImageGetter 代码可以参考：RichTextView 方法调用就是 1ImageTextUtil.setImageText(tv,html); 需注意的是 //个别机型如魅族手机，如果使用以下语句会报错导致无法显示Textview内容 View too large to fit into drawing cache 的Warning// if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.HONEYCOMB) {// tv.setLayerType(View.LAYER_TYPE_SOFTWARE, null); 关闭硬件加速// tv.setTextIsSelectable(true); 设置是否可以粘贴// }","categories":[{"name":"Android技术","slug":"Android技术","permalink":"https://centmeng.github.io/categories/Android技术/"}],"tags":[{"name":"图文混排","slug":"图文混排","permalink":"https://centmeng.github.io/tags/图文混排/"}]},{"title":"hexo安装","date":"2016-07-19T11:29:53.000Z","path":"2016/07/19/hexo安装/","text":"###下载hexo 安装node 查看安装的node版本 npm -v 安装git 安装Hexo sudo npm install -g hexo-cli ###生成本地hexo目录 创建hexo目录 cd hexo 初始化hexo hexo init ###启动hexo 生成静态页面 hexo generate（hexo g也可以） 启动本地服务 hexo server 浏览器输入http://localhost:4000 ###github的repository与hexo关联 创建个人github的repository repository名称必须为${userName}.github.io 建立与hexo的连接 cd hexo vim _config.yml 修改config.yml中最下方如下： deploy: type: git repo:https://github.com/${userName}/${userName}.github.io.git branch:master npm install hexo-deployer-git –save hexo deploy 浏览器http://${userName}.github.io/ 部署 每次布署前，按下列顺序执行 hexo clean hexo generate hexo deploy ###更换头像、作者、主题 修改头像 cd hexo/themes/yilia vim _config.yml 找到 #你的头像url avatar: 后接一个URL就行了，头像就修改成功了 修改作者名字 cd hexo vim _config.yml 找到 author: 潘柏信，修改成你自己的名字就行了 部署 hexo g 提交 hexo d 修改主题 cd hexo/themes git clone ${gitThemeAddress}.git cd hexo vim _config.yml 找到如下文字 # Extensions ## Plugins: http://hexo.io/plugins/ ## Themes: http://hexo.io/themes/ theme:yilia 改成theme: yilia，theme:后面接你自己的主题名字就行了,然后分别执行 部署 hexo g 提交 hexo d 常用命令 hexo new”postName” #新建文章 hexo new page”pageName” #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server） hexo deploy #将.deploy目录部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 常见错误 ERROR Deployer not found: git 或者 ERROR Deployer not found: github 解决方法： npm install hexo-deployer-git –save ERROR Process failed: layout/.DS_Store 进入主题里面layout和_partial目录下，使用删除命令： rm-rf.DS_Store ERROR Plugin load failed: hexo-server 原因：Besides,utilities are separated into a standalone module.hexo.util is not reachable anymore. 解决方法，执行命令：sudo npm install hexo-server 执行命令hexo server，提示：Usage: hexo …. 原因：我认为是没有生成本地服务 解决方法，执行命令：npm install hexo-server–save 提示：hexo-server@0.1.2 node_modules/hexo-server .... 表示成功了 这个时候再执行：hexo-server 得到: INFOHexois running at http://0.0.0.0:4000/.PressCtrl+C to stop. 这个时候再点击http://0.0.0.0:4000，正常情况下应该是最原始的画面，但是我看到的是： 白板和Cannot GET / 几个字 原因： 由于2.6以后就更新了，我们需要手动配置些东西，我们需要输入下面三行命令： npm install hexo-renderer-ejs--save npm install hexo-renderer-stylus--save npm install hexo-renderer-marked--save 这个时候再重新生成静态文件，命令： hexo generate（或hexo g） 启动本地服务器： hexo server（或hexo s） 再点击网址http://0.0.0.0:4000O No layout: index.html 原因：更换主题后，主题文件不正确。","categories":[{"name":"其他","slug":"其他","permalink":"https://centmeng.github.io/categories/其他/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://centmeng.github.io/tags/hexo/"}]}]